{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e0e7a8",
   "metadata": {},
   "source": [
    "First pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8529c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://www.cms.gov/Regulations-and-Guidance/Guidance/Manuals/downloads/som107ap_a_hospitals.pdf\n",
      "Processing: https://nam.edu/wp-content/uploads/2021/07/4.3-AI-in-Health-Care-title-authors-summary.pdf\n",
      "Processing: https://www.chfs.ky.gov/agencies/dph/oc/Documents/FY24-Clinical-Service-Guide.pdf\n",
      "Error processing https://www.chfs.ky.gov/agencies/dph/oc/Documents/FY24-Clinical-Service-Guide.pdf: 403 Client Error: Forbidden for url: https://www.chfs.ky.gov/agencies/dph/oc/Documents/FY24-Clinical-Service-Guide.pdf\n",
      "Processing: https://dcr.hawaii.gov/wp-content/uploads/2024/08/2024-Community-Resource-Guide-Part-1.pdf\n",
      "Processing: https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf\n",
      "Error processing https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf: 404 Client Error: Not Found for url: https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf\n",
      "Processing: https://stacks.cdc.gov/view/cdc/103606/cdc_103606_DS1.pdf\n",
      "Processing: https://www.ahima.org/media/gq5jeclv/recertification_guide_2021.pdf\n",
      "Processing: https://dsp.delaware.gov/wp-content/uploads/sites/118/2020/07/Annual-Report-2019.pdf\n",
      "Processing: https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0268.pdf\n",
      "Error processing https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0268.pdf: 403 Client Error: Forbidden for url: https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0268.pdf\n",
      "Processing: https://pdfs.semanticscholar.org/7fa1/44eef185f0ecea7724fbcddffb7343fe1edf.pdf\n",
      "Processing: https://doit.illinois.gov/content/dam/soi/en/web/doit/meetings/ai-taskforce/reports/2024-gen-ai-task-force-report.pdf\n",
      "Processing: https://www.in.gov/sboe/files/Board-Memo-and-SEBH-Plan.pdf\n",
      "Processing: https://www.healthit.gov/sites/default/files/page/2022-10/Priorities%20to%20Accelerate%20Workflow%20Automation-508-1022.pdf\n",
      "Error processing https://www.healthit.gov/sites/default/files/page/2022-10/Priorities%20to%20Accelerate%20Workflow%20Automation-508-1022.pdf: 403 Client Error: Forbidden for url: https://www.healthit.gov/sites/default/files/page/2022-10/Priorities%20to%20Accelerate%20Workflow%20Automation-508-1022.pdf\n",
      "Processing: https://www.education.nh.gov/sites/g/files/ehbemt326/files/inline-documents/sonh/504-resource-guide-201612.pdf\n",
      "Error processing https://www.education.nh.gov/sites/g/files/ehbemt326/files/inline-documents/sonh/504-resource-guide-201612.pdf: 403 Client Error: Forbidden for url: https://www.education.nh.gov/sites/g/files/ehbemt326/files/inline-documents/sonh/504-resource-guide-201612.pdf\n",
      "Processing: https://dpcpsi.nih.gov/sites/default/files/NIH-2010-2011-Biennial-Report-2-19-13.pdf\n",
      "Processing: https://www.pa.gov/content/dam/copapwp-pagov/en/education/documents/instruction/charter-schools/charter-school-annual-reports/2022-23/pennsylvania%20cyber%20cs%202022-23%20annual%20report.pdf\n",
      "Processing: https://www.ama-assn.org/system/files/a23-mss-refcomm-report.pdf\n",
      "Processing: https://education.mn.gov/mdeprod/groups/educ/documents/hiddencontent/mdaw/mda1/~edisp/005242.pdf\n",
      "Processing: https://doit.illinois.gov/content/dam/soi/en/web/doit/documents/initiatives/doit-steam/2023-newsletters/STEAM%20Newsletter%20April%202023.pdf\n",
      "Processing: https://www.sos.mo.gov/CMSImages/AdRules/moreg/2025/v50n3Feb3/V50n3.pdf\n",
      "Error processing https://www.sos.mo.gov/CMSImages/AdRules/moreg/2025/v50n3Feb3/V50n3.pdf: 403 Client Error: Forbidden for url: https://www.sos.mo.gov/CMSImages/AdRules/moreg/2025/v50n3Feb3/V50n3.pdf\n",
      "\n",
      "Done. Results saved to: /Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CSV_PATH = \"/Users/winnie/Documents/GitHub/MedAI/classify_by_state/sampled_20_rows.csv\"  # Path to your CSV\n",
    "OUTPUT_PATH = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories.csv\"  # Output file\n",
    "\n",
    "# Define category keywords\n",
    "category_keywords = {\n",
    "    \"Predictive AI\": [r\"\\bpredictive\\b\", r\"\\brisk prediction\\b\", r\"\\bforecasting\\b\", r\"\\bearly warning\\b\"],\n",
    "    \"Generative AI\": [r\"\\bgenerative\\b\", r\"\\bchatbot\\b\", r\"\\btext generation\\b\", r\"\\bsynthetic data\\b\"],\n",
    "    \"Prescriptive AI\": [r\"\\bprescriptive\\b\", r\"\\btreatment recommendation\\b\", r\"\\bdecision support\\b\"],\n",
    "    \"Descriptive AI\": [r\"\\bdescriptive\\b\", r\"\\bpattern recognition\\b\", r\"\\bclustering\\b\", r\"\\bphenotype discovery\\b\"],\n",
    "    \"AI Agents\": [r\"\\bAI agent\\b\", r\"\\bautonomous AI\\b\", r\"\\bvirtual assistant\\b\", r\"\\bAI companion\\b\"]\n",
    "}\n",
    "\n",
    "# === FUNCTION TO DOWNLOAD AND EXTRACT PDF TEXT ===\n",
    "def extract_text_from_pdf_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(\"temp.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        reader = PdfReader(\"temp.pdf\")\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "        os.remove(\"temp.pdf\")\n",
    "        return text.lower()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# === PROCESSING SCRIPT ===\n",
    "def classify_pdfs(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    results = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row[1]\n",
    "        print(f\"Processing: {url}\")\n",
    "        text = extract_text_from_pdf_url(url)\n",
    "        matched_categories = []\n",
    "\n",
    "        for category, patterns in category_keywords.items():\n",
    "            if any(re.search(p, text) for p in patterns):\n",
    "                matched_categories.append(category)\n",
    "\n",
    "        results.append({\"pdf_url\": url, \"categories\": \", \".join(matched_categories) if matched_categories else \"None\"})\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"\\nDone. Results saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "# === RUN ===\n",
    "if __name__ == \"__main__\":\n",
    "    classify_pdfs(CSV_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f54830",
   "metadata": {},
   "source": [
    "Second pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f75e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (1/20): https://www.cms.gov/Regulations-and-Guidance/Guidance/Manuals/downloads/som107ap_a_hospitals.pdf\n",
      "Processing (2/20): https://nam.edu/wp-content/uploads/2021/07/4.3-AI-in-Health-Care-title-authors-summary.pdf\n",
      "Processing (3/20): https://www.chfs.ky.gov/agencies/dph/oc/Documents/FY24-Clinical-Service-Guide.pdf\n",
      "Processing (4/20): https://dcr.hawaii.gov/wp-content/uploads/2024/08/2024-Community-Resource-Guide-Part-1.pdf\n",
      "Processing (5/20): https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf\n",
      "Error downloading or reading https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf: 404 Client Error: Not Found for url: https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf\n",
      "Processing (6/20): https://stacks.cdc.gov/view/cdc/103606/cdc_103606_DS1.pdf\n",
      "Processing (7/20): https://www.ahima.org/media/gq5jeclv/recertification_guide_2021.pdf\n",
      "Processing (8/20): https://dsp.delaware.gov/wp-content/uploads/sites/118/2020/07/Annual-Report-2019.pdf\n",
      "Processing (9/20): https://journalwjarr.com/sites/default/files/fulltext_pdf/WJARR-2025-0268.pdf\n",
      "Processing (10/20): https://pdfs.semanticscholar.org/7fa1/44eef185f0ecea7724fbcddffb7343fe1edf.pdf\n",
      "Processing (11/20): https://doit.illinois.gov/content/dam/soi/en/web/doit/meetings/ai-taskforce/reports/2024-gen-ai-task-force-report.pdf\n",
      "Processing (12/20): https://www.in.gov/sboe/files/Board-Memo-and-SEBH-Plan.pdf\n",
      "Processing (13/20): https://www.healthit.gov/sites/default/files/page/2022-10/Priorities%20to%20Accelerate%20Workflow%20Automation-508-1022.pdf\n",
      "Processing (14/20): https://www.education.nh.gov/sites/g/files/ehbemt326/files/inline-documents/sonh/504-resource-guide-201612.pdf\n",
      "Processing (15/20): https://dpcpsi.nih.gov/sites/default/files/NIH-2010-2011-Biennial-Report-2-19-13.pdf\n",
      "Processing (16/20): https://www.pa.gov/content/dam/copapwp-pagov/en/education/documents/instruction/charter-schools/charter-school-annual-reports/2022-23/pennsylvania%20cyber%20cs%202022-23%20annual%20report.pdf\n",
      "Processing (17/20): https://www.ama-assn.org/system/files/a23-mss-refcomm-report.pdf\n",
      "Processing (18/20): https://education.mn.gov/mdeprod/groups/educ/documents/hiddencontent/mdaw/mda1/~edisp/005242.pdf\n",
      "Processing (19/20): https://doit.illinois.gov/content/dam/soi/en/web/doit/documents/initiatives/doit-steam/2023-newsletters/STEAM%20Newsletter%20April%202023.pdf\n",
      "Processing (20/20): https://www.sos.mo.gov/CMSImages/AdRules/moreg/2025/v50n3Feb3/V50n3.pdf\n",
      "\n",
      "Classification complete. Results saved to /Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CSV_PATH = \"/Users/winnie/Documents/GitHub/MedAI/classify_by_state/sampled_20_rows.csv\"  # Path to your CSV\n",
    "OUTPUT_PATH = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories2.csv\" \n",
    "TEXT_DIR = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_texts\"\n",
    "\n",
    "# === Ensure output directory exists ===\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "\n",
    "# === Category Keywords ===\n",
    "category_keywords = {\n",
    "    \"Predictive AI\": [\n",
    "        r\"\\bpredictive model(s)?\\b\",\n",
    "        r\"\\bpredictive analytics\\b\",\n",
    "        r\"\\bpredictive algorithm(s)?\\b\",\n",
    "        r\"\\brisk prediction model(s)?\\b\",\n",
    "        r\"\\bmachine learning (for|based on) prediction\\b\",\n",
    "        r\"\\bpredicting (outcomes|disease|risk)\\b\"\n",
    "    ],\n",
    "    \"Generative AI\": [\n",
    "        r\"\\bgenerative ai\\b\",\n",
    "        r\"\\b(ai[- ]generated|ai[- ]powered generation)\\b\",\n",
    "        r\"\\blarge language model(s)?\\b\",\n",
    "        r\"\\blanguage generation\\b\",\n",
    "        r\"\\bsynthetic data generation\\b\",\n",
    "        r\"\\bgpt[- ]?[\\d]+\\b\",\n",
    "        r\"\\bchatbot(s)?\\b\",\n",
    "        r\"\\btext synthesis\\b\"\n",
    "    ],\n",
    "    \"Prescriptive AI\": [\n",
    "        r\"\\bprescriptive analytics\\b\",\n",
    "        r\"\\btreatment recommendation system(s)?\\b\",\n",
    "        r\"\\bai[- ]based decision support\\b\",\n",
    "        r\"\\bclinical decision support system(s)?\\b\",\n",
    "        r\"\\btherapy recommendation\\b\"\n",
    "    ],\n",
    "    \"Descriptive AI\": [\n",
    "        r\"\\bdescriptive analytics\\b\",\n",
    "        r\"\\bun\\-?supervised learning\\b\",\n",
    "        r\"\\bpattern recognition\\b\",\n",
    "        r\"\\bphenotype (clustering|discovery)\\b\",\n",
    "        r\"\\banomaly detection\\b\",\n",
    "        r\"\\bclinical data exploration\\b\"\n",
    "    ],\n",
    "    \"AI Agents\": [\n",
    "        r\"\\b(ai|intelligent) agent(s)?\\b\",\n",
    "        r\"\\bautonomous ai system(s)?\\b\",\n",
    "        r\"\\bvirtual (assistant|agent|companion)\\b\",\n",
    "        r\"\\bdigital health agent(s)?\\b\",\n",
    "        r\"\\binteractive ai system(s)?\\b\",\n",
    "        r\"\\bconversational ai\\b\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# === Download and Save PDF Text ===\n",
    "def save_pdf_text_from_url(url, filename):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "            \"Accept\": \"application/pdf\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "            \"Referer\": \"https://www.education.nh.gov/\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(\"temp.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        reader = PdfReader(\"temp.pdf\")\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "\n",
    "        os.remove(\"temp.pdf\")\n",
    "\n",
    "        text_path = os.path.join(TEXT_DIR, filename)\n",
    "        with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "        return text_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading or reading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# === Classify a Text File ===\n",
    "def classify_text_file(text_path):\n",
    "    try:\n",
    "        with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read().lower()\n",
    "        matched = []\n",
    "        for category, patterns in category_keywords.items():\n",
    "            if any(re.search(p, text) for p in patterns):\n",
    "                matched.append(category)\n",
    "        return \", \".join(matched) if matched else \"None\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading text file {text_path}: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# === Main Processing Function ===\n",
    "def process_documents(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    results = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row[\"PDF Link\"]\n",
    "        print(f\"Processing ({index + 1}/{len(df)}): {url}\")\n",
    "        filename = f\"doc_{index + 1}.txt\"\n",
    "\n",
    "        text_path = save_pdf_text_from_url(url, filename)\n",
    "        if text_path:\n",
    "            categories = classify_text_file(text_path)\n",
    "        else:\n",
    "            categories = \"Download Error\"\n",
    "\n",
    "        results.append({\"pdf_url\": url, \"categories\": categories})\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"\\nClassification complete. Results saved to {OUTPUT_PATH}\")\n",
    "\n",
    "# === Run Script ===\n",
    "if __name__ == \"__main__\":\n",
    "    process_documents(CSV_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffb4f3",
   "metadata": {},
   "source": [
    "Third pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CSV_PATH = \"/Users/winnie/Documents/GitHub/MedAI/classify_by_state/sampled_20_rows.csv\"\n",
    "OUTPUT_PATH = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories3.csv\" \n",
    "TEXT_DIR = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_texts\"\n",
    "\n",
    "# === Ensure output directory exists ===\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "\n",
    "# === Category Keywords ===\n",
    "category_keywords = {\n",
    "    \"Predictive AI\": [\n",
    "        r\"\\bpredictive model(s)?\\b\",\n",
    "        r\"\\bpredictive analytics\\b\",\n",
    "        r\"\\bpredictive algorithm(s)?\\b\",\n",
    "        r\"\\brisk prediction model(s)?\\b\",\n",
    "        r\"\\bmachine learning (for|based on) prediction\\b\",\n",
    "        r\"\\bpredicting (outcomes|disease|risk)\\b\"\n",
    "    ],\n",
    "    \"Generative AI\": [\n",
    "        r\"\\bgenerative ai\\b\",\n",
    "        r\"\\b(ai[- ]generated|ai[- ]powered generation)\\b\",\n",
    "        r\"\\blarge language model(s)?\\b\",\n",
    "        r\"\\blanguage generation\\b\",\n",
    "        r\"\\bsynthetic data generation\\b\",\n",
    "        r\"\\bgpt[- ]?[\\d]+\\b\",\n",
    "        r\"\\bchatbot(s)?\\b\",\n",
    "        r\"\\btext synthesis\\b\",\n",
    "        r\"\\bgenai\\b\"\n",
    "    ],\n",
    "    \"Prescriptive AI\": [\n",
    "        r\"\\bprescriptive analytics\\b\",\n",
    "        r\"\\btreatment recommendation system(s)?\\b\",\n",
    "        r\"\\bai[- ]based decision support\\b\",\n",
    "        r\"\\bclinical decision support system(s)?\\b\",\n",
    "        r\"\\btherapy recommendation\\b\"\n",
    "    ],\n",
    "    \"Descriptive AI\": [\n",
    "        r\"\\bdescriptive analytics\\b\",\n",
    "        r\"\\bun\\-?supervised learning\\b\",\n",
    "        r\"\\bpattern recognition\\b\",\n",
    "        r\"\\bphenotype (clustering|discovery)\\b\",\n",
    "        r\"\\banomaly detection\\b\",\n",
    "        r\"\\bclinical data exploration\\b\"\n",
    "    ],\n",
    "    \"AI Agents\": [\n",
    "        r\"\\b(ai|intelligent) agent(s)?\\b\",\n",
    "        r\"\\bautonomous ai system(s)?\\b\",\n",
    "        r\"\\bvirtual (assistant|agent|companion)\\b\",\n",
    "        r\"\\bdigital health agent(s)?\\b\",\n",
    "        r\"\\binteractive ai system(s)?\\b\",\n",
    "        r\"\\bconversational ai\\b\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a0cb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting pdf & Converting pdf to text file\n",
    "def extract_pdf_texts(csv_path, text_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row[\"PDF Link\"]\n",
    "        filename = f\"doc_{index + 1}.txt\"\n",
    "        text_path = os.path.join(text_dir, filename)\n",
    "\n",
    "        if os.path.exists(text_path):\n",
    "            print(f\"Skipping (already exists): {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Downloading and extracting: {url}\")\n",
    "        try:\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "                \"Accept\": \"application/pdf\",\n",
    "                \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "                \"Referer\": \"https://www.education.nh.gov/\"\n",
    "            }\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            with open(\"temp.pdf\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            reader = PdfReader(\"temp.pdf\")\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "\n",
    "            os.remove(\"temp.pdf\")\n",
    "\n",
    "            with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading or reading {url}: {e}\")\n",
    "\n",
    "# Classifying text files by keywords\n",
    "def classify_text_files(csv_path, text_dir, output_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    results = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row[\"PDF Link\"]\n",
    "        filename = f\"doc_{index + 1}.txt\"\n",
    "        text_path = os.path.join(text_dir, filename)\n",
    "\n",
    "        if not os.path.exists(text_path):\n",
    "            print(f\"Missing text file: {filename} — Skipping.\")\n",
    "            categories = \"Missing Text\"\n",
    "        else:\n",
    "            try:\n",
    "                with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    text = f.read().lower()\n",
    "                matched = []\n",
    "                for category, patterns in category_keywords.items():\n",
    "                    if any(re.search(p, text) for p in patterns):\n",
    "                        matched.append(category)\n",
    "                categories = \", \".join(matched) if matched else \"None\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading text file {filename}: {e}\")\n",
    "                categories = \"Read Error\"\n",
    "\n",
    "        results.append({\"pdf_url\": url, \"categories\": categories})\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Classification complete. Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a09212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping (already exists): doc_1.txt\n",
      "Skipping (already exists): doc_2.txt\n",
      "Skipping (already exists): doc_3.txt\n",
      "Skipping (already exists): doc_4.txt\n",
      "Downloading and extracting: https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf\n",
      "Error downloading or reading https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf: 404 Client Error: Not Found for url: https://www.maine.gov/dhhs/mecdc/environmental-health/plumb/documents/rules/CMR%20241%2007-1995.pdf\n",
      "Skipping (already exists): doc_6.txt\n",
      "Skipping (already exists): doc_7.txt\n",
      "Skipping (already exists): doc_8.txt\n",
      "Skipping (already exists): doc_9.txt\n",
      "Skipping (already exists): doc_10.txt\n",
      "Skipping (already exists): doc_11.txt\n",
      "Skipping (already exists): doc_12.txt\n",
      "Skipping (already exists): doc_13.txt\n",
      "Skipping (already exists): doc_14.txt\n",
      "Skipping (already exists): doc_15.txt\n",
      "Skipping (already exists): doc_16.txt\n",
      "Skipping (already exists): doc_17.txt\n",
      "Skipping (already exists): doc_18.txt\n",
      "Skipping (already exists): doc_19.txt\n",
      "Skipping (already exists): doc_20.txt\n"
     ]
    }
   ],
   "source": [
    "# Run for extracting pdfs and converting them to text files\n",
    "\n",
    "extract_pdf_texts(CSV_PATH, TEXT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c6d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing text file: doc_5.txt — Skipping.\n",
      "Classification complete. Results saved to /Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories3.csv\n"
     ]
    }
   ],
   "source": [
    "# Run for classifying the text files by keyword\n",
    "\n",
    "classify_text_files(CSV_PATH, TEXT_DIR, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c8768",
   "metadata": {},
   "source": [
    "Fourth pass with good_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630fccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CSV_PATH = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/good_docs.csv\"\n",
    "OUTPUT_PATH = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories4.csv\" \n",
    "TEXT_DIR = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/good_docs_texts\"\n",
    "\n",
    "# === Ensure output directory exists ===\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "\n",
    "# === Category Keywords ===\n",
    "category_keywords = {\n",
    "    \"Predictive AI\": [\n",
    "        r\"\\bpredictive model(s)?\\b\",\n",
    "        r\"\\bpredictive analytics\\b\",\n",
    "        r\"\\bpredictive algorithm(s)?\\b\",\n",
    "        r\"\\brisk prediction model(s)?\\b\",\n",
    "        r\"\\bmachine learning (for|based on) prediction\\b\",\n",
    "        r\"\\bmachine learning\\b\",\n",
    "        r\"\\bpredicting (outcomes|disease|risk)\\b\"\n",
    "    ],\n",
    "    \"Generative AI\": [\n",
    "        r\"\\bgenerative ai\\b\",\n",
    "        r\"\\b(ai[- ]generated|ai[- ]powered generation)\\b\",\n",
    "        r\"\\blarge language model(s)?\\b\",\n",
    "        r\"\\blanguage generation\\b\",\n",
    "        r\"\\bsynthetic data generation\\b\",\n",
    "        r\"\\bgpt[- ]?[\\d]+\\b\",\n",
    "        r\"\\bchatbot(s)?\\b\",\n",
    "        r\"\\btext synthesis\\b\",\n",
    "        r\"\\bgenai\\b\"\n",
    "    ],\n",
    "    \"Prescriptive AI\": [\n",
    "        r\"\\bprescriptive analytics\\b\",\n",
    "        r\"\\btreatment recommendation system(s)?\\b\",\n",
    "        r\"\\bai[- ]based decision support\\b\",\n",
    "        r\"\\bclinical decision support system(s)?\\b\",\n",
    "        r\"\\btherapy recommendation\\b\"\n",
    "    ],\n",
    "    \"Descriptive AI\": [\n",
    "        r\"\\bdescriptive analytics\\b\",\n",
    "        r\"\\bun\\-?supervised learning\\b\",\n",
    "        r\"\\bpattern recognition\\b\",\n",
    "        r\"\\bphenotype (clustering|discovery)\\b\",\n",
    "        r\"\\banomaly detection\\b\",\n",
    "        r\"\\bclinical data exploration\\b\"\n",
    "    ],\n",
    "    \"AI Agents\": [\n",
    "        r\"\\b(ai|intelligent) agent(s)?\\b\",\n",
    "        r\"\\bautonomous ai system(s)?\\b\",\n",
    "        r\"\\bvirtual (assistant|agent|companion)\\b\",\n",
    "        r\"\\bdigital health agent(s)?\\b\",\n",
    "        r\"\\binteractive ai system(s)?\\b\",\n",
    "        r\"\\bconversational ai\\b\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e575917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting pdf & Converting pdf to text file\n",
    "def extract_pdf_texts(csv_path, text_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row[\"PDF Link\"]\n",
    "        filename = f\"doc_{index + 1}.txt\"\n",
    "        text_path = os.path.join(text_dir, filename)\n",
    "\n",
    "        if os.path.exists(text_path):\n",
    "            print(f\"Skipping (already exists): {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Downloading and extracting: {url}\")\n",
    "        try:\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "                \"Accept\": \"application/pdf\",\n",
    "                \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "                \"Referer\": \"https://www.education.nh.gov/\"\n",
    "            }\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            with open(\"temp.pdf\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            reader = PdfReader(\"temp.pdf\")\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "\n",
    "            os.remove(\"temp.pdf\")\n",
    "\n",
    "            with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading or reading {url}: {e}\")\n",
    "\n",
    "# Classifying text files by keywords\n",
    "def classify_text_files(csv_path, text_dir, output_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    results = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row[\"PDF Link\"]\n",
    "        filename = f\"doc_{index + 1}.txt\"\n",
    "        text_path = os.path.join(text_dir, filename)\n",
    "\n",
    "        if not os.path.exists(text_path):\n",
    "            print(f\"Missing text file: {filename} — Skipping.\")\n",
    "            categories = \"Missing Text\"\n",
    "        else:\n",
    "            try:\n",
    "                with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    text = f.read().lower()\n",
    "                matched = []\n",
    "                for category, patterns in category_keywords.items():\n",
    "                    if any(re.search(p, text) for p in patterns):\n",
    "                        matched.append(category)\n",
    "                categories = \", \".join(matched) if matched else \"None\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading text file {filename}: {e}\")\n",
    "                categories = \"Read Error\"\n",
    "\n",
    "        results.append({\"pdf_url\": url, \"categories\": categories})\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Classification complete. Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45548053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting: https://www.ama-assn.org/system/files/clrpd-report-generative-ai.pdf\n",
      "Downloading and extracting: https://watech.wa.gov/sites/default/files/2024-07/Ethical%20Considerations%20in%20the%20use%20of%20Artificial%20Intelligence%20in%20Healthcare%2C%20and%20Washington%27s%20approach%20to%20Generative%20AI.pdf\n",
      "Downloading and extracting: https://www.healthit.gov/sites/default/files/jsr-17-task-002_aiforhealthandhealthcare12122017.pdf\n",
      "Downloading and extracting: https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf\n",
      "Error downloading or reading https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf: EOF marker not found\n",
      "Downloading and extracting: https://cdt.ca.gov/wp-content/uploads/2025/01/SIMM-5305-F-GenAI-Risk-Assessment-2025_0131-final.pdf\n",
      "Downloading and extracting: https://www.house.texas.gov/pdfs/committees/reports/interim/88interim/House-Select-Committee-on-Artificial-Intelligence-and-Emerging-Technologies-Interim-Report-2024.pdf\n",
      "Downloading and extracting: https://www.healthit.gov/sites/default/files/facas/2023-05-03_Decision_Support_Interventions_%28DSI%29_and_Predictive_Models_Group_2_Full.pdf\n",
      "Downloading and extracting: https://www.whitehouse.gov/wp-content/uploads/2023/11/AI-in-Government-Memo-draft-for-public-review.pdf\n"
     ]
    }
   ],
   "source": [
    "# Run for extracting pdfs and converting them to text files\n",
    "\n",
    "extract_pdf_texts(CSV_PATH, TEXT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6e8a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing text file: doc_4.txt — Skipping.\n",
      "Classification complete. Results saved to /Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/pdf_ai_categories4.csv\n"
     ]
    }
   ],
   "source": [
    "# Run for classifying the text files by keyword\n",
    "\n",
    "classify_text_files(CSV_PATH, TEXT_DIR, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
