{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499448fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text file pre-processing function\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_pdf_text(text):\n",
    "    # Step 1: Remove page numbers (assuming they appear on a line by themselves)\n",
    "    text = re.sub(r'\\n\\d+\\n', '\\n', text)\n",
    "\n",
    "    # Step 2: Remove common headers and footers (heuristic)\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if len(line.strip()) < 3:  # Skip short lines (e.g., single letters or digits)\n",
    "            continue\n",
    "        if re.match(r'^(Page|PAGE)\\s*\\d+', line.strip()):  # Page indicators\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    text = '\\n'.join(cleaned_lines)\n",
    "\n",
    "    # Step 3: Fix hyphenated line breaks (e.g., \"inter-\\nview\" → \"interview\")\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "    # Step 4: Merge lines that are artificially split (end of line not a sentence end)\n",
    "    # First, normalize line endings\n",
    "    text = re.sub(r'\\r\\n?', '\\n', text)\n",
    "\n",
    "    # Then merge lines that are not paragraph breaks\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)  # convert single line breaks to spaces\n",
    "\n",
    "    # Step 5: Normalize multiple newlines (paragraph breaks)\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "\n",
    "    # Step 6: Normalize whitespace\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)  # collapse tabs and spaces\n",
    "    text = re.sub(r' +\\n', '\\n', text)   # trim trailing spaces on lines\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5facf4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking the document function\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def chunk_text(text, chunk_size=100, overlap=15):\n",
    "    encoding = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        decoded = encoding.decode(chunk)\n",
    "        chunks.append(decoded)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e36b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category definitions\n",
    "\n",
    "categories = {\n",
    "    \"Clinical Decision Support\": (\n",
    "        \"Artificial intelligence systems that assist healthcare providers in clinical decision-making by analyzing patient data to generate diagnostic suggestions, treatment recommendations, and personalized care plans. These tools may use rules-based logic, machine learning, or probabilistic reasoning to help clinicians make timely and evidence-based decisions, especially in complex or high-risk scenarios.\"\n",
    "    ),\n",
    "\n",
    "    \"Clinical Documentation AI\": (\n",
    "        \"AI applications that streamline or automate the creation, management, or structuring of clinical documentation. This includes generating summary reports, transcribing and organizing clinical notes, auto-completing documentation during consultations, and extracting structured data from free-text clinical narratives. These systems reduce administrative burden, improve documentation quality, and integrate with electronic health records (EHRs).\"\n",
    "    ),\n",
    "\n",
    "    \"Medical Imaging AI\": (\n",
    "        \"AI tools used to interpret, analyze, or enhance medical imaging data such as radiology scans, pathology slides, and ophthalmology images. These systems may perform tasks like detecting abnormalities (e.g., tumors, fractures), segmenting anatomical structures, quantifying lesions, or prioritizing imaging workflows. Techniques include convolutional neural networks (CNNs), image classification, and computer vision-based diagnostics.\"\n",
    "    ),\n",
    "\n",
    "    \"Predictive Analytics\": (\n",
    "        \"AI models that analyze historical and real-time clinical data to forecast future patient outcomes. These models are used for risk stratification, early warning systems, prediction of readmission or mortality, and estimating treatment effectiveness. Common data inputs include vitals, labs, medications, demographics, and medical history. Techniques may include regression, time-series analysis, and deep learning.\"\n",
    "    ),\n",
    "\n",
    "    \"Operational and Administrative Automation\": (\n",
    "        \"AI systems designed to optimize hospital operations and administrative workflows. This includes automating scheduling, resource allocation, billing, claims management, supply chain logistics, and staff workflow optimization. These systems improve efficiency, reduce human error, and enhance the management of hospital throughput and resources using algorithms and machine learning.\"\n",
    "    ),\n",
    "\n",
    "    \"Patient-facing AI\": (\n",
    "        \"AI applications that interact directly with patients to support health monitoring, self-care, education, or triage. These include chatbots and virtual assistants, symptom checkers, wearable device integrations, and remote monitoring platforms. They provide personalized guidance, collect patient-reported outcomes, and may flag concerning symptoms for provider review.\"\n",
    "    ),\n",
    "\n",
    "    \"Robotics and Surgical AI\": (\n",
    "        \"AI systems integrated into robotic platforms used in surgical or interventional procedures. These include robotic-assisted surgery systems for enhanced precision, AI-guided tools for minimally invasive techniques, and rehabilitation robotics used post-operatively. These systems combine real-time sensing, motion control, and decision support to improve surgical outcomes and reduce human error.\"\n",
    "    ),\n",
    "\n",
    "    \"Education and Training AI\": (\n",
    "        \"AI tools used in healthcare education and workforce development. This includes virtual patient simulations, intelligent tutoring systems, curriculum personalization tools, and performance analytics for medical trainees. These systems aim to enhance clinical reasoning skills, procedural knowledge, and continuing education using adaptive learning and natural language processing.\"\n",
    "    ),\n",
    "\n",
    "    \"Research and Clinical Trial AI\": (\n",
    "        \"AI platforms that support biomedical research and clinical trial operations. These tools assist with patient cohort identification, trial design optimization, natural language processing of scientific literature, data analysis, and drug discovery. They help accelerate evidence generation, hypothesis testing, and treatment development in both pre-clinical and clinical phases.\"\n",
    "    ),\n",
    "\n",
    "    \"Public Health AI\": (\n",
    "        \"AI systems used to analyze population-level health data to support public health policy and intervention. Applications include epidemiological modeling, outbreak detection, surveillance of disease trends, analysis of social determinants of health, and health equity analysis. These tools support proactive, data-driven public health strategies and real-time monitoring.\"\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5cc58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category examples\n",
    "\n",
    "category_examples = {\n",
    "    \"Clinical Decision Support\": [\n",
    "        \"Once validated, its use can be envisioned in a wide range of scenarios, including decision support in existing practice.\",\n",
    "        \"Transparently disclose the use of GenAI and its role in decision making.\",\n",
    "        \"AI suggests treatment plans for a patient based on medical history.\",\n",
    "        \"Computerized clinical decision support systems (CCDSSs) provide patient-specific assessments or recommendations to clinicians to aid clinical decision making.\",\n",
    "        \"Some systems suggest diagnostic tests, while others suggest treatments or preventative measures, but these should be carefully evaluated by the healthcare professional before usage.\"\n",
    "    ],\n",
    "\n",
    "    \"Clinical Documentation AI\": [\n",
    "        \"Electronic health record systems should integrate artificial intelligence to increase efficiency in simple documentation, allowing healthcare professionals to spend more time attending to patient needs.\",\n",
    "        \"Generative AI usage for patient visit summaries should be approached with caution, due to risks of inaccurate information communication.\",\n",
    "        \"GenAI-enabled clinical documentation tools assist in creating encounter summaries, generating draft notes, and extracting structured data from conversations.\"\n",
    "    ],\n",
    "\n",
    "    \"Medical Imaging AI\": [\n",
    "        \"Recently a transformational advance in automated retinal image analysis, using Deep Learning algorithms, has been demonstrated.\",\n",
    "        \"Some CCDSSs include radiographic image interpretation tools that help clinicians identify abnormalities.\",\n",
    "        \"Experts recommend using AI-assisted image analysis systems as a first consultation, deferring back to the radiologist for confirmation.\",\n",
    "        \"Although traditional ML-based approaches dominate imaging, emerging GenAI models show promise in tasks such as image synthesis and labeling.\"\n",
    "    ],\n",
    "\n",
    "    \"Predictive Analytics\": [\n",
    "        \"A model trained to predict the likelihood of death from pneumonia assigned lower risk to patients with asthma, but only because such patients were treated as higher priority by the hospital.\",\n",
    "        \"CCDSSs may calculate risk scores for conditions such as cardiovascular disease or osteoporosis, helping identify high-risk patients.\",\n",
    "        \"Risk prediction tools integrate patient data to estimate the probability of future adverse health events.\"\n",
    "    ],\n",
    "\n",
    "    \"Operational and Administrative Automation\": [\n",
    "        \"AI software has been integrated into the organizational infrastructure of our hospital operations.\",\n",
    "        \"Using AI, hospital workers' shift scheduling can be automated to reduce secretarial burdens.\",\n",
    "        \"GenAI applications in administrative tasks include automating prior authorizations and summarizing payer policies.\"\n",
    "    ],\n",
    "\n",
    "    \"Patient-facing AI\": [\n",
    "        \"Kardia Mobile uses a finger pad and a smartphone app to record an EKG. The platform claims to use AI-enabled detection of atrial fibrillation.\",\n",
    "        \"CloudUPDRS, an AI algorithm differentiates between actual tremors and bad data, enabling Parkinson's patients to perform in-home testing.\",\n",
    "        \"There is a proliferation of companies developing apps that offer online doctors' appointments. Babylon claims to use an AI algorithm to automatically triage patients virtually.\",\n",
    "        \"Chatbots powered by generative AI can respond to patient queries, schedule appointments, and assist in medication adherence.\",\n",
    "        \"Concerns regarding the lack of verification in patient-facing AI tools suggest mitigation of such software in high-stakes situations.\"\n",
    "    ],\n",
    "\n",
    "    \"Robotics and Surgical AI\": [\n",
    "        \"AI-integrated surgical machines can help increase the precision in difficult medical procedures.\",\n",
    "        \"In post-op physical therapy sessions, machines integrated with a patient's progress and data can help provide the appropriate training.\",\n",
    "        \"If the AI pacemaker fails, the responsibility to which this falls upon remains ambiguous.\"\n",
    "    ],\n",
    "\n",
    "    \"Education and Training AI\": [\n",
    "        \"All work completed by medical students should be conducted without the usage of artifical intelligence.\",\n",
    "        \"GenAI has potential in medical training, for example, simulating patient interactions or generating test questions tailored to learning goals.\",\n",
    "        \"Hospitals should integrate AI into staff trainings because it provides a customized experience.\"\n",
    "    ],\n",
    "\n",
    "    \"Research and Clinical Trial AI\": [\n",
    "        \"We need your help to take personalized medicine to its full potential, and develop a Machine Learning algorithm that automatically classifies genetic variations.\",\n",
    "        \"It may support clinical trial design by generating hypotheses, summarizing relevant literature, or analyzing eligibility criteria from EHR data.\",\n",
    "        \"Using artificial intelligence in research raises concerns about fake data, which can have lasting implications on medical practices if not verified.\"\n",
    "    ],\n",
    "\n",
    "    \"Public Health AI\": [\n",
    "        \"Support the development of wearable devices for the sensing of environmental toxins and broad-based pathogen sensing for rural and urban environments. The collected data can inform policies for mitigating risks of pandemics and epidemics.\",\n",
    "        \"Providing access to data captured by mHealth apps and devices could enhance the research community's ability to build more insights into public health through AI.\",\n",
    "        \"GenAI could aid public health monitoring by extracting trends from social media, news sources, or reports, enhancing situational awareness.\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d04ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI setup\n",
    "\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load from .env file\n",
    "\n",
    "AZURE_ENDPOINT = os.getenv(\"AZURE_ENDPOINT_embeddings\")\n",
    "AZURE_API_KEY = os.getenv(\"AZURE_API_KEY_embeddings\")\n",
    "AZURE_API_VERSION = \"2025-04-01-preview\"\n",
    "\n",
    "openai = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    api_key=AZURE_API_KEY,\n",
    "    api_version=AZURE_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff0188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding function\n",
    "\n",
    "def get_embedding(text: str, model=\"embedding3large\"):\n",
    "    response = openai.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ecf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create category def+ex embeddings (so output is just one embedding per category)\n",
    "# just do one time\n",
    "\n",
    "category_all_embeddings = {}\n",
    "\n",
    "for label in categories:\n",
    "    combined_text = categories[label] + \" \" + \" \".join(category_examples.get(label, []))\n",
    "    category_all_embeddings[label] = get_embedding(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621b9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity and comparison functions\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def classify_with_combined_embeddings(chunk_embeddings, category_all_embeddings, threshold):\n",
    "    classification = defaultdict(list)\n",
    "\n",
    "    for idx, text, chunk_embedding in chunk_embeddings:\n",
    "        for category, cat_embedding in category_all_embeddings.items():\n",
    "            sim = cosine_similarity(chunk_embedding, cat_embedding)\n",
    "            if sim >= threshold:\n",
    "                classification[category].append((idx, sim, text))\n",
    "    return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f7b9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute document-level similarity function\n",
    "\n",
    "def compute_document_level_similarity(results, category_all_embeddings, threshold=0.6):\n",
    "    document_scores = {}\n",
    "\n",
    "    for category, matches in results.items():\n",
    "        if matches:\n",
    "            # Average cosine similarity of all matched chunks in this category\n",
    "            sims = [sim for _, sim, _ in matches]\n",
    "            avg_sim = sum(sims) / len(sims)\n",
    "            document_scores[category] = avg_sim\n",
    "        else:\n",
    "            document_scores[category] = 0.0  # No matches → 0 similarity\n",
    "\n",
    "    # Filter categories above threshold\n",
    "    classified_categories = {\n",
    "        category: score\n",
    "        for category, score in document_scores.items()\n",
    "        if score >= threshold\n",
    "    }\n",
    "\n",
    "    return document_scores, classified_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fe63475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Download Error] Could not download https://prod.drupal.gaotest.org/assets/gao-21-7sp.pdf: 403 Client Error: Forbidden for url: https://www.gao.gov/assets/gao-21-7sp.pdf\n",
      "[Skip] PDF not found or unreadable: https://prod.drupal.gaotest.org/assets/gao-21-7sp.pdf\n",
      "[Download Error] Could not download https://jtc1info.org/wp-content/uploads/2023/12/Overview_of_ISO_IEC_workshop_Wael.pdf: HTTPSConnectionPool(host='jtc1info.org', port=443): Max retries exceeded with url: /wp-content/uploads/2023/12/Overview_of_ISO_IEC_workshop_Wael.pdf (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe771220be0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "[Skip] PDF not found or unreadable: https://jtc1info.org/wp-content/uploads/2023/12/Overview_of_ISO_IEC_workshop_Wael.pdf\n",
      "[Download Error] Could not download https://www.medrxiv.org/content/10.1101/2024.10.23.24315991v1.full.pdf: HTTPSConnectionPool(host='www.medrxiv.org', port=443): Max retries exceeded with url: /content/10.1101/2024.10.23.24315991v1.full.pdf (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fe7712d7460>, 'Connection to www.medrxiv.org timed out. (connect timeout=15)'))\n",
      "[Skip] PDF not found or unreadable: https://www.medrxiv.org/content/10.1101/2024.10.23.24315991v1.full.pdf\n",
      "✅ Batch classification complete. Results saved to AI_appl_results_10.csv\n",
      "Appended 3 new failed links to /Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/AI_appl_failed_docs_10.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "import requests\n",
    "from error_handling import save_failed_docs\n",
    "\n",
    "# Extract text from PDF (returns text instead of saving to file)\n",
    "def pdf_to_text(pdf_path):\n",
    "    import fitz  # PyMuPDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "# Download PDF if link is a URL, with User-Agent header and error handling\n",
    "def get_pdf_path(link):\n",
    "    if link.startswith(\"http\"):\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(link, headers=headers, timeout=15)\n",
    "            response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
    "            tmp.write(response.content)\n",
    "            tmp.close()\n",
    "            return tmp.name\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"[Download Error] Could not download {link}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return link  # assume local path\n",
    "\n",
    "# Read CSV\n",
    "csv_path = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/FINAL_dataset_10.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "results_list = []\n",
    "failed_links = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    pdf_link = row[\"URL\"]\n",
    "    pdf_path = get_pdf_path(pdf_link)\n",
    "    if not pdf_path or not os.path.exists(pdf_path):\n",
    "        print(f\"[Skip] PDF not found or unreadable: {pdf_link}\")\n",
    "        failed_links.append(pdf_link)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Extract and preprocess text\n",
    "        raw_text = pdf_to_text(pdf_path)\n",
    "        clean_text = preprocess_pdf_text(raw_text)\n",
    "        chunks = chunk_text(clean_text)\n",
    "\n",
    "        # Embedding and classification\n",
    "        chunk_embeddings = [(i, chunk, get_embedding(chunk)) for i, chunk in enumerate(chunks)]\n",
    "        results = classify_with_combined_embeddings(chunk_embeddings, category_all_embeddings, threshold=0.6)\n",
    "        document_scores, classified_categories = compute_document_level_similarity(results, category_all_embeddings, threshold=0.6)\n",
    "\n",
    "        # Store results\n",
    "        results_list.append({\n",
    "            \"URL\": pdf_link,\n",
    "            \"AI Applications\": list(classified_categories.keys()),\n",
    "            \"Similarity Scores\": document_scores\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Processing Error] Could not process {pdf_link}: {e}\")\n",
    "        failed_links.append(pdf_link)\n",
    "\n",
    "    finally:\n",
    "        # Clean up temp file if downloaded\n",
    "        if pdf_link.startswith(\"http\") and pdf_path and os.path.exists(pdf_path):\n",
    "            os.remove(pdf_path)\n",
    "\n",
    "# Save results to DataFrame/CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"AI_appl_results_10.csv\", index=False)\n",
    "print(\"✅ Batch classification complete. Results saved to AI_appl_results_10.csv\")\n",
    "\n",
    "# Save failed links at the end\n",
    "save_failed_docs(\n",
    "    failed_links,\n",
    "    output_dir=\"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type\",\n",
    "    filename=\"AI_appl_failed_docs_10.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b66ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSV to JSON\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(csv_file_path, json_file_path):\n",
    "    # Read the CSV and add data to a dictionary\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        data = list(reader)\n",
    "\n",
    "    # Write the JSON file\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "csv_to_json('/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/batch_classification4_results.csv', '/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/batch_classification4_results.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "311bc6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch classification complete. Results saved to AI_appl_results_12_for_prev_failed.csv\n",
      "No failed documents to save.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import requests\n",
    "from error_handling import save_failed_docs\n",
    "\n",
    "\n",
    "# Extract text from PDF (returns text instead of saving to file)\n",
    "def pdf_to_text(pdf_path):\n",
    "    import fitz  # PyMuPDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "# List of local PDF paths (update this list with your actual file paths)\n",
    "pdf_folder = \"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type/prev_failed_docs\"  # <-- update this path\n",
    "pdf_files = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder) if f.lower().endswith('.pdf')]\n",
    "\n",
    "results_list = []\n",
    "failed_links = []\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    pdf_link = pdf_path  # Use the local path as the 'URL' field\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"[Skip] PDF not found: {pdf_link}\")\n",
    "        failed_links.append(pdf_link)\n",
    "        continue\n",
    "    try:\n",
    "        # Extract and preprocess text\n",
    "        raw_text = pdf_to_text(pdf_path)\n",
    "        clean_text = preprocess_pdf_text(raw_text)\n",
    "        chunks = chunk_text(clean_text)\n",
    "\n",
    "        # Embedding and classification\n",
    "        chunk_embeddings = [(i, chunk, get_embedding(chunk)) for i, chunk in enumerate(chunks)]\n",
    "        results = classify_with_combined_embeddings(chunk_embeddings, category_all_embeddings, threshold=0.6)\n",
    "        document_scores, classified_categories = compute_document_level_similarity(results, category_all_embeddings, threshold=0.6)\n",
    "\n",
    "        # Store results\n",
    "        results_list.append({\n",
    "            \"URL\": pdf_link,\n",
    "            \"AI Applications\": list(classified_categories.keys()),\n",
    "            \"Similarity Scores\": document_scores\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"[Processing Error] Could not process {pdf_link}: {e}\")\n",
    "        failed_links.append(pdf_link)\n",
    "\n",
    "# Save results to DataFrame/CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"AI_appl_results_12_for_prev_failed.csv\", index=False)\n",
    "print(\"✅ Batch classification complete. Results saved to AI_appl_results_12_for_prev_failed.csv\")\n",
    "\n",
    "# Save failed links at the end\n",
    "save_failed_docs(\n",
    "    failed_links,\n",
    "    output_dir=\"/Users/winnie/Documents/GitHub/MedAI/Analysis&NLP/classify_by_AI_type\",\n",
    "    filename=\"AI_appl_failed_docs_12.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
