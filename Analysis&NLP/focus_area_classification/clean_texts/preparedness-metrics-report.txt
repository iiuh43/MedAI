Measuring Preparedness for Public  Health and Health Care Emergencies   The Current State of Preparedness Metrics in the United  States and Considerations for the Future       Report submitted August 30, 2024    Submitted to:  Allison Kolbe  Office of the Assistant Secretary for Planning and Evaluation (ASPE)  U.S. Department of Health and Human Services  200 Independence Ave. S.W.  Washington, DC 20201  Work performed under:  Contract No. HHSP233201500035I, Task Order No. 75P00122F37070  Disclaimer  This research was performed by Mathematica. The findings and conclusions of this research are those of  the authors and do not necessarily represent the views of ASPE or the U.S. Department of Health and  Human Services (HHS). Links and references to information from non-governmental organizations are  provided for informational purposes and are not an HHS endorsement, recommendation, or preference  for the non-governmental organizations.  Authors  Katie Morrison Lee, MPP, Sue Felt-Lisk, MPA, Camille Veri, MPA, Sheila Hoag, MA, Emily Crabtree, MPH  Acknowledgments   The authors wish to thank the Technical Expert Panel members (Appendix D) for their valuable  contributions to this work, as well as Chris Palo, Effie Metropoulos, Jill Miller, Dorothy Bellow, and Sheryl  Friedlander at Mathematica. We would also like to acknowledge the following individuals:    Kevin Yeskey, MD, MDB Inc.  Nicholas Cagliuso, PhD, MPH, MDB Inc.  Allison Kolbe, PhD, ASPE  Deborah Porterfield, MD, MPH, ASPE  Contract Officer’s Representative, Marsha Clarke, PhD, ASPE  Kim Nguyen, DVM, MPH, ASPE  Kathleen Miller PhD, MS, ASPE  Laurin Grabowsky, MSc, ASPE  Jessica White, MPP, ASPE    Contents  Mathematica® Inc.  ii    Contents  Executive Summary .......................................................................................................................................................................................... v  A.  Background .................................................................................................................................................................................... v  B.  The current state of public health and health care preparedness metrics in the United States ................. v  C.  Strategies to improve measurement of public health and health care preparedness ................................. viii  I.  Introduction .............................................................................................................................................................................................. 1  II.  The Current State of Public Health and Health Care Preparedness Metrics in the United States ......................... 5  A.  What public health and health care preparedness tools are currently available in the United  States? ............................................................................................................................................................................................... 6  B.  What are the gaps in existing public health and health care preparedness metrics? .................................. 16  C.  What lessons learned from the COVID-19 pandemic can inform measurement of emergency  preparedness and response at STLT public health agencies in the future? ...................................................... 22  III.  Strategies to Improve Measurement of Public Health and Health Care Preparedness .......................................... 24  A.  What key attributes should new public health and health care preparedness measures have,  and what gaps would they address? ................................................................................................................................. 24  B.  What strategies could potentially be explored to improve measurement of public health and  health care preparedness? .................................................................................................................................................... 27  C.  Discussion .................................................................................................................................................................................... 35  References ......................................................................................................................................................................................................... 36  Appendix A. Methods .................................................................................................................................................................................. A.1  Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care  Preparedness in the United States............................................................................................................................... B.1  Appendix C. Summary of Literature Assessing the Extent to Which Preparedness Indices Predicted  Outcomes During the COVID-19 Pandemic ............................................................................................................ C.1  Appendix D. Technical Expert Panel Participants ............................................................................................................................ D.1  Appendix E. Technical Expert Panel Agenda ...................................................................................................................................... E.1    Exhibits  Mathematica® Inc.  iii  Exhibits    Exhibit ES.1. List and description of tools to assess STLT public health and healthcare preparedness ........................ vi  Exhibit ES.2. Summary of key characteristics of existing public health and health care preparedness  metrics and their gaps and limitations .................................................................................................................................. vi  Exhibit ES.3. Four strategies that could potentially advance preparedness measurement, and potential  follow-up efforts for consideration ....................................................................................................................................... viii  Exhibit I.1. What is public health and health care preparedness? ................................................................................................. 1  Exhibit I.2. FEMA’s National Preparedness Goal and the five phases of emergency preparedness ................................ 1  Exhibit I.3. An all-hazards approach to preparedness ........................................................................................................................ 2  Exhibit I.4. Entities that might make up a local public health emergency preparedness system ..................................... 3  Exhibit I.5. Why measure preparedness? ................................................................................................................................................. 3  Exhibit I.6. Study research questions ......................................................................................................................................................... 4  Exhibit II.1. Types of preparedness metrics ............................................................................................................................................ 5  Exhibit II.2. List and description of tools to assess STLT public health and healthcare preparedness ........................... 6  Exhibit II.3. Prominent global tools to measure national public health and health care preparedness ........................ 7  Exhibit II.4. Characteristics of sets of capabilities from FEMA, CDC, and ASPR ....................................................................... 8  Exhibit II.5. Example of national preparedness scores using national trend data on the NHSPI website .................. 11  Exhibit II.6. Examples of measures that assess various aspects of the five phases of emergency  management from select preparedness tools, including the NHSPI, COPI, HPP measure set,  and ADEPT ....................................................................................................................................................................................... 12  Exhibit II.7. Examples of tools to measure health and social vulnerability or resilience78 ................................................ 13  Exhibit II.8. Examples of tools that measure components of STLT preparedness for specific disasters ..................... 14  Exhibit II.9. Examples of data sources used to measure preparedness in existing tools, by level (state  and/or local) that the data are available ............................................................................................................................. 15  Exhibit II.10. Spotlight on the technical expert panel: Factors that are inadequately captured in existing  metrics ............................................................................................................................................................................................... 16  Exhibit II.11. Examples of metrics that quantify public trust in government ......................................................................... 19  Exhibit II.12. Local health departments’ perception of preparedness by threat ................................................................... 20  Exhibit III.1. Key attributes of preparedness measures and the gaps they addressa .......................................................... 25  Exhibit III.2. Four strategies that could potentially advance preparedness measurement ............................................... 27  Exhibits  Mathematica® Inc.  iv  Exhibit III.3. Survey instruments to measure the strength of partnerships among STLT public health  departments and their partners.............................................................................................................................................. 28  Exhibit III.4. Contextual factors affecting public health preparedness and response outcomes ................................... 29  Exhibit III.5. Potential approaches to address strategy #1, and likely resource intensity of each ................................. 29  Exhibit III.6. Example of health equity in local hazard-specific preparedness metrics: ...................................................... 31  Exhibit III.7. Potential approaches to address strategy #2 and likely resource intensity of each .................................. 32  Exhibit III.8. What is an after-action report? ........................................................................................................................................ 32  Exhibit III.9. Examples of non-public data sources that could be leveraged to improve measurement of  preparedness .................................................................................................................................................................................. 33  Exhibit III.10. Potential approaches to address strategy #3, and likely resource-intensity of each .............................. 34  Exhibit III.11. Potential approaches to address strategy #4, and likely resource-intensity of each .............................. 35  Exhibit A.1. Identification of literature via databases and supplemental searches ............................................................ A.2  Exhibit A.2. Characteristics of preparedness metrics assessed in the analysis of themes and gaps ........................... A.3    Executive Summary  Mathematica® Inc.  v  Executive Summary  A. Background  A wide range of recent domestic disasters—from wildfires to the COVID-19 pandemic—have highlighted  the challenge of preparing for large-scale public health emergencies. Inadequate preparation for these  disasters has resulted in preventable loss of life, diminished public trust in federal, state, tribal, local, and  territorial (STLT) governments, and ongoing confusion about actions needed to improve preparedness.   To help the federal government and STLT jurisdictions better prepare for emergencies, there is a need to  understand how prepared different jurisdictions are for various emergencies. Understanding a  jurisdiction’s level of preparedness can inform resource allocation and identify actions that the federal  government and STLT jurisdictions can take to bolster preparedness, such as developing formal response  plans, training public health and health staff, or forming contractual agreements with partner  organizations. However, assessing whether a jurisdiction is prepared for different emergencies is  inherently complex and there is a lack of consensus among practitioners and scholars on how to approach  preparedness measurement. Measurement tools introduced in recent decades have numerous limitations,  such as inconsistently defining preparedness and its goals, relying on subjective agency assessments of  the standards and capabilities that contribute to preparedness, and failing to provide an evidence base for  measures. The cross-sectoral, cross-jurisdictional nature of public health systems adds to the complexity  of preparedness measurement: because of the many agencies and organizations involved in emergency  response efforts, it is challenging to understand how performance should be measured and accountability  distributed across these partners. Further, the singularity of public health emergencies makes it difficult to  assess whether key takeaways from one disaster will apply to the next.  In response to these challenges, the U.S. Department of Health and Human Services Office of the Assistant  Secretary for Planning and Evaluation (ASPE) funded a study to address 1) the current state of metrics for  public health and health care preparedness in the United States, including gaps in existing metrics and  limitations of existing metrics identified during the COVID-19 pandemic and 2) strategies to potentially  improve measurement of public health and health care preparedness and address the gaps and  limitations in current metrics. The methods for this study include a synthesis of key findings from a  targeted environmental scan of domestic preparedness metrics and a technical expert panel (TEP) made  up of representatives from federal agencies, public health and healthcare organizations, and academic  institutions, with diverse experience in preparedness measurement and emergency response.   B. The current state of public health and health care preparedness metrics in the  United States  We conducted an environmental scan to understand tools currently available to assess STLT preparedness,  including indices, measure sets, and other instruments such as self-administered preparedness surveys.I  We identified nine tools to measure STLT emergency preparedness, including three that have also been  used to assess national preparedness in the United States (Exhibit ES.1).     I We define indices as tools that assess preparedness across a range of measures and create a composite score  summarizing a jurisdiction’s preparedness. Measure sets similarly assess preparedness across a variety of measures  but do not produce a summary statistic.   Executive Summary  Mathematica® Inc.  vi  Exhibit ES.1. List and description of tools to assess STLT public health and healthcare  preparedness  Tool  Description  Tools for internal and external stakeholders  Community Outbreak  Preparedness Index (COPI)   Assesses county-level preparedness for infectious disease outbreaks using  publicly available data  Hospital Medical Surge  Preparedness Index (HMSPI)   Evaluates the capacity of hospitals to handle patient surges during mass casualty  events, using over 120 measures from publicly available data sources  Hospital Preparedness Program  (HPP) performance measure set  Assesses preparedness of HPP funding recipients based on 22 performance  measures reported by recipients and disseminated broadly  National Health Security  Preparedness Index (NHSPI)   Generates a composite preparedness score for states, territories, and the nation  overall based on 130 measures derived from publicly available data sources  Trust for America’s Health  (TFAH) Ready or Not tool  Evaluates states’ preparedness for public health emergencies using a targeted set  of 10 measures largely derived from the NHSPI  Self-administered tools for internal use by STLT jurisdictions  Assessment for Disaster  Engagement with Partners Tool  (ADEPT)   Summarizes the frequency and nature of activities related to disaster  preparedness, response, and recovery that local health departments engage in  with community-based organizations, using a 15-item index for use by local  health departments  Connectivity Measurement Tool  Quantifies the level of connectivity of different organizations and systems  involved in public health preparedness across 28 items  Preparedness Capacity  Assessment Survey (PCAS)   Creates an aggregate score summarizing preparedness of local health  departments  Rapid Urban Health Security  Assessment (RUHSA)   Evaluates local-level health security capacities across 46 measures  We present a summary of key characteristics of these tools, as well as gaps and limitations as identified by  the literature and the TEP, in Exhibit ES.2.  Exhibit ES.2. Summary of key characteristics of existing public health and health care  preparedness metrics and their gaps and limitations  Characteristic  Summary of existing metrics and their gaps/ limitations  Purpose and  users  Tools vary in their target audience:  • Five tools are intended for internal and external stakeholders. Results from these tools are  publicly disseminated for use by a broad audience of federal and STLT policy makers, public  health and health care organizations, and the general public.   • Four tools require self-administration and are intended for internal users, such as local health  department staff and their partners.   Gaps and limitations: Tools intended for broad internal and external audiences may not feel  actionable for STLT users that face challenges interpreting and adapting scores to their local  contexts.   Executive Summary  Mathematica® Inc.  vii  Characteristic  Summary of existing metrics and their gaps/ limitations  Jurisdiction  levels  Of the nine STLT tools:   • Two tools (the NHSPI and the TFAH tool) assess preparedness at the state and territorial level;  in addition, the HPP measure set can be aggregated at the state level.  • Seven tools assess preparedness within states and territories at the local level (e.g., county, local  health department, or hospital level).  • Results from two tools—the NHSPI and HPP measure set—are routinely aggregated at the  national level to present a snapshot of national preparedness. In addition, the TFAH tool groups  states into tiers based on scores for each measure, which can be used to assess national  preparedness (for example, by assessing the number or percentage of states in the highest or  lowest performing tier for each measure to assess relative strengths and weaknesses across the  United States).  • None of the tools were adapted for tribal communities.  Gaps and limitations: There is no comprehensive all-hazards index to measure and guide local  jurisdictions’ emergency preparedness efforts. In addition, there were no preparedness tools  tailored to tribal communities.  Factors  measured   Tools vary in the breadth of factors that they measure. For example:  • The NHSPI and COPI take a comprehensive approach to measuring preparedness across the  emergency management cycle (i.e., prevention, protection, mitigation, response, and recovery)  and include “proactive” measures of preparedness that assess social vulnerability and resilience.   • Other tools are more focused on specific aspects of preparedness (for example, the HMSPI  focuses on surge capacity and the Connectivity Measurement Tool focuses on perceptions of  partnerships).  Gaps and limitations: Existing tools inadequately capture several important factors that affect  preparedness, including strength of cross-sector collaboration, individual readiness and training of  the workforce, administrative capacity, political factors, social vulnerability, and public trust.  Types of  disasters  addressed  Eight out of nine preparedness tools take an all-hazards approach to measurement, assessing  measures of preparedness applicable to a wide range of disasters.   Gaps and limitations: There is a lack of disaster-specific tools; all-hazards tools may not reliably  predict outcomes for all types of emergencies and may be challenging for STLT users to interpret.  Data sources  and availability  Four tools leverage data from nearly 100 different public sources, including national surveys,  government agencies, and associations; the other five tools are designed for self-reporting/self- administration.  Gaps and limitations: There is a lack of publicly available data at the local level. In addition, there  are limitations in the availability of timely data, with some sources being updated infrequently.  In addition to the gaps noted above, the COVID-19 pandemic exposed other weaknesses that need to be  addressed to improve emergency preparedness and preparedness measurement. For example:  / Many preparedness tools—including the NHSPI, TFAH, and other prominent global tools—were not  valid predictors of COVID-19 outcomes, such as excess mortality rates. This underscores the need to  explore ways to improve measurement within existing tools and consider whether all-hazards tools like  the NHSPI are the best way to assess preparedness for the wide range of unique emergencies that the  country is likely to face.   / A variety of critical factors that affect outcomes are not accounted for in current preparedness  measures, such as partnerships, political will, and public trust, among others. Moving forward, it will be  important to consider ways to measure these factors and incorporate them in preparedness metrics.  / The disparate impacts of the COVID-19 pandemic on socially vulnerable communities, who suffered  higher incidence of COVID-19 infections and deaths, highlight the need to embed equity in how  Executive Summary  Mathematica® Inc.  viii  jurisdictions prepare for emergencies and thus, in how we measure communities’ preparedness and  assess their vulnerabilities.   / Finally, the COVID-19 pandemic exposed significant weaknesses in the public health data and  surveillance infrastructure, as evidenced by challenges with reporting and tracking lab test results, lack  of interoperability across health and public health reporting systems, and gaps in the types of data that  are collected and tracked. Investments in data infrastructure could help improve preparedness metrics,  especially at the local level where measurement is limited by the availability of standardized, timely data.  C. Strategies to improve measurement of public health and health care  preparedness  Given the gaps and limitations in existing tools and inherent challenges in measuring preparedness, there  is an opportunity to apply lessons learned from the COVID-19 pandemic to pursue development of  improved metrics. These efforts must be rooted in an understanding of the ideal attributes of public  health preparedness measures, so that there are set criteria against which future metrics could be  evaluated. We present ten attributes in this report, informed by current public health performance  measurement literature. Then, considering these key attributes and feedback from the TEP, we outline  four strategies and examples of associated follow-up efforts that could potentially advance preparedness  measurement, summarized in Exhibit ES.3.  Exhibit ES.3. Four strategies that could potentially advance preparedness measurement, and  potential follow-up efforts for consideration  Strategies  Potential follow-up efforts  1. Address gaps in existing  metrics by developing or  refining important  measures of preparedness  and supplementing  preparedness metrics with  contextual data.  Low-intensity efforts could include:  • Advancing individual training and measurement of training by working with  professional associations.  • Evaluating existing online preparedness curricula to set a foundation for  measurement of individual preparedness.  • Exploring degree program accreditation as a tool to improve readiness of future  public health professionals and set a foundation for a national measure of  individual preparedness.  Medium-intensity efforts could include:  • Developing new trainings to fill gaps, supporting improvement on future  measurement of individual preparedness.  • Advancing measurement on the strength of essential partnerships  • Investigating contextual factors critical to response and outcomes.  High-intensity efforts could include:  • Improving measurement of administrative response capabilities and providing  support to help STLT jurisdictions overcome barriers.  • Developing a national-level measure or measures corresponding to administrative  response capability.  Executive Summary  Mathematica® Inc.  ix  Strategies  Potential follow-up efforts  2. Improve how health equity  is addressed in  preparedness metrics by  engaging underserved  communities in continuous  efforts to advance  measurement and  considering social  vulnerability data together  with preparedness  measures.  A low-intensity effort could include:  • Developing recommendations for an effective approach to present social and  health vulnerability indicators with or within preparedness indices.  A medium- to high-intensity effort (depending on the number of communities  included) could include:  • Identifying locally appropriate metrics focused on health equity to advance  equity-focused preparedness measurement in communities, such as metrics  summarizing the preparedness level of neighborhoods disproportionately  impacted by COVID-19 and at elevated risk for specific types of emergencies (for  example, flooding in a low-lying area or floodplain).  3. Improve source data and  use additional analyses to  enhance the availability,  responsiveness, and  salience of preparedness  metrics.  Low-intensity efforts could include:  • Exploring the feasibility of using artificial intelligence with After Action Reports  (AARs), to facilitate scaled up qualitative analysis to identify themes.  • Exploring stakeholder receptiveness to implementing a metadata template for  AARs, to facilitate synthesizing patterns across AARs.  • Exploring the feasibility and benefits of using non-public data sources, such as  data from the Real-World Incident Reporting and Evaluation tool or others, to  advance the evidence base for preparedness metrics.   Medium-intensity efforts could include:  • Analyzing AARs on a large scale to identify key themes.  • Facilitating improvement of AARs’ quality and availability, through an organized  peer review process and support to ensure AARs are created and shared following  all disasters.  • Undertaking research using non-public data sources to advance the evidence  base for preparedness metrics.  A high-intensity effort could include:  • Identifying and developing automated data solutions that would reduce reporting  burden.  4. Enhance actionability and  understandability of  metrics by developing and  disseminating information  on exemplars.  A low-intensity effort could include:  • Conducting a needs assessment to identify jurisdiction types, organizations, and  disaster types most in need of exemplar models, and a landscape assessment to  identify existing strong examples and find important gaps.  A medium-intensity effort could include:  • Developing case studies to fill identified needs for exemplar models and  disseminate them to relevant audiences.  Notes:  Low-intensity=likely to require one to three staff working for less than a year; high-intensity=those that involve large-scale  data collections or system changes; medium-intensity=efforts likely to fall between the low- and high-intensity ranges. Low- intensity and italicized efforts could begin when resources are available. Italicized medium and high-intensity efforts  indicate those not dependent on low-intensity efforts. Medium- and high-intensity efforts not italicized would best be  structured using results from the low-intensity efforts listed.  Implementing these strategies would require collaboration across a range of stakeholders, including  federal agencies, STLT jurisdictions, public health and health care organizations and their partners, and  researchers. In addition, these strategies would require investments that need to be considered against  the many competing priorities that public health systems face. The low-intensity efforts listed above often  set up and help structure suggested medium- and high-intensity efforts and would be good places to  start. However, several of the suggestions for medium- or high-intensity efforts could begin without  additional preliminary work as soon as resources permit; those are italicized in Exhibit ES.3. The specific  Executive Summary  Mathematica® Inc.  x  selection of where to begin depends, as a practical matter, on how managers within the relevant agencies  find the efforts well-matched with existing work, resources, and program opportunities; but even  implementing a few of the efforts listed in Exhibit ES.3 could help agencies make incremental progress.  Ultimately, the availability of better tools to measure and understand gaps in preparedness against  specific threats could inform federal and state resource allocation and help set priorities to improve  preparedness of public health and healthcare system for the next public health threat. In the hands of  strong leadership, better measurement can also catalyze and enable improvement, resulting in a better- prepared nation. Chapter I. Introduction  Mathematica® Inc.  1  I. Introduction  A wide range of recent domestic disasters have highlighted the  challenge of preparing for large-scale public health emergencies.  Since 2020, the U.S. Department of Health and Human Services  (HHS) has issued 57 declarations of new and continuing public health  emergencies for a range of crises, including infectious diseases such  as COVID-19 and monkeypox; natural disasters such as wildfires,  hurricanes, and severe storms; and the ongoing opioid epidemic.2,II  Inadequate preparation for these disasters has resulted in  preventable loss of life; diminished public trust in federal, state, tribal,  local, and territorial (STLT) governments; and ongoing confusion  about the actions needed to improve public health and health care  preparedness (Exhibit I.1).  Three federal agencies provide critical guidance and funding to help STLT jurisdictions and public  health and health care systems nationwide advance emergency preparedness. The U.S. Centers for  Disease Control and Prevention (CDC)  and the Administration for Strategic  Preparedness and Response (ASPR)  maintain sets of core capabilities that  public health and health care systems  need to achieve preparedness. In  addition, the Federal Emergency  Management Agency (FEMA) maintains  a set of 32 capabilities intended to  guide emergency preparedness  broadly at the community level,  helping to achieve FEMA's National  Preparedness Goal, organized across  five mission areas (Exhibit I.2).4  Collectively, since 2002, federal  agencies, including CDC, ASPR, and  FEMA, have distributed more than $75  billion in funding to help STLT  jurisdictions and public health system  partners prevent, prepare for, and  respond to emergencies.5,6,7     II This count includes both new public health emergency declarations and declarations that have been renewed by the  Secretary of the Department of Health and Human Services for ongoing emergencies, such as the opioid crisis and  COVID-19.   Exhibit I.1. What is public  health and health care  preparedness?  Public health and health care  preparedness is the ability of  public health and health systems,  communities, and individuals to  prevent, protect against,  mitigate, quickly respond to, and  recover from health  emergencies.1  Exhibit I.2. FEMA’s National Preparedness Goal and the five  phases of emergency preparedness  FEMA defines the National Preparedness Goal as “a secure and  resilient Nation with the capabilities required across the whole  community to prevent, protect against, mitigate, respond to, and  recover from the threats and hazards that pose the greatest risk.”    FEMA further describes five categories, or “mission areas,” needed  to support this goal: 3  1. Prevention. Ability to avoid, prevent, or stop imminent threats  Example capability: Intelligence and information sharing  2. Protection. Ability to secure the homeland against acts of  terrorism or disasters  Example capability: Supply chain integrity and security  3. Mitigation. Ability to reduce loss of life and property by  lessening the impact of disasters  Example capability: Community resilience  4. Response. Ability to save lives, protect property and the  environment, and meet basic human needs after an incident  Example capability: Public health, health care, and emergency  medical services  5. Recovery. Ability to help communities recover quickly  Example capability: Housing   Chapter I. Introduction  Mathematica® Inc.  2  Because communities face distinct hazards, public health and health care emergency preparedness  strategies vary from jurisdiction to jurisdiction. For example, a rural community in a low-lying coastal  region would necessarily prioritize different preparedness capabilities than a landlocked city prone to  tornadoes. While guidance from the CDC, ASPR, and FEMA is designed to support emergency  preparedness across a broad range of disaster types (Exhibit 1.3), these agencies also encourage routine  hazard or risk assessments to help communities understand  distinct threats they face and prioritize capabilities based on  local needs. FEMA requires government agencies to work with  stakeholders to conduct a thorough community risk assessment  every three years using the Community Threat and Hazard  Identification Risk Assessment to guide their work.9 Similarly,  CDC's Public Health Emergency Preparedness (PHEP) program  requires funded public health agencies to work with local  jurisdictions and their community partners to conduct a risk  assessment at least once every five years.10 Risk assessments are  also common at the facility (such as hospital or nursing home)  level. For example, health care facilities that participate in  Medicare or Medicaid are required to complete or update a  hazard vulnerability analysis annually to better understand risks  and prioritize activities to mitigate, respond to, and recover from  these risks.11   Preparing for emergencies requires planning and collaboration across a multitude of public and  private sector partners that play distinct roles in public health and health care emergency response.  For example, CDC’s public health preparedness and response capability standards include STLT public  health departments, health clinics, ambulatory care providers, fire departments, law enforcement agencies,  public works, and other partners as contributors to medical surge capabilities; first responders,  epidemiologists, environmental health agencies, clinical laboratories, and other partners as contributors to  laboratory testing capabilities; and social service agencies, schools, community coalitions, mental health  providers, housing programs, and other partners as contributors to community recovery capabilities.12  Similarly, ASPR’s Health Care Preparedness and Response Capabilities are designed for multisector health  care coalitions (HCCs) consisting of public health agencies, hospitals, emergency medical services, and  emergency management organizations located in a defined geographic location.13   The landscape of organizations that make up the public health system and contribute to public  health and health care preparedness is varied and complex. Exhibit I.4 presents the broad network of  partners involved in emergency preparedness and response. Partners range from health clinics and  emergency medical services (EMS) that provide direct health care services, to employers and schools that  play key roles in ensuring safe workplaces and learning environments, such as encouraging testing and  vaccination, as many employers and organizations did during the COVID-19 pandemic.    Exhibit I.3. An all-hazards  approach to preparedness  The capabilities advanced by CDC,  ASPR, and FEMA are designed to be  adaptable across all hazard types:  natural disasters; infectious disease  outbreaks; terrorist attacks;  cybersecurity attacks; and chemical,  biological, radiological, or nuclear  incidents. This all-hazards approach to  preparedness recognizes that “while  hazards vary in source (natural,  technological, societal), they often  challenge health systems in similar  ways and demand a multisectoral  response.”8  Chapter I. Introduction  Mathematica® Inc.  3  Exhibit I.4. Entities that might make up a local public health emergency preparedness system     Image adapted from NACCHO, “Local Assessment Instrument.” National Association of City and County Health  Officials, 2013.  Assessing whether a jurisdiction is prepared for  different emergencies is inherently complex,  and there is a lack of consensus among  practitioners and scholars on how to measure  preparedness. Despite the promise and potential  of preparedness measurement (Exhibit 1.5), tools  introduced in recent decades have numerous  limitations: inconsistently defining preparedness  and its goals, relying on subjective agency  assessments of the standards and capabilities that  contribute to preparedness, and failing to provide  an evidence base for measures.15,16,17 The cross- sectoral, cross-jurisdictional nature of public health  systems adds to the complexity of preparedness  measurement; because of the many agencies and  organizations involved in emergency response, it is  challenging to understand how performance  should be measured and accountability distributed  across these partners.18 The singularity of public  health emergencies is a central challenge. Because    Exhibit I.5. Why measure preparedness?  Measuring preparedness can provide a powerful  decision-making tool to guide strategies to ensure a  community of any size is ready for an emergency.  Stoto and Nelson14 present three core aims of  preparedness measurement:   1. Accountability. Measures can help hold leaders  and public health system partners accountable  for their investments in preparedness by allowing  them to assess preparedness relative to set  standards or benchmarks.  2. Systems improvement. Measures can highlight  where weaknesses and gaps exist across the  public health system, driving quality  improvement efforts.  3. Research and knowledge sharing. Over time, as  measures are tested and refined, they can help  build evidence on “what works” when preparing  for emergencies, which is key to informing the  study of public health preparedness.   Chapter I. Introduction  Mathematica® Inc.  4  each disaster is unique, it is difficult to assess whether key takeaways from one disaster will apply to the  next.19  The COVID-19 pandemic exposed flaws in U.S. emergency response systems, demonstrating the  urgent need for more reliable, evidence-based preparedness measures. Public health and health care  systems faced extraordinary pressures, from staffing a qualified workforce to meeting surging demand for  medical care to addressing the stark health inequities that persisted across communities. Given the  significance of the pandemic and its lasting impact, a close examination of current approaches to  preparedness measurement, including key drivers of preparedness that may have been overlooked, is  essential to inform readiness for infectious disease outbreaks and other potential disasters.  In response to the issues outlined above, HHS’s Office of the Assistant Secretary for Planning and  Evaluation (ASPE) funded this study, designed to draw lessons from the COVID-19 pandemic to  inform efforts to measure preparedness going forward. The study included a targeted environmental  scan of domestic preparedness metrics and a technical expert panel (TEP)—made up of representatives  from federal agencies, public health and health care organizations, and academic institutions—with  diverse experience in preparedness measurement and emergency response.  This report gives a comprehensive overview of the current landscape of preparedness measurement tools  and suggests areas for improvement, exploring why current efforts to measure preparedness have failed  to predict effective responses in real-world settings. In addition, to inform future measurement efforts, it  reveals key criteria that preparedness metrics should meet and highlights strategies that could potentially  advance measurement to meet these criteria and address the gaps found in current metrics of public  health and health care preparedness.   The research questions in Exhibit I.6 guided this work. Questions 1–3 focus on current measures and are  addressed in Chapter II; Questions 4 and 5 look to the future of public health preparedness measurement  and are addressed in Chapter III. In addition, Appendix A describes the study methods, Appendix B  describes existing tools to measure STLT emergency preparedness, Appendix C summarizes literature  assessing how well preparedness indices predicted outcomes during the COVID-19 pandemic, Appendix D  lists the TEP participants, and Appendix E provides the agenda for the TEP.    Exhibit I.6. Study research questions  1. What public health and health care preparedness tools are currently available in the United States? (Chapter II)  2. What are the gaps in existing public health and health care preparedness metrics? (Chapter II)  3. What lessons learned from the COVID-19 pandemic can inform measurement of emergency preparedness and  response at STLT public health agencies in the future? (Chapter II)  4. What attributes should public health and health care preparedness metrics have, and what gaps would these  attributes address? (Chapter III)  5. What strategies should potentially be explored to improve measurement of public health and health care  preparedness? (Chapter III)  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  5  II. The Current State of Public Health and Health Care Preparedness  Metrics in the United States  The nation’s response to the COVID-19 pandemic provides an opportunity to better understand  how to improve public health and medical response to all types of disasters, including infectious  disease outbreaks, cybersecurity threats, and other emergencies. To seize this opportunity, we drew  on findings from the environmental scan and TEP to address the following research questions, which are  the basis of this chapter’s structure:  1. What metrics on public health and health care preparedness are currently available in the United  States?  2. What are the gaps in existing public health and  health care preparedness metrics?  3. What lessons learned from the COVID-19  pandemic can inform measurement of  emergency preparedness and response at STLT  public health agencies in the future?  Unless otherwise noted, this chapter focuses on  tools that quantify preparedness in the United  States across multiple phases of the emergency  management cycle (that is, prevention,  protection, mitigation, response, and recovery).  We define preparedness tools as indices, measure  sets, and other instruments (such as self- administered surveys) that are designed to quantify  how prepared public health and health care  systems are to respond to and recover from  emergencies and disasters across multiple  measures (Exhibit II.1). Exhibit II.2 and Appendix B  summarize the existing STLT preparedness tools  and serve as the foundation for the chapter. Given  the study’s focus on preparedness metrics in the United States, Exhibit II.2 and Appendix B exclude: (1)  global tools used to measure preparedness in other countries or to measure nation-level preparedness  (for example, the Global Health Security Index); (2) tools that focus on a single phase or aspect of the  emergency management cycle (for example, resilience or vulnerability indices); (3) tools that assess but do  not quantify preparedness (for example, FEMA’s Community Threat and Hazard Identification and Risk  Assessment, which describes a process communities can use to understand their risks and capabilities);  and (4) tools that are not publicly accessible because they protected from disclosure under the Protected  Exhibit II.1. Types of preparedness metrics  This chapter covers three types of metrics used to  assess public health and health care emergency  preparedness:  •  Measures quantify specific aspects of emergency  preparedness and response, such as whether a  state has written disaster plans for long-term  care and nursing facilities, or the percentage of  adults receiving a seasonal flu vaccine.   •  Indices create a composite statistic or score by  collecting and aggregating data from multiple  measures, helping audiences easily compare  jurisdictions along various dimensions of  emergency preparedness.   •  Measure sets are lists of measures to help users  quantify preparedness along various dimensions.  Unlike indices, measure sets do not produce a  composite score.  We use the term preparedness tools to describe  indices and measure sets that assess preparedness  across multiple measures.   Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  6  Critical Infrastructure Information Program (for example, Cybersecurity & Infrastructure Security Agency’s  Infrastructure Survey Tool). III  A. What public health and health care preparedness tools are currently available  in the United States?  In this section, we describe the tools that are currently available to assess STLT preparedness across  multiple phases of the emergency management cycle. We focus on the following characteristics:  / The number and types of tools  / The tools’ purpose and intended users  / The jurisdiction levels the tools apply to   / How existing tools conceptualize preparedness  / The types of disasters the tools address  / Sources of data used to quantify preparedness in the tools  1.  Number and types of available tools  There are relatively few tools designed to measure STLT public health and health care preparedness  in the United States. The environmental scan found just nine preparedness tools for use at the STLT level  in the United States, of which three have been used to assess national preparedness (Exhibit II.2; Appendix  B). Of the nine tools, six were indices that produced composite scores and three were measure sets. In  addition, there were three sets of capabilities maintained by federal agencies, which we describe below,  but do not include in the list of tools because they do not quantify preparedness. The literature also  described a variety of tools to measure country-level preparedness; prominent examples are in Exhibit II.3.  Exhibit II.2. List and description of tools to assess STLT public health and healthcare  preparedness  Tool  Description  Tools for internal and external stakeholders  Community Outbreak  Preparedness Index (COPI) 20  Assesses county-level preparedness for infectious disease outbreaks using  publicly available data  Hospital Medical Surge  Preparedness Index21  Evaluates the capacity of hospitals to handle patient surges during mass casualty  events, using over 120 measures from publicly available data sources  Hospital Preparedness Program  (HPP) performance measure  set22  Assesses preparedness of HPP funding recipients based on 22 performance  measures reported by recipients and disseminated broadly  National Health Security  Preparedness Index (NHSPI) 23  Generates a composite preparedness score for states, territories, and the nation  overall based on 130 measures derived from publicly available data sources  Trust for America’s Health  (TFAH) Ready or Not tool24  Evaluates states’ preparedness for public health emergencies using a targeted set  of 10 measures largely derived from the NHSPI    IIIAlthough we excluded these tools from the main analysis of themes and gaps presented in Chapter II, we reviewed  and cite literature related to these tools as it relates to overarching themes and gaps in preparedness metrics.  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  7  Tool  Description  Self-administered tools for internal use by STLT jurisdictions  Assessment for Disaster  Engagement with Partners Tool  (ADEPT) 25  Summarizes the frequency and nature of activities related to disaster  preparedness, response, and recovery that local health departments engage in  with community-based organizations, using a 15-item index for use by local  health departments  Connectivity Measurement  Tool26  Quantifies the level of connectivity of different organizations and systems  involved in public health preparedness across 28 items  Preparedness Capacity  Assessment Survey (PCAS) 27  Creates an aggregate score summarizing preparedness of local health  departments  Rapid Urban Health Security  Assessment (RUHSA) 28  Evaluates local-level health security capacities across 46 measures  The most prominent STLT preparedness tool we  found in the literature is the NHSPI. First  released in 2013 and updated annually using  publicly available data, the NHSPI assesses U.S.,  state, and territorial health preparedness for a wide  range of emergencies and disasters. Scores are  disseminated publicly to inform planning efforts by  internal and external stakeholders. In the literature,  four peer-reviewed articles focused on the NHSPI,  and nearly all articles that described U.S.  preparedness tools mentioned the NHSPI as  relevant background.36,37,38,39 The NHSPI was  developed with input and support from a variety of  funders and partners, initially including the CDC  and the Association of State and Territorial Health  Officials, and beginning in 2016, the Robert Wood  Johnson Foundation. The most recent edition of  the NHSPI uses more than 60 publicly available  data sources across 130 measures to create an  overall preparedness score for each U.S. state on a  scale of 1 to 10.40 The tool also produces a score  for each state across six domains: health security  and surveillance; community planning and  engagement; incident and information  management; health care delivery;  countermeasures management; and environmental  and occupational health.   Existing tools contain a varying number of  measures. Several of these tools are designed to  measure preparedness broadly across 50 or more  Exhibit II.3. Prominent global tools to measure  national public health and health care  preparedness  Although this report focuses on U.S. tools to  measure STLT preparedness, there are a variety of  tools used globally to measure country-level  preparedness. Prominent global preparedness tools  include:  •  Oppenheim et al.’s Epidemic Preparedness  Index. Assesses national-level preparedness for  infectious disease outbreaks.29   •  Global Health Security Index. Assesses and  benchmarks health security and related  capabilities. This tool was originally developed in  partnership among Nuclear Threat Initiative,  Johns Hopkins Center for Health Security, and  Economist Impact, with Brown University  Pandemic Center supporting development of the  most recent edition.30  •  Pan American Health Organization’s  Preparedness Index for Emergencies and  Disasters. Estimates the capacity of national  health care systems to deal with and recover  from emergencies and disasters.31  •  World Health Organization’s Joint External  Evaluation Tool. Measures capacity and  progress toward nine technical areas to assess a  nation’s capacity to prevent, detect, and rapidly  respond to public health threats.32  As detailed in Appendix C, the COVID-19 pandemic  exposed limitations in the predictive validity of many  of these global tools.33, 34, 35  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  8  measures (such as the NHSPI, COPI, the HMSPI, RUHSA). Others have a narrower focus and fewer  measures, such as the ADEPT, which contains 15 items focused specifically on local health departments’  partnerships to prepare for, respond to, and recover from disasters, or the TFAH tool, which assesses  preparedness across a focused set of 10 measures that are largely derived from the NHSPI.   In addition to the tools highlighted in Exhibit II.2, FEMA, CDC, and ASPR maintain lists of  capabilities that are also intended to guide STLT public health preparedness. Although not intended  to quantify and summarize preparedness like indices or measure sets, FEMA, CDC, and ASPR each  maintain sets of capabilities and associated resources and trainings to guide STLT jurisdictions’ efforts to  prepare for and respond to emergencies. For example, FEMA maintains a list of 32 core capabilities that  communities need to advance emergency preparedness.41 CDC and ASPR maintain similar sets of  capabilities and guidance for STLT public health agencies and health care coalitions,IV respectively.42,43  Although these three sets of capabilities are intended for different users, contain different numbers of  capabilities, and use different organizing domains to group the capabilities, all three are designed to be  flexible and adaptable to meet the needs of all STLT jurisdictions, which vary in size, geography, and  governance structures.44,45,46 However, these capabilities sets are largely intended for self-administration  and do not produce composite scores or other data sets that allow for quantitative comparison across  jurisdictions. Exhibit II.4 highlights similarities and differences across these three capability sets.   Exhibit II.4. Characteristics of sets of capabilities from FEMA, CDC, and ASPR  Characteristic  FEMA’s National  Preparedness Goal Core  Capabilities41  CDC’s Public Health  Emergency Preparedness  and Response Capabilities42  ASPR’s Health Care  Preparedness and  Response Capabilities43  Intended user or target  audience  Whole communities  STLT jurisdictions and their  public health agencies  Multisector health care  coalitions, including health  care organizations and  public health agencies  Purpose  To assist everyone who has  a role in preventing,  protecting against,  mitigating, responding to,  and recovering from the  threats and hazards that  pose the greatest risk  To serve as national standards  for STLT public health  Lists the necessary  attributes for the health  care system to save lives  and continue to function in  advance of, during, and  after a response  Initial release year  2011  2011  2012  Most recent release year  2015  2018a  2017  Number of capabilities  32  15a  4b    IV Health care coalitions are defined as multisector groups of health care and response organizations—including public health  agencies—within a geographic area.46    Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  9  Characteristic  FEMA’s National  Preparedness Goal Core  Capabilities41  CDC’s Public Health  Emergency Preparedness  and Response Capabilities42  ASPR’s Health Care  Preparedness and  Response Capabilities43  Domains  • Prevention  • Protection  • Mitigation  • Response  • Recovery  • Community resilience   • Incident management   • Information management   • Countermeasures and  mitigation   • Surge management   • Biosurveillance  • Foundation for health  care and medical  readiness   • Health care and medical  response coordination   • Continuity of health care  service delivery   • Medical surge  a CDC launched the Next Generation of the Public Health Emergency Preparedness Program (PHEP) initiative in 2020, which may  impact capability standards.   b ASPR expects to release an updated set of capabilities in 2024 that will add four new capabilities to the set (for a total of eight).  The COVID-19 pandemic exposed that preparedness tools—such as the NHSPI, TFAH tool, and  other prominent global tools—were not accurate predictors of COVID-19 outcomes.47,48,49,50 For  example, the NHSPI did not successfully predict excess mortality rates at the outset of the COVID-19  pandemic even though the tool was assessed for construct validity during its development and continues  to undergo validity and sensitivity testing on an ongoing basis as new sources of public health emergency  data emerge. 51,52,53 Appendix C summarizes literature on preparedness tools’ accuracy in predicting  COVID-19 outcomes. Even before the COVID-19 pandemic, the evidence-base for preparedness tools was  limited because the relative rarity of public health emergencies limited the use of real-world data to  validate tools.54   2.  Purpose and intended users  Five tools summarize preparedness for broad audiences, including internal and external  stakeholders. The NHSPI, HMSPI, COPI, and TFAH tools all use publicly available data to generate results  that are disseminated broadly and can be easily interpreted by a wide range of internal and external users.  These users may include federal, state, and local officials; public health and health practitioners and  administrators; multisector coalitions; researchers; communications specialists; and the general  public.55,56,57. In addition, data from the HPP measure set are available for use by internal and external  users. Although the HPP measure set is designed to be completed by HPP funding recipients and to  inform federal program monitoring, data from the HPP measure set are publicly available in easy-to-use  visualizations that show and compare how states and health care coalitions performed.58   Four tools are self-administered; they have a narrower focus and more targeted audience. The  ADEPT, Connectivity Measurement Tool, PCAS, and RUHSA are self-guided tools that local jurisdictional  leaders can use to assess preparedness and identify areas for improvement.59,60,61 For example, the ADEPT  tool collects data from local health department staff and their partners to measure the strength of local  health departments’ partnerships with community-based organizations to prepare for, respond to, and  recover from emergencies.62 Unlike the tools described above, results from the self-administered tools are  intended for internal stakeholders only, and are not routinely shared with a broad audience.   Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  10  3.  Jurisdiction levels  Two tools measure state and territorial preparedness, although additional tools produce results  that can be aggregated at the state level. The NHSPI is a comprehensive tool to measure and  summarize preparedness at the state and territorial levels. 63, Similarly, the TFAH tool, which consist of nine  measures from the NHSPI and an additional measure of state public health spending trends, provides  another way for states to compare themselves to others and assess areas for improvement.64 Further,  some of the other tools that collect data within states, such as the HPP performance measure set, can be  rolled up to the state level to understand preparedness across the state.   Seven tools assess preparedness at a local level—such as at the county, local health department, or  hospital level—but they have noteworthy limitations that could be addressed through additional  research and new or innovative sources of local data. For example, the COPI creates a composite  outbreak preparedness score at the county level and assesses a wide range of measures across the  emergency management cycle, but is a relatively new tool and consequently, has not been widely used or  validated across settings.65 Similarly, the HMSPI assesses preparedness at the hospital level, but the index  has not been widely validated against hospital performance during actual disasters.66. The HPP measure  set includes measures of preparedness for health care coalitions, but the size and composition of health  care coalitions varies across localities, making the data difficult to compare. A few tools, such as the  ADEPT, Connectivity Measurement Tool, PCAS, and RUHSA, measure the emergency preparedness of local  health departments, but are self-assessment tools intended to be completed by staff at the public health  departments and are not publicly reported (which would allow for comparison across local health  departments). New or untapped sources of local data could support development of new tools that could  facilitate comparison of local jurisdictions’ preparedness and inform federal and STLT planning efforts.   Three of the STLT tools can assess preparedness at the national level. Results from two tools—the  NHSPI and HPP measure set—are routinely aggregated at the national level to present a snapshot of  national preparedness (an example from NHSPI is shown in Exhibit II.5). In addition, the TFAH tool groups  states into tiers based on scores for each measure, which can be used to assess national preparedness, for  example by assessing the number or percentage of states in the highest performing tier for each measure  to assess relative strengths and weaknesses across the United States.  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  11  Exhibit II.5. Example of national preparedness data available on the NHSPI website    Note: The dashboard is available on the NHSPI website (https://nhspi.org/#by-state) and includes preparedness scores for the nation  and by state, including the overall preparedness level and preparedness scores by domain.  4.  How existing tools conceptualize preparedness  A few tools take a comprehensive approach to defining and measuring preparedness and include  measures that address all five phases of emergency management. Comprehensive indices like the  NHSPI and COPI include measures aligned with all five phases of the emergency management cycle  (prevention, protection, mitigation, response, and recovery).67,68 Tools with fewer measures and a  narrower focus, such as the ADEPT or the HPP measure set, tend to focus on measuring jurisdictions’  efforts to develop and implement emergency response plans related to prevention, mitigation, and  response. Exhibit II.6 highlights examples of measures from select tools across the five phases of  emergency management.   STLT preparedness tools include a mix of proactive and reactive measures. Proactive measures for  disaster preparedness identify potential risks and establish best practices to mitigate their impact— aligning with the prevention, protection, and mitigation phases of emergency management—whereas  reactive measures focus on post-event response and recovery.69 The tools we found generally contain a  mix of both types of measures. Examples of common proactive measures of preparedness include  accreditation of public health and health care facilities, measures quantifying the size of vulnerable  populations, such as children, adults ages 65 and older, or people eligible for Medicaid, and measures of  social capital, such as housing affordability or voter turnout. The tools also contained numerous reactive  measures focused on the ability to respond to threats, such as the number of burn care beds or  emergency response teams, access to volunteers (measured as the number of registered Medical Reserve   Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  12  Corp volunteers or the number of partnerships with volunteer entities), and availability of personal  protective equipment, among others.  Exhibit II.6. Examples of measures that assess various aspects of the five phases of emergency  management from select preparedness tools, including the NHSPI, COPI, HPP measure set, and  ADEPT   Emergency management phasea  Examples of measures from select tools  Prevention. Ability to avoid, prevent,  or stop imminent threats  • Number of epidemiologists per 100,000 population in the state, by  quintile (NHSPI)  • Population coverage for wastewater surveillance testing (COPI)  • Percentage of health care coalitions engaged in their recipient’s (state or  large local health department’s) jurisdiction risk assessment (HPP measure  set)  • State health department participates in a broad prevention collaborative  addressing health care–associated infections (NHSPI)  Protection. Ability to secure the  homeland against acts of terrorism  and disasters  • Percentage of bridges that are in good or fair condition (transportation  structural integrity) (NHSPI)  • Number of infrastructure companies (e.g., utility and communications  companies) and local public safety agencies (e.g., law enforcement)  participating in the health care coalition (HPP measure set)  Mitigation. Ability to reduce loss of  life and property by lessening the  impact of disasters  • Number of obstetricians and gynecologists per 100,000 female population  in the state (NHSPI)  • Pediatric vaccination rate (defined as proportion of county’s children with  all required immunizations for school enrollment) (COPI)  • Whether programs have conducted community outreach side-by-side  with community-based organization staff to reach vulnerable and hard-to- reach populations (ADEPT)  • Percentage of HCCs that access the de-identified emPOWER data map at  least once every six months to identify the number of individuals with  electricity-dependent medical and assistive equipment for planning  purposes (HPP Measure Set)  Response. Ability to save lives,  protect property and the  environment, and meet basic humans  needs after an incident  • State public health laboratory has a plan for a six-to-eight-week surge in  testing capacity to respond to an outbreak or other public health event,  with enough staffing capacity to work five 12-hour days for six to eight  weeks in response to an infectious disease outbreak (NHSPI)  • Number of community emergency response team (CERT) programs in a  county per capita (COPI)  • Program has coordinated the use of a community-based organization  facility during a disaster (ADEPT)  • Percentage of HCCs that have a complete and approved response plan  annex addressing the specialty surge requirement (HPP measure set)  Recovery. Ability to help  communities recover effectively  • Percentage of employed population in the state engaging in some work  from home by telecommuting (NHPSI)  • Quality of unemployment (UE) benefits (defined as ratio of state maximum  weekly UE benefits divided by county’s average supplemental poverty  measure threshold) (COPI)  aEmergency management phases and definitions are from the FEMA National Preparedness Goal.44   ADEPT = Assessment for Disaster Engagement with Partners Tool; COPI = Community Outbreak Preparedness Index; HCC = health  care coalition; NHSPI = National Health Security Preparedness Index; HPP = Hospital Preparedness Program.   Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  13  Numerous tools measure specific aspects  of preparedness, such as vulnerability or  resiliency. Social vulnerability and community  resilience play an important role in  preparedness and are pertinent to health  outcomes after emergencies and disasters.78  To strengthen individual and community  resilience in the U.S., HHS recently developed  the Federal Plan for Equitable Long-Term  Recovery and Resilience, which lays out an  approach for federal agencies to cooperatively  strengthen the vital conditions for health and  well-being.79 Although it is widely accepted  that social vulnerability and resilience affect preparedness, there are competing views on the extent that  these measures and other contextual factors should be included in preparedness tools. Some researchers  believe these factors affect preparedness and so should be incorporated in indices,80 but others suggest  that preparedness indices should only measure factors within the immediate control of jurisdictions.81  These tensions contribute to overarching challenges defining and conceptualizing preparedness.  Although we do not focus on these tools in this chapter, Exhibit II.7 highlights several examples of tools  that measure resilience and vulnerability.  5.  Types of disasters addressed  Many tools take an “all-hazards” approach that measures preparedness for a range of disasters  rather than for a specific type of disaster or emergency.82 Eight of the nine tools take an all-hazards  approach to measuring preparedness across emergency situations, including natural disasters;  communicable disease outbreaks; cyberattacks; acts of terrorism; and risks related to chemical, biological,  radiological, nuclear, and explosive incidents. Consequently, most measures within these tools are relevant  to a range of disasters—for example, NHSPI’s “percentage of local health departments in the state with an  emergency preparedness coordinator” or TFAH’s “change in state public health spending” measure— rather than targeting skills and resources needed by emergency type, such as whether a state has an  evacuation route in place if a hurricane occurs.   Exhibit II.7. Examples of tools to measure health  and social vulnerability or resilience78  •  Baseline Resilience Indicators for Communities70   •  Community Disaster Resilience Index71  •  Community Resilience Estimates72   •  Community Resilience Index73   •  COVID-19 Community Vulnerability Index74  •  COVID-19 Vulnerability Index75  •  COVID-19 Pandemic Vulnerability Index76   •  Social Vulnerability Index (SVI)77  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  14  The COPI is the only one of the nine tools we reviewed that focuses on preparedness for infectious  disease outbreaks.V Before the COVID-19 pandemic, there were a few global tools—like the Epidemic  Preparedness Index, Global Health Security Index, and Infectious Disease Vulnerability Index87— that  assessed countries’ preparedness to respond to infectious disease emergencies. A March 2023 study cited  the need for additional measures to quantify preparedness and response capabilities for pandemics and  infectious disease outbreaks specifically in the United States.88 In response to the lack of local-level tools  and COVID-19, a team at a California-based nonprofit developed the COPI to assess county-level  preparedness across the five phases of emergency management for an outbreak of an infectious disease.  The index measures strengths and gaps in areas such hospital surge capacity, nursing home staffing,  insurance coverage and access to primary care,  using over 30 data sources. It includes new data  sources developed in response to COVID-19, such  as the Centers for Medicare and Medicaid Services’  Nursing Home COVID-19 Vaccination Data.   There are some efforts to measure components  of STLT preparedness for natural disasters.  Exhibit II.8 highlights examples of disaster-specific  tools related to wildfire smoke exposure,  hurricanes, tsunamis, and extreme heat. Although  many of the factors assessed in these tools overlap  with the all-hazards tools described above—such  as measures of community socioeconomic status  and unemployment— they also include factors that  are specific to types of disasters. For example, the  TsunamiReady guidelines include a measure of  whether the community has produced tsunami  evacuation maps, and the ReadyMapper data  visualization tool, which has been used during  wildfires and hurricanes, includes variables of  population-level movement to show where people  are evacuating from and where they are going.89  6.  Data sources  Four tools leverage data from public sources,  including national surveys, government  agencies, and associations. The NHSPI, COPI,  HMSPI, and TFAH tool all rely on publicly available  data to inform measurement (Exhibit II.9). The NHSPI uses publicly available data from 64 sources to  calculate states’ preparedness scores,90 and the COPI uses data from more than 30 sources.91 A limitation    V As noted in Exhibit II.6, several tools specifically assess state and local vulnerability and resilience to COVID-19—and  not other infectious diseases—but do not focus on preparedness.  Exhibit II.8. Examples of tools that measure  components of STLT preparedness for specific  disasters   Examples of tools that measure components of STLT  preparedness for specific disasters include:  •  Community Health Vulnerability Index.  Measures county-level vulnerability to wildfire  smoke exposure. Health officials can use the tool  in combination with air quality models to focus  public health strategies on areas where air  quality is impaired.83   •  ReadyMapper. Tracks and measures response— including population mobility, infrastructure  damage, and health system response capacity—  during natural disasters. ReadyMapper was used  during the wildfires in California and in the  Hurricane Ida response in Louisiana.84  •  National Weather Service’s TsunamiReady  program and associated guidelines. Establishes  16 guidelines for communities to work towards  to mitigate, prepare for, and respond to  tsunamis.85  •  Heat Vulnerability Index. Assesses factors  associated with adverse health effects during  extreme heat to identify communities at the  greatest risk and inform mitigation efforts, such  as setting up cooling centers in vulnerable areas  where many people do not have access to air  conditioning.86  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  15  to using publicly available data is that there are often lags in availability. For example, the latest NHSPI  report, released in 2021, relies on data from 2020 and earlier, and the COPI report released in 2023 draws  on some data sources dating back to 2014.  Five preparedness tools rely on self-reported data. The ADEPT, Connectivity Measurement Tool, PCAS,  and RUHSA are self-assessment tools, meaning the data are collected and used by the jurisdiction  only.92,93,94,95,96,97 Although this approach expands the types of measures that can be assessed because  tool developers are not limited by data availability, self-assessment tools do not allow for comparison  across jurisdictions. Similarly, self-reported data are prone to response bias.98 The HPP measure set is also  self-reported by HPP funding recipients but results are disseminated publicly for external stakeholders.  Exhibit II.9. Examples of data sources used to measure preparedness in existing tools, by level  (state and/or local) that the data are available    State  Local  Survey data  American Hospital Association Annual Survey      Association of Public Health Laboratories All-Hazards Laboratory Preparedness Survey      Association of Public Health Laboratories Comprehensive Laboratory Services      Association of State and Territorial Health Officials Profile Survey      Centers for Disease Control and Prevention’s Behavioral Risk Factor Surveillance System      Centers for Disease Control and Prevention’s Youth Risk Behavior Survey      Robert Wood Johnson Foundation’s National Longitudinal Survey of Public Health  Systemsa       National Association of City and County Health Officials Profile of Local Health  Departments      U.S. Census Bureau’s American Community Survey      U.S. Census Bureau’s Current Population Survey      Publicly available data from government agencies  Agency for Healthcare Research and Quality Pediatric Quality Indicators      Agency for Toxic Substance and Disease Registry Environmental Justice Index      Administration for Strategic Preparedness and Response Hospital Preparedness Program  measure data      Administration for Strategic Preparedness and Response Medical Reserve Corp data       Bureau of Labor Statistics Occupational Employment Statistics      Centers for Disease Control and Prevention’s National Snapshot of Public Health  Preparedness      Centers for Disease Control and Prevention’s National Health care Safety Network  Prevention Status Reports      Centers for Disease Control and Prevention’s Funding Recipient lists      CDC’s National Vital Statistics System data       Centers for Medicare & Medicaid Services Hospital Compare      Centers for Medicare & Medicaid Skilled Nursing Facility Quality Reporting Program data      Federal Emergency Management Association Community Rating System      Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  16    State  Local  Health Resources and Services Administration data on health care shortage areas      National Plan & Provider Enumeration System National Provider Identifier registry       Data from associations and other organizations  Association of Public Health Laboratories member list      Leapfrog group hospital safety score      NACCHO Project Public Health Ready participation      National Emergency Management Association data      Penn State University Social Capital Index composite score of civic engagement      Public Health Accreditation Board member list      United States Election Project General Election Turnout Rates      Note:  Mathematica compiled the data sources in this table by reviewing the source lists for the NHSPI and HMSPI. The list focuses  on publicly available data sources and is not meant to be exhaustive. We define local level data as any data available within  states (such as data from a county, hospital system, health care coalition, or hospital). Survey data available at the local level  may only be available for a sample of local jurisdictions.   a The survey was originally funded by the Centers for Disease Control and Prevention before the Robert Wood Johnson Foundation  became the primary funder.  B. What are the gaps in existing public health and health care preparedness  metrics?   In this section, we describe gaps in preparedness  metrics, including gaps in:  / Factors that are measured in existing indices and  measure sets  / Jurisdiction levels for which the preparedness  tools are designed   / Types of disasters addressed  / Available data  / Other areas (including limitations)  1.  Gaps in factors that are measured  Existing preparedness tools do not fully capture  several important predictors of preparedness  and response capacity. Next, we describe the  predictors of preparedness that the literature and  TEP cited as missing or insufficiently captured in  preparedness measurement; they are also  summarized in Exhibit II.10.  Current preparedness tools do not adequately  assess partnerships and cross-sector collaboration. It is well documented that cross-sector  collaboration between public health, health systems, community-based organizations, laboratories, and  Exhibit II.10. Spotlight on the technical expert  panel: Factors that are inadequately captured in  existing metrics  Technical expert panel (TEP) members highlighted  several important factors that affect preparedness in  the U.S., but are inadequately captured in existing  preparedness indices and tools:  •  Partnerships and cross-sector collaboration  (mentioned 11 times by TEP members)  •  Individual training and preparedness (mentioned  11 times by TEP members)  •  Administrative capacity to hire and scale up  operations (mentioned seven times by TEP  members)  •  Political factors (mentioned six times by TEP  members)  •  Social vulnerability (mentioned six times by TEP  members)  •  Public trust (mentioned five times by TEP  members)  Source: Mathematica’s analysis of TEP data.  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  17  other organizations is critical for promoting resource sharing and engaging communities and volunteers  in preparedness, response, and recovery.99,100,101,102 However, both the literature and the TEP emphasized  the need for better measures of cross-sector collaboration; in fact, this was one of the most prominent  TEP themes. 103 A TEP member noted that it can be resource intensive to collect the survey data needed to  assess relational coordination.   We can see these weaknesses when we examine  specific tools. For example, the NHSPI has a sub- domain dedicated to “cross-sector/community  collaboration” that includes six measures, but these  measures (which rely on publicly available data) do  not capture the extent to which a state and its  localities have plans and systems in place to  collaborate during emergencies.VI Likewise, a  known weakness of the HMSPI is that it includes publicly available measures of individual hospitals’  preparedness for mass casualty events, but it does not measure the synergies between hospitals that  would improve collective response.104 On the other hand, the HPP performance measure set is specifically  designed to collect and summarize information about cross-sector health care coalitions and the extent to  which their member organizations partner with each other.105 However, HPP funding recipients cite  challenges with burdensome reporting requirements.106   Existing metrics fail to consider whether the individuals working in public health and health  organizations are adequately trained to perform their duties. TEP members highlighted that  numerous tools measure the number and types of staff in an organization, but do not assess how they  have been trained and whether that training gives them the ability to effectively respond to an  emergency. TEP members pointed out that ill-prepared leadership across sectors and a lack of real-world  experience among epidemiologists and other experts are both key limitations of existing metrics. The  CDC’s guidance document summarizing public health capabilities includes detailed suggestions on  individual skills and training needs to meet the required capabilities,107 which implies that STLT public  health agencies may have this information to guide their planning, but it is not currently assessed in  indices and measure sets.  TEP members highlighted the need for additional  measures to assess STLT health departments’  administrative capacity to hire staff and scale up  operations during emergencies. TEP members noted  that a variety of metrics are designed to measure  epidemiological or public health laboratory capacity  (for example, number of epidemiologists per 100,000),  but fewer measures examine functions like human  resources and procurement (for example, staff who    VI Examples of measures in this NHSPI domain include “state health department accredited by the Public Health  Accreditation Board” and “percent of hospitals in the state that participate in health care preparedness coalitions  through the Hospital Preparedness Program.” See NHSPI 2020 Measure Set.    “Being able to measure relational coordination  and connectivity is something we did learn  from the COVID-19 pandemic. That is a  measure that is really important [for  preparedness].”   — TEP member   ‘What we’re finding now is that [key  questions are,] “Can you move people,  money, stuff, and data around quickly? Do  you have the systems and authorities in  place to allow you to do that? Can you hire  quickly? Can you buy things quickly?”’   — TEP member  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  18  support recruitment, training, payroll and benefit administration, and purchasing). The COVID-19  pandemic exposed how critical such measures are, as many STLT public health departments struggled to  quickly hire staff and source computers and other basic supplies for contact tracing operations and  COVID-19 testing sites.108  Preparedness indices do not capture the importance of political factors in public health  preparedness and response outcomes. Existing tools do  not measure the presence of effective political  leadership109,110 or how political leanings might affect public  health operations and outcomes.111 Several TEP members  expanded on this, noting that measuring the presence of a  public health emergency response plan, as many existing  indices do, is not sufficient when political leaders have the  power to prevent these plans from being executed.   Existing metrics do not adequately measure STLT  jurisdictions’ preparedness to mitigate, respond to, and recover from emergencies affecting  socially and medically vulnerable populations. Most of the comprehensive preparedness indices that  we focused on for this report attempt to assess risks for some vulnerable populations, but also exclude  important subgroups. For example, the NHSPI has a sub-domain on “at-risk populations.” The four  measures in the domain focus on children and people who are pregnant, but do not measure other  important groups that may be at elevated risk of experiencing adverse effects from disasters, such as  people living with disabilities or people who are uninsured. On the other hand, indices focused exclusively  on vulnerability (such as those in Exhibit II.7) may help to identify communities that may need support  before, during, or after disasters based on socioeconomic factors, household characteristics, racial and  ethnic composition, and housing types and transportation, but they miss other critical factors related to  preparedness, such as emergency planning and surge capacity. Several TEP members reinforced this  finding, emphasizing the importance of identifying communities that are most vulnerable to disasters and  the extent that these communities are receiving the support they need to prevent, mitigate, respond to,  and recover from emergencies. The literature highlighted opportunities to combine social vulnerability  data from tools like CDC’s Social Vulnerability Index with results from preparedness tools to improve the  predictive capability of existing preparedness tools for underserved communities.112,113  TEP members highlighted a need for measures of public trust in government. Public trust in the  government had important implications for population-level health behaviors and outcomes during the  COVID-19 pandemic.114 TEP members noted that this factor is not adequately addressed in existing  preparedness measures and should be explored. A starting point could be examining existing metrics that  quantify public trust in government (Exhibit II.11).   2.  Gaps by jurisdiction type  Currently, there is no comprehensive all-hazards index to measure and guide local jurisdictions’  emergency preparedness efforts. Although there are a handful of tools to measure preparedness across  localities within states (for example, at the county or local health department level), none of these tools  comprehensively quantify local public health preparedness across disaster types. Existing tools at the local    “You can have capacity, you can have the  capability, and people could be robustly  prepared ... but if the political will isn’t  there, [it’s not] going to happen.”   — TEP member Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  19  level either have a somewhat narrow focus, such as the ADEPT tool’s focus on partnerships for  preparedness and response, or HMSPI’s focus on hospital surge plans and capacity, or are intended for  self-administration rather than broader dissemination, such as the PCAS and RUHSA. Further, although  the recently developed COPI takes a comprehensive approach to assessing preparedness for infectious  disease outbreak at the county level, its focus on infectious disease and lack of widespread validation may  limit its usefulness on a broad scale.   This is a critical gap that makes it challenging for  federal and state officials to understand which  communities and local public health departments  are less prepared and need additional resources  and support to address emergencies. The TEP  mentioned this gap, noting that the lack of a local  all-hazards index makes it challenging for similarly  sized communities to compare themselves to each  other and prioritize areas for improvement.  However, there are trade-offs to consider. One TEP  member cautioned that all-hazards indices at the  local level may be challenging for localities to use  and interpret, given the notable variation in size,  geographic characteristics, and governance  structure across local jurisdictions. This TEP  member suggested that hazard-specific tools may  be easier for local jurisdictions to use. Another TEP  member cautioned that STLT jurisdictions may fear  political consequences and the stigma of “being at  the bottom of the list” if they have a low  preparedness score. Because local organizations  such as public health agencies, hospitals, and other  health care and social service providers are on the  front lines of emergency responses, it is important  to consider options for developing additional tools  to understand community-level preparedness.119  Tribal communities need tailored metrics to  help them assess preparedness and response. FEMA’s pre-disaster recovery guide for tribal  governments highlights the need for special considerations for tribal communities when planning for  emergencies.120 For example, the guide encourages tribal communities to consider the presence of sacred  or historic land when taking inventory of assets during emergency preparedness exercises, and  emphasizes the criticality of cross-jurisdictional coordination (including intergovernmental agreements  with state, local, and other tribal governments) given the sovereignty of federally recognized tribes. Yet  the existing preparedness tools and the related literature do not discuss implications or use of  measurement tools with or by tribal organizations, suggesting that potential gaps may exist in measuring  preparedness within tribal nations and communities. More recently, FEMA released the 2022–2026  Exhibit II.11. Examples of metrics that quantify  public trust in government  Several indices quantify public trust in government  across multiple dimensions. For example:  •  The Citizen Trust in Government  Organizations scale includes nine items  measuring citizens’ perception of government  agencies’ competence, benevolence, and  integrity.115   •  The Trust in Government Measure quantifies  public trust as it relates to population health  interventions and public health messaging. The  tool includes 17 items related to perceptions of  the government’s capability, effectiveness,  judgement, beneficence, and integrity.116  In addition, a few U.S. organizations collect and track  standalone measures of citizens’ self-reported trust  in government. For example:  •  Pew Research Center estimates the percentage  of people in the U.S. who trust the government  to do what is right “just about always”, “most of  the time”, “only some of the time” or “never”  based on polling data.117,  •  A survey conducted by the Harvard T. H. Chan  School of Public Health asks respondents to  rate their level of trust in federal, state, and local  public health agencies using a four-point Likert  scale. 118    Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  20  National Tribal Strategy, which expands on the FEMA national preparedness goal by addressing its  responsibilities to tribal nations.121 One aim of the National Tribal Strategy is to develop tribal-specific  technical assistance resources and case studies to help Tribal Nations reach goals related to preparedness,  protection, mitigation, response, and recovery. Although metrics could help set and track progress toward  these goals, it will be critical that any tools to assess the preparedness of tribal groups are developed in  close consultation with tribes and do not have any unexpected consequences.   3.  Gaps by disaster type  Most preparedness tools discussed here were designed to assess “all hazards” preparedness, which  may not reliably predict outcomes for all types of emergencies. The literature and TEP members  highlighted that all-hazards indices do not reliably predict outcomes for all types of emergencies and may  be challenging for jurisdictional users to use to improve preparedness.122 This was evidenced during the  COVID-19 pandemic, when numerous studies found that all-hazards indices were poor predictors of  COVID-19 mortality rates. (See Appendix C.)123,124,125 TEP members highlighted unique challenges in  measuring preparedness for infectious disease outbreaks—borne out by the experience of the COVID-19  pandemic—such as the need to plan for a sustained response over many months or years, reduction in  routine program functions, changing priorities and policies, and the critical role of public health leaders  relative to other common types of responders, such as fire and rescue. These challenges also apply to  measuring preparedness for other emergency situations, such as concurrent disasters (e.g., a hurricane  occurring during an infectious disease outbreak) or cascading hazards (e.g., a tsunami triggering electrical  grid failure that ultimately results in a nuclear power plant incident).   There are potential gaps in preparedness  metrics for emergent threats, such as  cybersecurity threats, natural disasters, and  other hazards. Infectious disease outbreaks are  not the only type of hazard that require specialized  plans. Cybersecurity threats require extensive  planning that may not be captured in all-hazards  indices. For example, the NHSPI assesses the  existence of data systems to coordinate emergency  response, but does not measure plans if these data  systems are breached or inoperable due to  cybersecurity attacks.127 A 2023 report released by  the White House highlighted the need for a  national cybersecurity strategy, including  approaches to measure preparedness for  cybersecurity threats.128 Similarly, natural disasters  have unique preparedness needs. For example,  planning for storms and floods involves  determining evacuation routes, planning to protect  food and water from contamination, and developing communication plans to update the public during  power outages.129 With the growing threat of cyber-related service disruptions and natural disasters and  Exhibit II.12. Local health departments’  perception of preparedness by threat  The 2022 NACCHO Survey of Local Health  Department Preparedness asks respondents to  assess their own preparedness and concern for 23  different threats/hazards.126 Among the 23 hazards,  there are seven hazards on which their concern was  substantially higher than they thought their  preparedness was (defined as a difference of 20  percentage points [ppts] or more):  •  Opioid abuse and overdose (58 ppt difference)  •  Medical supply chain disruptions (38 ppt  difference)  •  Cyber-related threats (35 ppt difference)  •  Active shooter (24 ppt difference)  •  Critical infrastructure protection (24 ppt  difference)  •  Storms/ flooding (23 ppt difference)  •  Vaccine-preventable diseases (23 ppt difference)  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  21  rising concerns about the hazards listed in Exhibit II.12, it is important to ensure there are ways to  adequately measure STLT preparedness for these types of events.130,131  4.  Gaps in available data  There are gaps in data sources used to measure preparedness at the local level. Many data sources  are only available for public use at the state or national level (Exhibit II.9), and only about half of these  data sources are available at the sub-state level. The literature attributes the lack of comprehensive  indices at the local level, in part, to the lack of standardized data collection among local public health  agencies,132,133 as well as challenges related to interoperability (for example, incompatible software and  systems, diverse data sources, STLT-level regulations around data sharing, and concerns about data  security and privacy) and the lack of a public health IT infrastructure network.134   Data are not always timely. Several TEP members mentioned that static measures of preparedness can  be misleading because they only capture a single point in  time and are not regularly updated. This is especially true  of assessing measures of response capacity such as  vacant hospital beds or availability of personal protective  equipment. Many data sources like national surveys tend  to be collected sporadically and may have lags between  the times when data are collected and when they are  publicly available. There is a growing need to identify  data sources that are frequently updated and rapidly available for public use so more timely measures of  preparedness are available.  5.  Other gaps and limitations   The scan highlighted a few additional limitations in STLT jurisdictions’ ability to use existing  preparedness tools, such as challenges adapting scores from indices to their local contexts and  using the tools for goal setting. This suggests that there is a need for greater STLT engagement in  developing and refining metrics, and in informing development of technical assistance tools to  support use and interpretation of metrics. A few TEP members said it can be difficult for STLT  jurisdictions to interpret and adapt preparedness scores from existing indices to their unique context to  identify the greatest threats and risks their own community faces. Furthermore, for both state and local  jurisdictions, preparedness tools lack benchmarks to help guide goal setting and improvement. Although  indices like the NHSPI contain helpful information to summarize preparedness, the literature cites  challenges at the STLT level in using this information to set goals and guide improvement.135 Moving  forward, those responsible for developing and improving metrics should consider ways to continuously  engage STLT jurisdictions and their partners in developing, testing, and refining tools. This would increase  awareness of tools and ensure they are actionable for end users.136,137,138    “Static measures [of preparedness] give us a lot  of misleading information about what capacity  we do or do not have.”   — TEP member Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  22  C. What lessons learned from the COVID-19 pandemic can inform measurement  of emergency preparedness and response at STLT public health agencies in the  future?   Experiences from the COVID-19 pandemic offer critical takeaways that can inform the development of  more robust and effective measures in the future. Below, we highlight some of these lessons learned.  The COVID-19 pandemic exposed preparedness tools’ lack of predictive validity. As noted in section  II.1 and described in detail in Appendix C, numerous studies found that preparedness tools—including the  NHSPI, TFAH tool, and prominent all-hazards global tools—were poor predictors of COVID-19 mortality  rates.139,140,141 This underscores the need to explore ways to improve measurement within existing tools  and consider whether all-hazards tools are the best way to assess preparedness for the wide range of  unique emergencies that the country is likely to face. It also highlights the need to test and refine existing  tools on an ongoing basis as new sources of public health emergency data become available.   During the pandemic, researchers uncovered a variety of factors associated with public health  outcomes that should be considered and measured when assessing emergency preparedness. As  highlighted in Section II.B, factors such as strength of partnerships, political will, public trust, and social  vulnerability were shown to be associated with key outcomes during the pandemic, and TEP members  underscored them as noteworthy gaps in existing metrics. We can improve our understanding of  preparedness by finding ways to measure these factors. Relatedly, a few TEP members noted that there is  potential to use artificial intelligence to expedite review of after-action reports and qualitative data on  preparedness to discover additional factors to measure.   The COVID-19 pandemic underscored the need to embed equity into emergency preparedness and  response systems, and thus, into how we measure communities’ preparedness and assess their  vulnerabilities. It is well documented that the COVID-19 pandemic disproportionately impacted  historically marginalized communities.142,143 For example, one study showed that communities with higher  rates of social and health vulnerability had significantly lower health security levels as measured by the  NHSPI.144 This underscores the need for emergency preparedness systems to adopt approaches that  promote equitable crisis response processes and outcomes. Examples of equitable approaches to crisis  response include creating diverse crisis response teams and partnering with community organizations  known to local communities, who can help build trust and support communication with groups at  elevated risk of poor health outcomes due to structural and systemic barriers. The CDC recently  implemented the Public Health Response Readiness Framework, which includes health equity as one 10  program priorities. The 2024-2028 PHEP notice of funding opportunity (NOFO) embeds health equity  requirements in the NOFO’s three overarching strategies.145However, there remains a need to develop  equity-focused preparedness metrics that align with the changes to the CDC framework and incorporate  them in existing indices and tools to quantify inequities in preparedness. This need is further articulated in  a 2023 report from the American Medical Association, which calls for improved collection of demographic  and social needs data (such as race and ethnicity, language, disability status, and gender identity) to  reliably detect, measure, and evaluate inequities in crisis preparedness and response.146  Investments in data infrastructure could improve measurement of preparedness, especially at the  local level where measurement is limited by a lack of standardized data sources. The COVID-19  Chapter II. The Current State of Public Health and Health Care Preparedness Metrics in the United States  Mathematica® Inc.  23  pandemic exposed many weaknesses in the public health data and surveillance infrastructure in the  United States, including limitations in reporting and tracking lab test results, lack of interoperability across  health care and public health reporting systems, and gaps in the types of data that are collected and  tracked, among others.147,148 Improved data infrastructure, sharing, and collection was mentioned nearly  20 times by members of the expert panel. This is especially true at the local level, where lack of timely,  standardized data (along with other factors such as limited resources, local priorities, and so on) makes it  challenging to create composite measures of preparedness. CDC’s multibillion dollar Data Modernization  Initiative, which began in 2020, aims to improve data infrastructure to make it easier for STLT public health  agencies to report data (including data related to preparedness) and for state and federal officials to use  these data to inform decision making. TEP members noted that better data infrastructure—including  systems that are updated with data in real time—could help the nation transition from point-in-time  measurement of preparedness to continuous assessment, which would be a significant advance. To  support data infrastructure improvements, many TEP members highlighted that federal and STLT public  health agencies need additional funding and other resources so they can invest in new data systems and  support ongoing changes to the ones they have.   Although existing metrics have been updated and improved substantially in the last decade, the  evidence base for public health and health care preparedness metrics remains weak, and  substantial work remains at all levels—national, state, local, tribal territorial, and the private  sector—to ensure the United States is prepared to respond to federal public health and health care  emergencies.149 Although the development of tools like the NHSPI, TFAH tool, COPI, and others listed in  Appendix B has advanced STLT preparedness measurement, noteworthy gaps remain in public health  preparedness metrics and in STLT emergency preparedness more broadly. For example, a 2023  Government Accountability Office (GAO) report stated that substantial deficits in the federal government’s  preparedness for emergencies remain—noting that GAO had made 155 recommendations to HHS for  improvements in the prior ten years, and only 64 had been implemented. In the wake of the COVID-19  pandemic, the literature also highlights the need for improvements to other aspects of the U.S. public  health infrastructure—such as building the public health workforce, advancing the collection and use of  public health data, and enhancing communication from public health agencies to the communities they  serve—to enhance preparedness for future emergencies.150 Improving tools to measure public health  preparedness is key to tracking the nation’s progress towards emergency preparedness goals, but the lack  of consensus on how preparedness should be conceptualized and defined in preparedness frameworks,  capabilities lists, and tools complicates the path to success in this area. Looking forward, it will be  important to know which strategies can address the gaps in preparedness metrics so the federal  government and STLT public health agencies can find the weaknesses and better allocate resources to  improve emergency preparedness nationwide.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  24  III. Strategies to Improve Measurement of Public Health and Health  Care Preparedness  Gaps and challenges in current preparedness metrics can inform refinement of domestic  preparedness metrics going forward. Considering takeaways from Chapter II, this chapter focuses on  ways to improve preparedness measurement by addressing the following two research questions:  1. What key attributes should public health and health care preparedness measures and indices have,  and what gaps from Chapter II do these attributes address?  2. What strategies should potentially be explored to improve measurement of public health and health  care preparedness?   A. What key attributes should new public health and health care preparedness  measures have, and what gaps would they address?   To identify strategies for improving preparedness measurement, researchers and policymakers  should begin by (1) examining the ideal attributes of measures and indices, and (2) considering  how they could fill the gaps revealed here. Defining key attributes or necessary characteristics of  metrics provides a set of criteria to assess measures and indices against. Exhibit III.1 lists 10 key attributes  to consider for preparedness metrics, along with the gaps they address. This list is based on the attributes  put forth by Lichiello and Turnock in their Guidebook for Performance Measurement.151 The research team  then drew on existing literature on public health measurement to consider modifications to the attributes.  These 10 attributes were ultimately organized into three categories:  / Research-dependent attributes—including importance, validity, and reliability—require quantitative  analysis to understand whether the measure or index is relevant, accurate, and repeatable.   / Data-source dependent attributes—including availability, responsiveness, and completeness—concern  access to timely data sources that underlie measures and indices.   / Ready for real-world use attributes—including understandability, actionability, credibility, and  flexibility/adaptability—support a measure or index’s ability to be used in practice.   Eight of the attributes highlighted in Exhibit III.1 apply to both the measures themselves and to indices;  two of the attributes—completeness and flexibility and adaptability—apply solely to indices. Lichiello and  Turnock noted that there is a risk to complete and accurate reporting if there will be negative  consequences for staff or organizations that report low scores. Lichiello and Turnock described this as a  need for “abuse-proof” measurement,152 while the TEP noted a need to avoid political leaders fearing  retribution over low scores.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  25  Exhibit III.1. Key attributes of preparedness measures and the gaps they addressa  No. Attribute  Description and risk if not met  Current gaps or weaknesses  addressed  Research-dependent  1  Importance  Reflects a structure, process, or outcome with a large  impact on health; demonstrates substantial variation  reflecting meaningful underlying differences;153 is  directly related to objectives.  Risk if not met: The measure or index may not focus on  activities that preserve life or improve health or other  key outcomes following an emergency.  Metrics reflect a wide range of  competing capabilities and  frameworks set forth by federal  agencies and researchers, with  little evidence base for selection  of their components.  2  Validity   Captures the essence of what it purports to measure,  instead of correlated characteristics.   Risk if not met: The measure or index may inaccurately  indicate a jurisdiction is prepared, when in reality it is  not.  High performance on  preparedness metrics did not  predict COVID-19 outcomes for  many indices; there is a lack of  evidence supporting the validity  of measures in practice.  3  Reliability  Has a high likelihood of yielding the same results in  repeated trials, so there are low levels of random error  in measurement.  Risk if not met: The measure or index may accurately  predict preparedness in one scenario, but not others.  There is a lack of evidence  supporting the reliability of  measures and indices in practice.  Data source-dependent  4  Availability  Readily available with means on hand; accessible,  ongoing sources of data.154   Risk if not met: The measure or index will require time- intensive data collection and reporting, displacing focus  that could be spent on preparedness activities.  Data limitations have hindered  development of comprehensive  local indices. Lack of data makes  it difficult to measure some  aspects of preparedness, such as  the strength of partnerships.  Challenges with interoperability  impede timely data sharing, a  critical component of  preparedness.   5  Responsiveness  Able to detect change; properly calibrated and sensitive  enough to pick up important changes.155   Risk if not met: The measure or index is not up to date  when an incident occurs; that is, a capacity that  appeared adequate from older data is not there.  Gaps in timely data sources and  lack of dynamic measures of  preparedness limit existing  indices’ ability to register critical  changes in preparedness.  6  Completenessb  An emergency preparedness index should ideally cover  all important aspects of emergency preparedness that  affect outcomes.  Risk if not met: The index will fail to predict the quality  of response and outcomes in an emergency. For  example, if the index captures a wide range of factors  that affect preparedness but does not include measures  of surge capacity, a jurisdiction may be ill-equipped to  meet demand for health services, leading to increased  preventable mortality following a disaster.  Existing metrics fail to consider  the wide range of factors that  affect preparedness, such as the  strength of partnerships,  individual training, and  administrative capabilities.  There is a lack of equity- focused preparedness metrics  to identify potential inequities in  crisis preparedness and response.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  26  No. Attribute  Description and risk if not met  Current gaps or weaknesses  addressed  Ready for real-world use  7  Understandability Easily understood by all, with minimal explanation.   Risk if not met: The measure or index is unlikely to be  used in practice or could be used incorrectly.  All-hazards indices and tools  that compound preparedness  scores across a range of  measures may be difficult to  interpret, especially at the local  level, and there are few hazard- specific preparedness tools  available at the STLT level.  8  Actionability  Process or condition within the organization’s control.156  Risk if not met: The measure or index is unlikely to  improve readiness or be used in practice.  Many indices lack benchmarks  to help jurisdictions set goals,  track progress, and take action to  improve preparedness.  The lack of regularly updated  data sources makes it  challenging to measure factors  that change quickly, limiting the  actionability of preparedness  measures that rely on outdated  data.  9  Credibility   Supported by stakeholders.  Risk if not met: The measure or index is unlikely to be  used in practice.  STLT jurisdictions have described  challenges using existing tools,  which may be related to lack of  engagement of STLT  jurisdictions in the development  and refinement of metrics.  10  Flexibility and  adaptabilityb  An index should be adaptable across jurisdiction types.  For example, an index may need to have required and  optional components that could be tailored to a  jurisdiction and its specific hazards.157,158  Risk if not met: The index will not accurately capture  preparedness across communities with different risks  and/or may not be feasibly used across communities  with different public health structures.  There is a lack of metrics that  can be adapted to the unique  needs and risks of STLT  jurisdictions in a way that informs  their efforts to improve  preparedness.  aAttributes 1–5, 7, and 9 are adapted from Lichiello and Turnock’s Guidebook for Performance Measurement;146 additional references  are as noted.  bAttributes 6 and 10 apply to indices only.  The COVID-19 experience suggests that federal, state, local, and nongovernmental organizations  could establish priorities for preparedness measurement—including assessing tradeoffs between  measure attributes and the feasibility of various measurement strategies—to make incremental  progress as resources become available. One of the TEP members lamented the lack of progress in the  past decade on improving availability of preparedness measurement metrics. A variety of factors have  limited progress, including constrained resources and the challenge of prioritizing how to invest them.  More recently, fading memories of just how ill-prepared the U.S. was during the COVID-19 public health  emergency could also be a factor. To help ASPE and others capitalize on ASPE’s investment in this project,  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  27  in the next section we outline a series of strategies, along with their likely resource intensity, for  consideration to help build forward momentum on preparedness measurement activities.   B. What strategies could potentially be explored to improve measurement of  public health and health care preparedness?  Given the challenges discussed, there is an  opportunity to pursue development of improved  measures and indices that have the attributes  described above in Exhibit III.1 and that address the  gaps in metrics described in Chapter II. This section  describes four strategies to advance preparedness  measurement (Exhibit III.2).   For each of the four proposed strategies, we  present tables that outline potential action steps  that could support achievement of these strategies  (Exhibits III.5, III.6, III.9, and III.10). For each action  step, we also estimate its resource intensity—low,  medium, or high—to shed light on strategy  feasibility. Low-intensity strategies are those likely  to require one to three staff working for less than a  year; high-intensity strategies are those that involve  large-scale data collections or system changes; and  medium-intensity strategies capture efforts likely to  fall between the low- and high-intensity ranges.  Some of the medium- and high-intensity strategies would benefit from building on the results of listed  low-intensity strategies, while others—those we have italicized—could begin as soon as resources are  available.   Strategy #1: Address gaps in existing metrics by developing or refining important measures of  preparedness and supplementing preparedness metrics with contextual data.  Developing new measures for critical aspects of preparedness would help fill identified gaps in  current measures and improve current measurement tools. As shown in Exhibit III.1, a key attribute of  a desirable measure is a proven link between the activity and outcomes. Further, indices should  incorporate all important aspects of emergency preparedness to achieve completeness. As discussed  during the TEP, several factors that contribute to preparedness are missing from current measures and  indices. Important preparedness factors that could be considered in future measure development work  include individual preparedness, cross-sector partnerships, and administrative response capabilities, each  discussed further below, with examples for potential follow up actions listed in Exhibit III.5. We also  discuss the importance of pairing supplemental data on social, political, economic, and environmental  factors with preparedness metrics, acknowledging that data sources to measure these factors are not  Exhibit III.2. Four strategies that could  potentially advance preparedness  measurement  1. Address gaps in existing metrics by developing  or refining important measures of preparedness  and supplementing preparedness metrics with  contextual data.   2. Improve how health equity is addressed in  preparedness metrics by engaging underserved  communities in continuous efforts to advance  measurement and considering social vulnerability  data together with preparedness measures.   3. Improve source data and use additional  analysis to enhance the availability,  responsiveness, and salience of preparedness  metrics.  4. Enhance actionability and understandability  of metrics by developing and disseminating  information on exemplars.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  28  currently available on an ongoing basis, meaning the cost of collecting these data would need to be  weighed against the importance of these measures.  /  Individual readiness of the public health and health care workforce. As highlighted in Chapter II,  TEP members noted the importance of measuring individual readiness—that is, whether public health  and health care workers have the right training to respond to public health emergencies—in addition to  organizational preparedness. In practice, this may be easier said than done. For example, during the  COVID-19 public health emergency, guidance for managing the response was sometimes emerging  locally and disparately, due to the novel situation, and there were limited and sometimes lagged or  incomplete data to inform that guidance. While neither individual nor organizational preparedness  training plans can account for all possible emergency scenarios with challenging conditions like the  COVID-19 pandemic, a better-trained workforce might mitigate some future challenges. To the extent  that policymakers need to issue local guidance as with COVID-19, they should also consider what  supplemental training or mentorship may be needed for health care workers to effectively implement  their guidance.  Beyond individual training, some degree of cross-training might also improve preparedness, since  during the COVID-19 public health emergency, many public health and health care professionals had to  assume roles for which they were not trained.162 Although there are many options for training public  health and health care workers and leaders on emergency readiness,163,164 the literature did not describe  any metrics that report the percentage of the public health or health care workforce that have recently  completed relevant, evidence-based training. Learning management systems, which are widely available  online, can easily collect and report the kinds of data that could be useful, such as the specific roles of  those trained (leader, health care worker, and so on), when they had their last training, percentage of  employees trained, and so on.165 In conjunction  with measuring individual readiness, there may  be an opportunity to improve or expand existing  preparedness programs and clarify a minimum  training expectation to ensure that all the types  of professionals necessary for an effective  response are trained.   / Cross-sector partnerships. As noted in Chapter  II, partnerships between public health, health  care, and other sectors such as community-based  organizations are critical to emergency response.  To better understand the strength of a  jurisdiction’s partnerships, a standardized survey  approach that preserves anonymity of  respondents could objectively capture this  information. Some survey tools exist to measure  partnerships (Exhibit III.3). Going forward, work  could focus on reviewing existing tools and  considering whether they could be adapted for  Exhibit III.3. Survey instruments to measure  the strength of partnerships among STLT public  health departments and their partners  •  The ADEPT index is intended for use by local  health departments to assess engagement with  cross-sector partners; however, it does not  capture other partners’ perspectives on the  relationships.159  •  A survey tool to measure post-disaster  resilience was developed and administered to  369 community-based organizations in New  York, as well as the New York State Department  of Health and Hygiene to measure partnership  activity and resilience after Hurricane Sandy, but  was not intended to assess preparedness  broadly.160   •  The Connectivity Measurement Tool includes a  survey of multiple partners in public health  emergency response about their perceived  connectivity, but there is little research on the  validity of the tool in peer-reviewed research.161   Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  29  widespread use, and on exploring the feasibility of incorporating a survey-based measure of partnership  strength into routine local preparedness measurement.   / Administrative response capability. To improve measurement of administrative capabilities like hiring  or procurement at STLT health departments, there may be an opportunity to build on existing data  collection efforts. For example, NACCHO’s 2022 Preparedness Profile survey asked a sample of local  health departments whether the following set of administrative capabilities were in place: (1) ability to  receive and use emergency funding, (2) ability to reduce time to contract for or procure necessary  goods and services, (3) ability to allocate or reallocate financial resources to pay for staff during an  emergency, and (4) ability to reduce time required to hire staff or reassign existing staff.166 Between 23  and 37 percent of local health departments reported these capabilities were either not in place, or they  were unsure if they were in place. The NACCHO tool is a valuable resource; further development of  administrative capacity measures using NACCHO’s tool or something similar could enhance  understanding of administrative capability trends across communities and over time.VII   / Contextual factors affecting response and  outcomes. Numerous social, political, economic,  and environmental factors affect emergency  response and outcomes but are outside the  control of the public health and health care  sector (Exhibit III.4). Incorporating measurement  of these factors into public health preparedness  indices would fail to consider the key measure  attribute of “actionability.” Instead, routinely  measuring and analyzing these contextual  factors, and presenting them alongside  preparedness measures within the control of the public health and health care sector, could help  policymakers and the public understand areas for investment.VIII   Exhibit III.5. Potential approaches to address strategy #1, and likely resource intensity of each  Examples of potential follow-up approaches  Likely  resource  intensity  • Advance individual training and measurement of training through professional associations.  Conduct key informant interviews with key public health and health professional associations about  interest in encouraging members to take a standardized emergency preparedness training and any  outstanding needs or barriers to doing that; identify how progress could be made and measured  (could lead to need for a Medium or High resource intensity follow-up to support the associations).   Low    VII If a survey were expanded and implemented annually, there could be an opportunity to improve actionability: the  same NACCHO survey identified barriers to administrative preparedness. Connecting health departments with  resources to improve readiness based on barriers identified during the survey process would help make the measures  actionable.   VIII A TEP member especially advocated for shining a light on government laws, policies, and regulations, providing an  example of how a hiring freeze had prevented jurisdictions from hiring during COVID-19 despite the availability of  federal funding to do so.  Exhibit III.4. Contextual factors affecting public  health preparedness and response outcomes  •  Social and health vulnerability167   •  Political will168  •  Public trust169  •  Policies/laws/regulations170,171  •  Supply chain172   •  Funding for public health173   •  Built and natural environment context174,175,176   Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  30  Examples of potential follow-up approaches  Likely  resource  intensity  • Evaluate existing online preparedness curricula to begin setting a foundation for measurement  of individual preparedness. Evaluate existing online curricula and obtain target audience input to  suggest improvements to help optimize them.  • Explore degree program accreditation as a tool to improve readiness of future public health  professionals and set a foundation for a national measure of individual preparedness. Meet  with the Council on Education for Public Health, which accredits schools’ public health degree  programs, to explore potential and any initiatives underway to increase “on-the-ground” training to  100 percent of students, and any initiatives promoting cross-training.   • Develop new trainings to fill gaps to support improvement on future measurement of  individual preparedness. Conduct a gap analysis and fill gaps in existing emergency preparedness  curricula by developing new modules or trainings.   • Advance measurement of strength of essential partnerships. Review existing tools for measuring  strength of partnerships as they relate to emergency preparedness, obtain input from the field,  suggest possible adaptations needed for widespread use, and explore the feasibility of incorporating  a survey-based measure into routine local preparedness measurement efforts.  • Investigate contextual factors critical to response and outcomes. Develop a method to quantify  or assess contextual factors affecting emergency response and outcomes based on publicly available  data sources; develop options for presenting these along with preparedness indices and gather  target audience feedback on best way to consider these alongside preparedness.  Medium  • Improve measurement of administrative response capability and provide support to help STLT  jurisdictions overcome barriers. Expand NACCHO or similar survey effort to capture administrative  response capability across all local health departments, and survey them annually until they are all  consistently reporting these capabilities. This effort should be paired with resources, including  technical assistance, to overcome barriers to improving these capabilities.  • Develop a national-level measure or measures corresponding to administrative response  capability. Track progress toward having 100 percent of new graduates in key fields enter the  professional workforce with appropriate preparedness training.  High  Notes:  Low-intensity=likely to require one to three staff working for less than a year; high-intensity=those that involve large-scale  data collections or system changes; medium-intensity=efforts likely to fall between the low- and high-intensity ranges.     Low-intensity and italicized efforts could begin when resources are available. Italicized efforts are not dependent on low- intensity efforts to be completed first. Medium- and high-intensity efforts not italicized would best be structured using  results from the low-intensity efforts listed.  Strategy #2: Improve how health equity is addressed in preparedness metrics by engaging  underserved communities in continuous efforts to advance measurement and considering social  vulnerability data together with preparedness measures.   Incorporating health equity into preparedness measurement could be considered high priority and  would strengthen the credibility and importance of existing metrics. The TEP emphasized the  importance of health equity, citing literature on the disproportionate burden of COVID-19 disease and  death on socially and medically vulnerable populations.177 In addition, addressing health equity in  preparedness measurement aligns with new priorities identified by the COVID-19 Health Equity Task  ForceIX and with CDC’s efforts to incorporate health equity into the Public Health Response Readiness    IX The Task Force was created through E.O. 13995 to make recommendations to the president for mitigating health  inequities caused or exacerbated by the pandemic, and for preventing them in the future (Office of Minority Health.    Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  31  Framework.178 PHEP requires its funding recipients to report on functional exercises involving critical  workforce groups and disproportionately impacted populations. However, there are no current measures  or indices that quantify preparedness to serve socially and medically vulnerable populations, such as those  disproportionately impacted by COVID-19.   One way to approach the challenge of incorporating health equity into preparedness measurement  is for researchers to engage frontline response staff at public health and health care organizations  in identifying local needs for metrics and ways to capture the required data. Historically, measure  development has relied on input from academic experts, as opposed to feedback from real-world,  frontline response workers embedded in the communities where emergencies occur. Future measure  development could prioritize community input and buy-in to ensure that measures are (1) feasible—that  is, they will work given local circumstances; (2) credible, because they are informed by users themselves;  and (3) important, because they are connected to desired outcomes based on end-user experiences.X  Local public health workers could be engaged along with first responders and emergency management  personnel in developing hazard-specific metrics tailored to their communities, which were identified in the  literature as missing from the "all-hazards approach” that most national frameworks and STLT tools take.  Exhibit III.6 highlights an example of health equity in local preparedness metrics.  Explore optimal ways to communicate  preparedness metrics alongside measures of  social vulnerability to guide equitable allocation  of resources. A community’s social and health  vulnerability is highly correlated with emergency  response and recovery outcomes regardless of the  level of preparedness.179 Pairing social and health  vulnerability information together with  preparedness measures or indices could increase  awareness of communities with low preparedness  and particularly high vulnerability so policymakers  could allocate resources effectively. This approach  would require developing and testing a preferred  format for communicating social vulnerability and preparedness measures together.   Examples of potential follow-up approaches are summarized in Exhibit III.7.    “COVID-19 Health Equity Task Force – Charter.” U.S. Department of Health and Human Services, January 2021.  https://www.minorityhealth.hhs.gov/omh/browse.aspx?lvl=3&lvlid=118. OMH, 2022).  X The NHSPI included a stakeholder engagement and communications workgroup in 2017; however, the workgroup  does not appear active today.  Exhibit III.6. Example of health equity in local  hazard-specific preparedness metrics:   A jurisdiction may have a neighborhood with low  average household income and a high percentage of  people of color, and that neighborhood may also be  physically low-lying or in a floodplain and as such,  more at-risk for severe flooding. Because this  neighborhood has specific needs that the rest of the  jurisdiction does not, input from local responders,  local public health workers, and community  members could be convened to identify or create a  preparedness metric to address their needs.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  32  Exhibit III.7. Potential approaches to address strategy #2 and likely resource intensity of each  Examples of potential follow-up approaches  Likely  resource  intensity  • Develop recommendations for an effective approach to present social and health  vulnerability indicators with or within preparedness indices. Mockup multiple options for  displaying social and health vulnerability indicators together with preparedness indices and  obtain feedback from target audiences to iterate to an effective approach or visualization  method. Promote the visualization tool in conjunction with the release of indices.  Low  • Identify locally appropriate metrics focused on health equity to advance equity-focused  preparedness measurement in communities. Select communities based on social vulnerability  that are part of larger, less vulnerable cities or counties that are typically the unit for  measurement. Engage front-line response staff to explore what metrics, including hazard-specific  metrics, would capture emergency preparedness and how these metrics could be included for  visibility as the larger area is assessed.   Medium to  high,  depending on  number of  communities  included  Notes:  Low-intensity=likely to require one to three staff working for less than a year; high-intensity=those that involve large-scale  data collections or system changes; medium-intensity=efforts likely to fall between the low- and high-intensity ranges.    Low-intensity and italicized efforts could begin when resources are available. Italicized efforts are not dependent on low- intensity efforts being completed first. Medium- and high-intensity efforts not italicized would best be structured using  results from the low-intensity efforts listed.  Strategy #3: Improve source data and use additional analysis to enhance the availability,  responsiveness, and salience of preparedness metrics.  Underused data sources—such as after-action reports and non-public data—as well as  unconventional data sources, such as cell phone data, could help close gaps in data availability,  particularly at the local level. Improving use of underused data is an appealing approach as it avoids  burden from new data collection, but it presents other challenges that vary by data source. Below we  highlight specific considerations for each potential data source; Exhibit III.10 provides a set of potential  follow-up approaches to consider.  / After-action reports (AARs). AARs are a promising data  source for identifying factors that affect preparedness  (Exhibit III.8)181,182 However, communities are not required  to complete them after disasters, and there is no  standardized format.183,184 While a standardized format  would better facilitate cross-AAR analysis, an analysis  identified strong AARs using varied methodologies and  following different outlines,185 suggesting that imposing a  single format may sacrifice utility for the localities that  need the results. Another possibility is requiring a  standardized metadata template, including categories  summarizing frequent types of challenges and  recommended improvements, as a way to facilitate cross- AAR analysis and learning without sacrificing flexibility.  A concern raised by the TEP members is that AARs may be seen as perfunctory requirements and not as  tools to inform future preparedness. One TEP member suggested future research could analyze AARs  Exhibit III.8. What is an after-action  report?  As defined by FEMA, “An after-action  report is developed after exercises and  real-world incidents to summarize key  information and continuous improvement- related analytical findings, including  observations and recommended actions. It  is a detailed and comprehensive  document that describes what went well  and what did not go well, considers why,  and provides recommended actions.”180   Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  33  from different communities and disaster types, comparing findings to existing metrics and revising  metrics to address challenges. Small-scale qualitative analysis of AARs has been conducted before186  and could be scaled up by using artificial intelligence to find patterns in reported processes and  challenges. The availability of AARs would need to be explored; one data source could be the Homeland  Security Digital Library, which houses an archive of AARs from jurisdictions across the United States,  some of which are available publicly. The variable quality of the AARs will affect the usefulness of these  data; improvements such as peer review of draft AARs could increase the value of AARs for both  learning and improvement.187  / Non-public data sources. Non-public data  sources, such as health system data, could build  an evidence base for the importance of  measures. The environmental scan and TEP  identified several non-public data sources that  could help measure factors related to  preparedness or link preparedness metrics to  outcomes (Exhibit III.9). These data sources are  restricted, so efforts to link measures and  outcomes using this data would require data  sharing agreements, de-identification, and other  data security protocols.   / Unconventional data collection and sources.  The COVID-19 pandemic required creative  approaches to obtaining urgently needed data.  For example, surge periods during the pandemic required first responders to access hospital capacity  data such as beds and key equipment available on a near real-time basis. To address this gap, the CDC’s  National Healthcare Safety NetworkXI (NHSN) provided a repository for hospitals (or state  intermediaries) to frequently input important facility-level data. In addition, some states implemented  their own statewide systems to share these data, such as New York’s publicly accessible Hospital Bed  Capacity Dashboard.XII Beyond facility-level preparedness data, a TEP member noted that many  jurisdictions turned to nontraditional data such as cell phone data to track cases and social media data  to track masking trends. Despite the critical information this type of infrastructure can convey, collecting  these data can be burdensome and may be considered intrusive, so future efforts may need to explore  making these data available solely during emergencies, rather than making them continuously available  (as in the case of cell phone data).     XI The CDC’s NHSN is the nation’s most widely used health care-associated infection tracking system, with most  hospitals in the U.S. contributing data through a secure, web-based application, traditionally on a monthly or  quarterly basis. https://www.cdc.gov/nhsn/index.html.  XII Bed occupancy data were required to input data on hospital and ICU beds available Monday through Friday on the  State’s Electronic Response Data System; see https://coronavirus.health.ny.gov/hospital-bed-capacity.  Exhibit III.9. Examples of non-public data  sources that could be leveraged to improve  measurement of preparedness   •  Non-public HPP data, such as data from the  Real-World Incident Reporting and Evaluation  Tool, and performance measure data.188  •  Emergency management data maintained by  vendors, cited by a TEP member as a central  source of granular data from large numbers of  hospitals on operations, capacity, and incidents.  •  Data from large hospital systems; for example, a  TEP member shared that one system’s readiness  project includes 140 preparedness-related data  points for more than 100 hospitals.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  34  Exhibit III.10. Potential approaches to address strategy #3, and likely resource-intensity of each   Examples of potential follow-up approaches  Likely  resource  intensity  • Explore feasibility of use of AI with AARs. Test feasibility of using AI methods, including  machine learning, to efficiently identify patterns in the challenges and learnings reported in AARs  that could have implications for preparedness metrics.   • Explore stakeholder receptiveness to implementing a metadata template for AARs, and  develop one if they are receptive, along with options for housing and accessing metadata. Could  lead to a medium resource intensity project to build and encourage use of a new system.  • Explore feasibility and benefits of using non-public data sources such as those in Exhibit III.8  to advance the evidence base for preparedness metrics.  • Capture lessons learned from use of cell phone data and social media tracking during  COVID-19. Explore how similar or improved use of these sources can be ready for future  emergencies.   Low  • Analyze AARs on a large scale, to identify themes in response experience; reflect and report on  the themes as they relate to current measurement and related needs; conduct follow up  interviews to verify themes and identify any additional reflections.   • Facilitate improvement of AARs’ quality and availability, through peer review and support to  ensure AARs are created and shared following all disasters.  • Undertake research using non-public data sources such as those in Exhibit III.8 to advance the  evidence base for preparedness metrics, once feasibility and a strong plan have been established.  Medium  • Identify and develop automated data solutions that would reduce reporting burden, such as  helping hospitals establish interfaces to automate NHSN submissions to obtain real-time, local  data for key capacity measures.   High  Notes:  Low-intensity=likely to require one to three staff working for less than a year; high-intensity=those that involve large-scale  data collections or system changes; medium-intensity=efforts likely to fall between the low- and high-intensity ranges.  Low-intensity and italicized efforts could begin when resources are available. Italicized efforts are not dependent on low-intensity  efforts to be completed first. Medium- and high-intensity efforts not italicized would best be structured using results from the low- intensity efforts listed.  Strategy #4: Enhance actionability and understandability of metrics by developing and  disseminating information on exemplars.  All-hazards preparedness indices may seem overwhelming to public health leaders given the  extensive capabilities they measure, the distinct local contexts and risks to consider, and the  complexity of cross-sector partnerships that are required. Presenting leaders with real-life examples of  exemplary emergency response can highlight the feasibility of “getting it right.” For example, one TEP  member noted, and another agreed, that it is important to showcase examples from hospitals or health  systems that performed relatively well—across both health outcomes and financially—during the COVID- 19 pandemic to encourage health systems to invest in preparedness. ASPR’s Healthcare Emergency  Preparedness Information Gateway (known as ASPR TRACIE) provides examples of strong community- level responses, but more can be done to improve access to and use of exemplar cases. Exhibit III.11  presents examples of potential action items for consideration.  Chapter III. Strategies to Improve Measurement of Public Health and Health Care Preparedness  Mathematica® Inc.  35  Exhibit III.11. Potential approaches to address strategy #4, and likely resource-intensity of each  Examples of potential follow-up approaches  Likely  resource  intensity  • Conduct a needs assessment to identify jurisdiction types, organizations, and disaster types  most in need of exemplar models, and a landscape assessment to identify existing strong  examples and find important gaps. Explore the key audience need through a small set of  interviews to ensure subsequent case studies (a medium resource intensity approach) are  designed to meet the needs.  Low  • Develop case studies to fill identified needs for exemplar models and disseminate them to  relevant audiences.   Medium  Notes:  Low-intensity=likely to require one to three staff working for less than a year; high-intensity=those that involve large-scale  data collections or system changes; medium-intensity=efforts likely to fall between the low- and high-intensity ranges.  C. Discussion  The four strategies shared in this section offer potential directions for the future to address clear  measurement gaps discussed in Chapter II. Ultimately, the availability of better tools to measure and  understand gaps in preparedness against specific threats could inform federal and state resource  allocation and help set priorities to improve preparedness of public health and healthcare system for the  next public health threat. In the hands of dedicated leadership, better measurement can also catalyze and  enable improvement, leading to a better-prepared nation.   Progress will depend on the interest and resources from government and nongovernment organizations  leading the way in preparedness at all jurisdiction levels. Each involved organization—at the federal level  to include ASPR, CDC, and FEMA—has its own preexisting priorities, and preparedness measurement  improvement resources will inevitably compete with program support. The breadth of the suggested  improvements should not discourage incremental enhancements. Incremental enhancements, such as any  handful of the low- and medium-intensity efforts described above, especially if coordinated across  organizations, could translate to a markedly better understanding of the status of preparedness among  public health leaders, policymakers, and the general public, thanks to better measurement. The specific  approaches that should be undertaken first depend, as a practical matter, on how managers within the  relevant agencies find the efforts well-matched with existing work, resources, and program opportunities. References  Mathematica® Inc.  36  References    1 Nelson, C., N. Lurie, J. Wasserman, and S. Zakowski. “Conceptualizing and Defining Public Health Emergency  Preparedness.” American Journal of Public Health, vol. 97, April 1, 2007, pp. S9–S11.  https://doi.org/10.2105/AJPH.2007.114496.   2 Administration for Strategic Preparedness and Response. “ASPR TRACIE Evaluation of Hazard Vulnerability  Assessment Tools.” January 2024. https://files.asprtracie.hhs.gov/documents/aspr-tracie-evaluation-of-hva-tools- 3-10-17.pdf. Accessed May 6, 2024.  3 Federal Emergency Management Agency. “Mission Areas and Core Capabilities.” July 2020.  https://www.fema.gov/emergency-managers/national-preparedness/mission-core-capabilities. Accessed June 17,  2024.  4 Federal Emergency Management Agency. “National Preparedness Goal.” March 2023.  https://www.fema.gov/emergency-managers/national-preparedness/goal. Accessed May 6, 2024.  5 Assistant Secretary for Preparedness and Response. “Hospital Preparedness Program.” n.d.  https://aspr.hhs.gov/HealthCareReadiness/HPP/Documents/HPP%20Fact%20Sheet%20April%202021.pdf.  Accessed May 6, 2024.  6 Centers for Disease Control and Prevention. “2023 Readiness Report.” 2023.  https://www.cdc.gov/orr/media/pdfs/ORR_2023_Readiness_Report_508.pdf. Accessed June 17, 2024.  7 Federal Emergency Management Agency. “Preparedness Grants.” February 2024.  https://www.fema.gov/grants/preparedness. Accessed June 17, 2024.  8 World Health Organization. “Key Approaches to Strengthening Emergency Preparedness and Response.” n.d.  https://www.who.int/europe/emergencies/our-work-in-emergencies/key-approaches. Accessed June 17, 2024.  9 Federal Emergency Management Agency. “2019 National Threat and Hazard Identification and Risk Assessment  (THIRA): Overview and Methodology.” U.S. Department of Homeland Security, July 2019.  https://www.fema.gov/sites/default/files/2020-06/fema_national-thira-overview-methodology_2019_0.pdf.  Accessed May 6, 2024.  10 Centers for Disease Control and Prevention. “Division of State and Local Readiness Friday Update.” June 2024.  https://www.cdc.gov/readiness/media/pdfs/2024/06/2024-06-07_DSLR-Friday-Update_508C.pdf.   11 Centers for Medicare & Medicaid Services. “Core EP Rule Elements.” September 2023.  https://www.cms.gov/medicare/health-safety-standards/quality-safety-oversight-emergency-preparedness/core- ep-rule-elements. Accessed June 13, 2024.  12 Centers for Disease Control and Prevention. “Public Health Emergency Preparedness and Response Capabilities:  National Standards for State, Local, Tribal, and Territorial Public Health.” October 2018.  https://www.cdc.gov/readiness/media/pdfs/CDC_PreparednesResponseCapabilities_October2018_Final_508.pdf.   13 Administration for Strategic Preparedness and Response. “General Overview of Healthcare Coalitions.” n.d.  https://files.asprtracie.hhs.gov/documents/aspr-tracie-general-overview-hccs.pdf.   14 Stoto, M., and C. Nelson. “Measuring and Assessing Public Health Emergency Preparedness: A Methodological  Primer.” SSRN, September 2012. https://doi.org/10.2139/ssrn.2886349.  15 Asch, S.M., M. Stoto, M. Mendes, R. Burciaga Valdez, M.E. Gallagher, P. Halverson, and N. Lurie. “A Review of  Instruments Assessing Public Health Preparedness.” Public Health Reports, vol. 120, no. 5, October 2005, pp. 532– 542. https://doi.org/10.1177/003335490512000508.  16 Nelson, C., N. Lurie, J. Wasserman, and S. Zakowski. “Conceptualizing and Defining Public Health Emergency  Preparedness.” American Journal of Public Health, vol. 97, April 1, 2007, pp. S9–S11.  https://doi.org/10.2105/AJPH.2007.114496.   17 Stoto, M., and C. Nelson. “Measuring and Assessing Public Health Emergency Preparedness: A Methodological  Primer.” SSRN, August 2023. http://dx.doi.org/10.2139/ssrn.4538548.   18 Ibid.    References  Mathematica® Inc.  37    19 Piltch-Loeb, R.N., C. Nelson, J. Kraemer, E. Savoia, and M. Stoto. “A Peer Assessment Approach for Learning from  Public Health Emergencies.” Public Health Reports, vol. 129, no. 6, November 2014, pp. 28–34.  https://doi.org/10.1177/00333549141296S405.  20 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  21 Marcozzi, D.E., R. Pietrobon, J.V. Lawler, M.T. French, C. Mecher, J. Peffer, N.E. Baehr, et al. “Development of a  Hospital Medical Surge Preparedness Index Using a National Hospital Survey.” Health Service and Outcomes  Research Methodology, vol. 20, no. 1, 2020, pp. 60–83.   22 Administration for Strategic Preparedness and Response. “2019–2023 Hospital Preparedness Program: Performance  Measures Implementation Guidance.” 2022.  https://aspr.hhs.gov/HealthCareReadiness/guidance/Documents/2019-2023-HPP-Performance-Measures- Implementation-Guidance-8Nov22.pdf.   23 Lumpkin, J.R., Y.K. Miller, T. Inglesby, J.M. Links, A.T. Schwartz, C.C. Slemp, R.L. Burhans, J. Blumenstock, and A.S.  Khan. “The Importance of Establishing a National Health Security Preparedness Index.” Biosecurity and  Bioterrorism: Biodefense Strategy, Practice, and Science, vol. 11, no. 1, 2013, pp. 81–87.  24 McKillop, M., R. Faberman, and D. Alpert Lieberman. “Ready or Not 2024: Protecting the Public’s Health from  Diseases, Disasters, and Bioterrorism.” Trust for America’s Health, 2024. https://www.tfah.org/report-details/ready- or-not-2024/.  25 Glik, D.C., D.P. Eisenman, I. Donatello, A. Afifi, M. Stajura, M.L. Prelip, J. Sammartinova, et al. “Reliability and Validity  of the Assessment for Disaster Engagement with Partners Tool (ADEPT) for Local Health Departments.” Public  Health Reports, vol. 129, no. 6, suppl. 4, 2014, pp. 77–86. https://doi.org/10.1177/00333549141296S411.  26 Dorn, B.C., E. Savoia, M.A. Testa, M.A. Stoto, and L.J. Marcus. “Development of a Survey Instrument to Measure  Connectivity to Evaluate National Public Health Preparedness and Response Performance.” Public Health Reports,  vol. 122, no. 3, 2007, pp. 329-38. doi: 10.1177/003335490712200306. PMID: 17518304; PMCID: PMC1847495.  Development of a Survey Instrument to Measure Connectivity to Evaluate National Public Health Preparedness  and Response Performance - PMC (nih.gov).  27 Davis, Mary, Glen Mays, James Bellamy, Christine Bevc, and Cammie Marti. “Improving Public Health Preparedness  Capacity Measurement: Development of the Local Health Department Preparedness Capacities Assessment  Survey.” Disaster Medicine and Public Health Preparedness, vol 7, 2013, pp. 1–7. 10.1017/dmp.2013.108.  28 Boyce, M.R., and R. Katz. “Rapid Urban Health Security Assessment Tool: A New Resource for Evaluating Local-Level  Public Health Preparedness.” BMJ Global Health, vol. 5, no. 6, 2020, article e002606.  29 Oppenheim, B., M. Gallivan, N.K. Madhav, N. Brown, V. Serhiyenko, N.D. Wolfe, and P. Ayscue. “Assessing Global  Preparedness for the Next Pandemic: Development and Application of an Epidemic Preparedness Index.” BMJ  Global Health, vol. 4, no. 1, 2019, article e001157.  30 Global Health Security Index. “What is the GHS Index?” n.d.  https://ghsindex.org/about/#:~:text=The%20Global%20Health%20Security%20%28GHS%29%20Index%20is%20an ,prevent%2C%20detect%2C%20and%20respond%20to%20epidemics%20and%20pandemics.  31 Pan American Health Organization. “Preparedness Index for Health Emergencies and Disasters.” 2019.  https://www.paho.org/en/documents/preparedness-index-health-emergencies-and-disasters-0.  32 Gupta, V., J.D. Kraemer, R. Katz, A.K. Jha, V.B. Kerry, J. Sane, J. Ollgren, et al. “Analysis of Results from the Joint  External Evaluation: Examining Its Strength and Assessing for Trends Among Participating Countries.” Journal of  Global Health, vol. 8, no. 2, 2018.  33 Stribling, J., A. Clifton, G. McGill, and K. de Vries. “Examining the UK Covid-19 Mortality Paradox: Pandemic  Preparedness, Healthcare Expenditure, and the Nursing Workforce.”  Journal of Advanced Nursing, vol. 76, no. 12,  2020, pp. 3218–3227. https://doi.org/10.1111/jan.14562.   34 Kaiser, M.A., T.Y. Chen, and P. Gluckman. “Should Policy Makers Trust Composite Indices? A Commentary on the  Pitfalls of Inappropriate Indices for Policy Formation.” Health Research Policy and Systems, vol. 19, no.1, March  2021. https://doi.org10.1186/s12961-021-00702-4.     References  Mathematica® Inc.  38    35 Haider, N., A. Yavlinsky, Y.M. Chang, M.N. Hasan, C. Benfield, A.Y. Osman, M.J. Uddin, et al. “The Global Health  Security Index and Joint External Evaluation Score for Health Preparedness Are Not Correlated with Countries'  COVID-19 Detection Response Time and Mortality Outcome.” Epidemiology and Infection, vol. 148, 2020, article  e210. https://doi.org/10.1017/S0950268820002046.   36 Lumpkin, J.R., Y.K. Miller, T. Inglesby, J.M. Links, A.T. Schwartz, C.C. Slemp, R.L. Burhans, J. Blumenstock, and A.S.  Khan. “The Importance of Establishing a National Health Security Preparedness Index.” Biosecurity and  Bioterrorism: Biodefense Strategy, Practice, and Science, vol. 11, no. 1, 2013, pp. 81–87.  37 Keim, M.E., and A.P. Lovallo. “Validity of the National Health Security Preparedness Index as a Predictor of Excess  COVID-19 Mortality.” Prehospital and Disaster Medicine, vol. 36, no. 2, 2021, pp. 141–144.  https://doi.org/10.1017/S1049023X20001521.   38 Moulton, A.D. “A COVID-19 Lesson: Better Health Emergency Preparedness Standards Are Needed.” Health  Security, vol. 20, no. 6, 2022, pp. 457–466. https://doi.org/10.1089/hs.2022.0037.   39 Mays, G., and M. Childress. “2021 Release of National Health Security Preparedness Index.” University of Colorado,  Colorado School of Public Health, June 2021.   40 National Health Security Preparedness Index. “Measures List: National Health Security Preparedness Index, 2021  Release.” https://nhspi.org/wp-content/uploads/2021/06/2021-NHSPI-Measure-List.pdf.  41 Federal Emergency Management Agency. “National Preparedness Goal.” U.S. Department of Homeland Security,  September 2015. https://www.fema.gov/sites/default/files/2020-06/national_preparedness_goal_2nd_edition.pdf.  42 Centers for Disease Control and Prevention. “Public Health Emergency Preparedness and Response Capabilities:  National Standards for State, Local, Tribal, and Territorial Public Health.” October 2018.  https://www.cdc.gov/orr/readiness/00_docs/CDC_PreparednesResponseCapabilities_October2018_Final_508.pdf.   43 Assistant Secretary for Preparedness and Response. “2017–2022 Health Care Preparedness and Response  Capabilities.” November 2016. https://www.phe.gov/Preparedness/planning/hpp/reports/Documents/2017-2022- healthcare-pr-capablities.pdf.  44 Federal Emergency Management Agency. “National Preparedness Goal.” U.S. Department of Homeland Security,  September 2015. https://www.fema.gov/sites/default/files/2020-06/national_preparedness_goal_2nd_edition.pdf.  45 Centers for Disease Control and Prevention. “Public Health Emergency Preparedness and Response Capabilities:  National Standards for State, Local, Tribal, and Territorial Public Health.” October 2018.  https://www.cdc.gov/orr/readiness/00_docs/CDC_PreparednesResponseCapabilities_October2018_Final_508.pdf.  46 Assistant Secretary for Preparedness and Response. “2017–2022 Health Care Preparedness and Response  Capabilities.” November 2016. https://www.phe.gov/Preparedness/planning/hpp/reports/Documents/2017-2022- healthcare-pr-capablities.pdf.  47 Stribling, J., A. Clifton, G. McGill, and K. de Vries. “Examining the UK Covid-19 Mortality Paradox: Pandemic  Preparedness, Healthcare Expenditure, and the Nursing Workforce.”  Journal of Advanced Nursing, vol. 76, no. 12,  2020, pp. 3218–3227. https://doi.org/10.1111/jan.14562.   48 Kaiser, M.A., T.Y. Chen, and P. Gluckman. “Should Policy Makers Trust Composite Indices? A Commentary on the  Pitfalls of Inappropriate Indices for Policy Formation.” Health Research Policy and Systems, vol. 19, no.1, March  2021. https://doi.org10.1186/s12961-021-00702-4.   49 Keim, M.E., and A.P. Lovallo. “Validity of the National Health Security Preparedness Index as a Predictor of Excess  COVID-19 Mortality.” Prehospital and Disaster Medicine, vol. 36, no. 2, 2021, pp. 141–144.  https://doi.org/10.1017/S1049023X20001521.   50 Haider, N., A. Yavlinsky, Y.M. Chang, M.N. Hasan, C. Benfield, A.Y. Osman, M.J. Uddin, et al. “The Global Health  Security Index and Joint External Evaluation Score for Health Preparedness Are Not Correlated with Countries'  COVID-19 Detection Response Time and Mortality Outcome.” Epidemiology and Infection, vol. 148, 2020, article  e210. https://doi.org/10.1017/S0950268820002046.   51 Keim, M.E., and A.P. Lovallo. “Validity of the National Health Security Preparedness Index as a Predictor of Excess  COVID-19 Mortality.” Prehospital and Disaster Medicine, vol. 36, no. 2, 2021, pp. 141–144.  https://doi.org/10.1017/S1049023X20001521.    References  Mathematica® Inc.  39    52 Moulton, A.D. “A COVID-19 Lesson: Better Health Emergency Preparedness Standards Are Needed.” Health  Security, vol. 20, no. 6, 2022, pp. 457–466. https://doi.org/10.1089/hs.2022.0037.   53 Mays, G., and M. Childress. “2021 Release of National Health Security Preparedness Index.” University of Colorado,  Colorado School of Public Health, June 2021.   54 Nelson, C., N. Lurie, J. Wasserman. “Assessing public health emergency preparedness: concepts, tools, and  challenges.” Annual Rev. Public Health, vol. 28, 2007, pp. 1- 18. https://doi.org/10.1146/annurev.publhealth.  28.021406.144054.  55 National Health Security Preparedness Index. “Measures List: National Health Security Preparedness Index, 2021  Release” 2021. https://nhspi.org/wp-content/uploads/2021/06/2021-NHSPI-Measure-List.pdf.  56 McKillop, M., R. Faberman, and D. Alpert Lieberman. “Ready or Not 2024: Protecting the Public’s Health from  Diseases, Disasters, and Bioterrorism.” Trust for America’s Health, 2024. https://www.tfah.org/report-details/ready- or-not-2024/.  57 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  58 U.S. Department of Health and Human Services. “HPP Performance Metrics – FY 2021 Dashboard.” 2021.  https://dhhs.maps.arcgis.com/apps/dashboards/71b5f53173cb4f4e9248b85244158151.  59 Dorn, B.C., E. Savoia, M.A. Testa, M.A. Stoto, and L.J. Marcus. “Development of a Survey Instrument to Measure  Connectivity to Evaluate National Public Health Preparedness and Response Performance.” Public Health Reports,  vol. 122, no. 3, 2007, pp. 329-38. doi: 10.1177/003335490712200306. PMID: 17518304; PMCID: PMC1847495.  Development of a Survey Instrument to Measure Connectivity to Evaluate National Public Health Preparedness  and Response Performance - PMC (nih.gov).  60 Davis, Mary, Glen Mays, James Bellamy, Christine Bevc, and Cammie Marti. “Improving Public Health Preparedness  Capacity Measurement: Development of the Local Health Department Preparedness Capacities Assessment  Survey.” Disaster Medicine and Public Health Preparedness, vol 7, 2013, pp. 1–7. 10.1017/dmp.2013.108.  61 Boyce, M.R., and R. Katz. “Rapid Urban Health Security Assessment Tool: A New Resource for Evaluating Local-Level  Public Health Preparedness.” BMJ Global Health, vol. 5, no. 6, 2020, article e002606.  62 Glik, D.C., D.P. Eisenman, I. Donatello, A. Afifi, M. Stajura, M.L. Prelip, J. Sammartinova, et al. “Reliability and Validity  of the Assessment for Disaster Engagement with Partners Tool (ADEPT) for Local Health Departments.” Public  Health Reports, vol. 129, no. 6, suppl. 4, 2014, pp. 77–86. https://doi.org/10.1177/00333549141296S411.  63 National Health Security Preparedness Index. “Methodology for the 2021 Release of the National Health Security  Preparedness Index.” https://nhspi.org/wp-content/uploads/2021/NHSPI_2021_Methodology.pdf.  64 McKillop, M., R. Faberman, and D. Alpert Lieberman. “Ready or Not 2024: Protecting the Public’s Health from  Diseases, Disasters, and Bioterrorism.” Trust for America’s Health, 2024. https://www.tfah.org/report-details/ready- or-not-2024/.  65 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  66 Marcozzi, D.E., R. Pietrobon, J.V. Lawler, M.T. French, C. Mecher, J. Peffer, N.E. Baehr, et al. “Development of a  Hospital Medical Surge Preparedness Index Using a National Hospital Survey.” Health Service and Outcomes  Research Methodology, vol. 20, no. 1, 2020, pp. 60–83.   67 National Health Security Preparedness Index. “Measures List: National Health Security Preparedness Index, 2021  Release.” https://nhspi.org/wp-content/uploads/2021/06/2021-NHSPI-Measure-List.pdf.  68 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  69 Gray, B., J. Eaton, J. Christy, J. Duncan, F. Hanna, and S. Kasi. “A Proactive Approach: Examples for Integrating  Disaster Risk Reduction and Mental Health and Psychosocial Support Programming.” International Journal of  Disaster Risk Reduction, vol. 15, no. 54, 2021. https://doi.org/10.1016/j.ijdrr.2021.102051.    References  Mathematica® Inc.  40    70 Cutter, S., C. Burton, and C.T. Emrich. "Disaster Resilience Indicators for Benchmarking Baseline Conditions.” Journal  of Homeland Security and Emergency Management, vol. 7: no. 1, August 2010. https://doi.org/10.2202/1547- 7355.1732.  71 Peacock, W.G., S.D. Brody, W.A. Seitz, W.J. Merrell, A. Vedlitz, S. Zahran, R.C. Harriss, et al. “Advancing Resilience of  Coastal Localities: Developing, Implementing, and Sustaining the Use of Coastal Resilience Indicators: A Final  Report.” Hazard Reduction & Recovery Center, 2010, pp. 1–148.  72 United States Census Bureau. 2020. Community Resilience Estimates: Quick Guide. Also available  at https://www2.census.gov/data/experimental-data-products/community-resilience-estimates/2020/technical- document.pdf.  73 Sherrieb, K., F.H. Norris, and S. Galea. “Measuring Capacities for Community Resilience.” Social Indicators Research,  vol. 99, no. 2, 2010, pp. 227–247.  74 Surgo Ventures. “COVID-19 Community Vulnerability Index (CCVI) Methodology.” 2020. https://covid-static- assets.s3.amazonaws.com/US-CCVI/COVID-19+Community+Vulnerability+Index+(CCVI)+Methodology.pdf.  75 Tiwari, A., A.V. Dadhania, V.A.B. Ragunathrao, and E.R.A Oliveira. “Using Machine Learning to Develop a Novel  COVID-19 Vulnerability Index (C19VI).” Science of the Total Environment, vol. 773, 2021, article 14565.   76 Marvel, S.W., J.S. House, M. Wheeler, K. Song, Y.H. Zhou, F.A. Wright, W.A. Chiu, et al. “The COVID-19 Pandemic  Vulnerability Index (PVI) Dashboard: Monitoring County-Level Vulnerability Using Visualization, Statistical  Modeling, and Machine Learning.” Environmental Health Perspectives, vol. 129, no. 1, 2021.   77 Flanagan, B.E., E.W. Gregory, E.J. Hallisey, J.L. Heitgerd, and B. Lewis. “A Social Vulnerability Index for Disaster  Management.” Journal of Homeland Security and Emergency Management, vol. 8, no. 1, 2011.   78 Rogers, C.J., B. Cutler, K. Bhamidipati, and J.K. Ghosh. “Preparing for the Next Outbreak: A Review of Indices  Measuring Outbreak Preparedness, Vulnerability, and Resilience.” Preventive Medicine Reports, vol. 35, 2023, article  102282. https://doi.org/10.1016/j.pmedr.2023.102282.   79 Office of Disease Prevention and Health Promotion, U.S. Department of Health and Human Services. “Federal Plan  for Equitable Long-Term Recovery and Resilience for Social, Behavioral, and Community Health.” January 2022.  Available at: https://health.gov/our-work/national-health-initiatives/equitable-long-term-recovery-and-resilience  80 Boyce, M. “State-level public health preparedness indices as predictors of COVID-19 mortality outcomes: results  from the United States of America in 2020.” Frontiers in Epidemiology, December 2023. DOI:  10.3389/fepid.2023.1229718.  81 Stoto, M., and C. Nelson. “Measuring and Assessing Public Health Emergency Preparedness: A Methodological  Primer.” SSRN, August 2023. http://dx.doi.org/10.2139/ssrn.4538548.   82 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  83 Environmental Protection Agency (EPA). “Community Health Vulnerability Index.”. July 2017.  https://www.epa.gov/sites/default/files/2017-07/documents/community_health_vulnerability_index.pdf.  84 Nallen, Joe. “ReadyMapper: A Digital Solution to Optimize Health System Resilience and Response During  Wildfires.” Crisis Ready, 2022. https://www.crisisready.io/optimizing-health-response-during-wild-fires-with-real- time-integrated-data/.  85National Weather Service. “TsunamiReady Guidelines.”n.d. https://www.weather.gov/tsunamiready/guidelines.  86 Hammer, J., D.G. Ruggieri, C. Thomas, and J. Caum. “Local Extreme Heat Planning: An Interactive Tool to Examine a  Heat Vulnerability Index for Philadelphia, Pennsylvania.” Journal of Urban Health, vol. 97, no. 4, 2020, pp. 519–528.  https://doi.org/10.1007/s11524-020-00443-9.   87 Moore, M., B. Gelfeld, and C.P. Adeyemi Okunogbe. “Identifying Future Disease Hot Spots: Infectious Disease  Vulnerability Index.” Rand Health Quarterly, vol. 6, no. 3, 2017.   88 Lee, J.M., R. Jansen, K.E. Sanderson, F. Guerra, S. Keller-Olaman, M. Murti, T.L. O'Sullivan, et al. “Public Health  Emergency Preparedness for Infectious Disease Emergencies: A Scoping Review of Recent Evidence.” BMC Public  Health, vol. 23, no. 1, 2023, pp. 420. https://doi.org/10.1186/s12889-023-15313-7.    References  Mathematica® Inc.  41    89 Nallen, Joe. “ReadyMapper: A Digital Solution to Optimize Health System Resilience and Response During  Wildfires.” Crisis Ready, 2022. https://www.crisisready.io/optimizing-health-response-during-wild-fires-with-real- time-integrated-data/.  90 National Health Security Preparedness Index. “Measures List: National Health Security Preparedness Index, 2021  Release.” https://nhspi.org/wp-content/uploads/2021/06/2021-NHSPI-Measure-List.pdf.  91 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  92 Glik, D.C., D.P. Eisenman, I. Donatello, A. Afifi, M. Stajura, M.L. Prelip, J. Sammartinova, et al. “Reliability and Validity  of the Assessment for Disaster Engagement with Partners Tool (ADEPT) for Local Health Departments.” Public  Health Reports, vol. 129, no. 6, suppl. 4, 2014, pp. 77–86. https://doi.org/10.1177/00333549141296S411.  93 Dorn, B.C., E. Savoia, M.A. Testa, M.A. Stoto, and L.J. Marcus. “Development of a Survey Instrument to Measure  Connectivity to Evaluate National Public Health Preparedness and Response Performance.” Public Health Reports,  vol. 122, no. 3, 2007, pp. 329-38. doi: 10.1177/003335490712200306. PMID: 17518304; PMCID: PMC1847495.  Development of a Survey Instrument to Measure Connectivity to Evaluate National Public Health Preparedness  and Response Performance - PMC (nih.gov).  94 Boyce, M.R., and R. Katz. “Rapid Urban Health Security Assessment Tool: A New Resource for Evaluating Local-Level  Public Health Preparedness.” BMJ Global Health, vol. 5, no. 6, 2020, article e002606.  95 Centers for Disease Control and Prevention. “Public Health Emergency Preparedness and Response Capabilities:  National Standards for State, Local, Tribal, and Territorial Public Health.” October 2018.  https://www.cdc.gov/orr/readiness/00_docs/CDC_PreparednesResponseCapabilities_October2018_Final_508.pdf.  96 Assistant Secretary for Preparedness and Response. “2017–2022 Health Care Preparedness and Response  Capabilities.” November 2016. https://www.phe.gov/Preparedness/planning/hpp/reports/Documents/2017-2022- healthcare-pr-capablities.pdf.  97 Federal Emergency Management Agency. “National Preparedness Goal.” U.S. Department of Homeland Security,  September 2015. https://www.fema.gov/sites/default/files/2020-06/national_preparedness_goal_2nd_edition.pdf.  98 Dorn, B.C., E. Savoia, M.A. Testa, M.A. Stoto, and L.J. Marcus. “Development of a Survey Instrument to Measure  Connectivity to Evaluate National Public Health Preparedness and Response Performance.” Public Health Reports,  vol. 122, no. 3, 2007, pp. 329-38. doi: 10.1177/003335490712200306. PMID: 17518304; PMCID: PMC1847495.  Development of a Survey Instrument to Measure Connectivity to Evaluate National Public Health Preparedness  and Response Performance - PMC (nih.gov).  99 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  100 Acosta, J.D., L. Burgette, A. Chandra, D.P. Eisenman, I. Gonzalez, D. Varda, and L. Xenakis. “How Community and  Public Health Partnerships Contribute to Disaster Recovery and Resilience.” Disaster Medicine and Public Health  Preparedness, vol. 12, no. 5, 2018, pp. 635–643. https://doi.org/10.1017/dmp.2017.130.   101 Adams, R.M., M.L. Prelip, D.C. Glik, I. Donatello, and D.P. Eisenman. “Facilitating Partnerships with Community- and  Faith-Based Organizations for Disaster Preparedness and Response: Results of a National Survey of Public Health  Departments.” Disaster Medicine and Public Health Preparedness, vol. 12, no. 1, 2018, pp. 57–66.  https://doi.org/10.1017/dmp.2017.3.   102 Brewer, L.C., G. Asiedu, C. Jones, M. Richard, J. Erickson, J. Weis, A. Abbenyi, et al. “Emergency Preparedness and  Risk Communication Among African American Churches: Leveraging a Community-Based Participatory Research  Partnership COVID-19 Initiative.” Preventing Chronic Disease, vol. 17, 2020. https://doi.org/10.5888/pcd17.200408.   103 Glik, D.C., D.P. Eisenman, I. Donatello, A. Afifi, M. Stajura, M.L. Prelip, J. Sammartinova, et al. “Reliability and Validity  of the Assessment for Disaster Engagement with Partners Tool (ADEPT) for Local Health Departments.” Public  Health Reports, vol. 129, no. 6, suppl. 4, 2014, pp. 77–86. https://doi.org/10.1177/00333549141296S411.  104 Marcozzi, D.E., R. Pietrobon, J.V. Lawler, M.T. French, C. Mecher, J. Peffer, N.E. Baehr, et al. “Development of a  Hospital Medical Surge Preparedness Index Using a National Hospital Survey.” Health Service and Outcomes  Research Methodology, vol. 20, no. 1, 2020, pp. 60–83.    References  Mathematica® Inc.  42    105 Administration for Strategic Preparedness and Response. “2019–2023 Hospital Preparedness Program:  Performance Measures Implementation Guidance.” 2022.  https://aspr.hhs.gov/HealthCareReadiness/guidance/Documents/2019-2023-HPP-Performance-Measures- Implementation-Guidance-8Nov22.pdf.   106 National Association of County and City Health Officials. “Administrative Preparedness: Emergency Reporting  Practices for Health Departments.” September 2013. https://www.naccho.org/uploads/header-images/public- health-preparedness/Admin-Prep_Reporting.pdf.  107 Centers for Disease Control and Prevention. “Public Health Emergency Preparedness and Response Capabilities:  National Standards for State, Local, Tribal, and Territorial Public Health.” October 2018.  https://www.cdc.gov/orr/readiness/00_docs/CDC_PreparednesResponseCapabilities_October2018_Final_508.pdf.  108 Gupta, N., S.A. Balcom, A. Gulliver, and R.L. Witherspoon. “Health Workforce Surge Capacity During the COVID-19  Pandemic and Other Global Respiratory Disease Outbreaks: A Systematic Review of Health System Requirements  and Responses.” The International Journal of Health Planning and Management, vol. 36, no. 1, 2021, pp. 26–41.  https://doi.org/10.1002/hpm.3137.   109 Stoto, M., and C. Nelson. “Measuring and Assessing Public Health Emergency Preparedness: A Methodological  Primer.” SSRN, August 2023. http://dx.doi.org/10.2139/ssrn.4538548.  110 Moulton, A.D. “A COVID-19 Lesson: Better Health Emergency Preparedness Standards Are Needed.” Health  Security, vol. 20, no. 6, 2022, pp. 457–466. https://doi.org/10.1089/hs.2022.0037.  111 Krieger, Nancy, Christian Testa, Jarvis T. Chen, William P. Hanage, and Alecia J. McGregor. “Relationship of Political  Ideology of U.S. Federal and State Elected Officials and Key COVID Pandemic Outcomes Following Vaccine Rollout  to Adults: April 2021–March 2022.” The Lancet Regional Health - Americas, vol. 16, 2022, article 100384.  https://doi.org/10.1016/j.lana.2022.100384.  112 Pence, J., I. Miller, T. Sakurahara, J. Whitacre, S. Reihani, E. Kee, and Z. Mohaghegh. “GIS-Based Integration of Social  Vulnerability and Level 3 Probabilistic Risk Assessment to Advance Emergency Preparedness, Planning, and  Response for Severe Nuclear Power Plant Accidents.” Risk Analysis, vol. 39, no. 6, 2019, pp. 1262–1280.  https://doi.org/10.1111/risa.13241.  113 Boyce, M. “State-level public health preparedness indices as predictors of COVID-19 mortality outcomes: results  from the United States of America in 2020.” Frontiers in Epidemiology, December 2023. DOI:  10.3389/fepid.2023.1229718.  114 Stoto, M., and C. Nelson. “Measuring and Assessing Public Health Emergency Preparedness: A Methodological  Primer.” SSRN, August 2023. http://dx.doi.org/10.2139/ssrn.4538548.   115 Grimmelikhuijsen, S & E. Knies. “Validating a scale for citizen trust in government organizations.” International  Review of Administrative Sciences, vol 83, no. 3, 2017, pp. 583 – 601. https://doi.org/10.1177/0020852315585950  116 Burns, K, P. Brown, M. Calnan, P.R. Ward, J. Little et al. “Development and validation of the Trust in Government  measure (TGM)”. BMC Public Health, 2023. https://doi.org/10.1186/s12889-023-16974-0  117 Pew Research Center. “Public Trust in Government: 1958 – 2024”. June  2024.https://www.pewresearch.org/politics/2024/06/24/public-trust-in-government-1958-2024/  118 SteelFisher, G., M. G. Finding, H.C. Caporello, K.M. Lubell, et al. “Trust in U.S. Federal, State, and Local Public Health  Agencies During COVID-19: Responses and Policy Implications.” Health Affairs, vol 42, no. 3, March 2023, pp. 328 –  337. https://doi.org/10.1377/hlthaff.2022.01204  119 Ghosh, J.K., B. Martinez, C. Beck, and C. Rogers. “Community Outbreak Preparedness Index (COPI).” Heluna Health,  October 2023. COPI_Technical_Report_October_2023.pdf.  120 Federal Emergency Management Agency. “Pre-Disaster Recovery Planning Guide for Tribal Governments (FP 104- 008-02).” U.S. Department of Homeland Security, September 2019. https://www.fema.gov/sites/default/files/2020- 07/pre-disaster-recovery-planning-guide-for-tribal-government.pdf.  121 Federal Emergency Management Agency. “2022–2026 FEMA National Tribal Strategy.” U.S. Department of  Homeland Security, 2022. https://www.fema.gov/sites/default/files/documents/fema_national-tribal- strategy_08182022.pdf.    References  Mathematica® Inc.  43    122 Lorenzoni, Nina, Stephanie Kainrath, Maria Unterholzner, and Harold Stummer. "Instruments for Disaster  Preparedness Evaluation: A Scoping Review." Australian Journal of Emergency Management, vol. 37, no. 3, 2022,  pp. 56.  123 Moulton, A.D. “A COVID-19 Lesson: Better Health Emergency Preparedness Standards Are Needed.” Health  Security, vol. 20, no. 6, 2022, pp. 457–466. https://doi.org/10.1089/hs.2022.0037.   124 Keim, M.E., and A.P. Lovallo. “Validity of the National Health Security Preparedness Index as a Predictor of Excess  COVID-19 Mortality.” Prehospital and Disaster Medicine, vol. 36, no. 2, 2021, pp. 141–144.  https://doi.org/10.1017/S1049023X20001521.  125 Kachali, Hlekiwe, Ira Haavisto, Riikka-Leena Leskelä, Auri Väljä, and Mikko Nuutinen. “Are Preparedness Indices  Reflective of Pandemic Preparedness? A COVID-19 Reality Check.” International Journal of Disaster Risk Reduction,  vol. 77, 2022, pp. 2212–4209. https://doi.org/10.1016/j.ijdrr.2022.103074.  126 NACCHOO, “2022 Preparedness Profile Study.” 2023. https://www.naccho.org/uploads/downloadable- resources/2022PrepProfile-PREVIEWREPORT.pdf.   127 National Health Security Preparedness Index. “Measures List: National Health Security Preparedness Index, 2021  Release.” 2021. https://nhspi.org/wp-content/uploads/2021/06/2021-NHSPI-Measure-List.pdf.  128 The White House. “National Cybersecurity Strategy.” March 2023. https://www.whitehouse.gov/wp- content/uploads/2023/03/National-Cybersecurity-Strategy-2023.pdf.  129 National Association of County and City Health Officials. “Hurricane and Flooding Preparedness Resources.”2015.  https://www.naccho.org/blog/articles/hurricane-and-flooding-preparedness-resources.  130 National Association of County and City Health Officials. “2022 Preparedness Profile Study.” 2023.  https://www.naccho.org/uploads/downloadable-resources/2022PrepProfile-PREVIEWREPORT.pdf.  131 National Health Security Preparedness Index. “Measures List: National Health Security Preparedness Index, 2021  Release.” 2021. https://nhspi.org/wp-content/uploads/2021/06/2021-NHSPI-Measure-List.pdf.  132 Qari, S.H., H.R. Yusuf, S.L. Groseclose, M.R. Leinhos, and E.G. Carbone. “Public Health Emergency Preparedness  System Evaluation Criteria and Performance Metrics: A Review of Contributions of the CDC-Funded Preparedness  and Emergency Response Research Centers.” Disaster Medicine and Public Health Preparedness, vol. 13, no. 3,  2019, pp. 626–638. https://doi.org/10.1017/dmp.2018.110.  133 Government Accountability Office. “COVID-19: Pandemic Lessons Highlight the Need for Public health Situational  Network.” 2022. https://www.gao.gov/products/gao-22-104600.  134 Ibid.  135 Lorenzoni, Nina, Stephanie Kainrath, Maria Unterholzner, and Harold Stummer. "Instruments for Disaster  Preparedness Evaluation: A Scoping Review." Australian Journal of Emergency Management, vol. 37, no. 3, 2022,  pp. 56.  136 Ibid.  137 Qari, S.H., H.R. Yusuf, S.L. Groseclose, M.R. Leinhos, and E.G. Carbone. “Public Health Emergency Preparedness  System Evaluation Criteria and Performance Metrics: A Review of Contributions of the CDC-Funded Preparedness  and Emergency Response Research Centers.” Disaster Medicine and Public Health Preparedness, vol. 13, no. 3,  2019, pp. 626–638. https://doi.org/10.1017/dmp.2018.110.  138 Institute of Medicine Committee on Post-Disaster Recovery of a Community's Public Health, Medical, and Social  Services. “Healthy, resilient, and sustainable communities after disasters: strategies, opportunities, and planning  for recovery.” Washington (DC): National Academies Press (US); 2015 Sep 10. Available from:  https://www.ncbi.nlm.nih.gov/books/NBK316532/ doi: 10.17226/18996.  139 Stribling, J., A. Clifton, G. McGill, and K. de Vries. “Examining the UK Covid-19 Mortality Paradox: Pandemic  Preparedness, Healthcare Expenditure, and the Nursing Workforce.”  Journal of Advanced Nursing, vol. 76, no. 12,  2020, pp. 3218–3227. https://doi.org/10.1111/jan.14562.     References  Mathematica® Inc.  44    140 Kaiser, M.A., T.Y. Chen, and P. Gluckman. “Should Policy Makers Trust Composite Indices? A Commentary on the  Pitfalls of Inappropriate Indices for Policy Formation.” Health Research Policy and Systems, vol. 19, no.1, March  2021. https://doi.org10.1186/s12961-021-00702-4.  141 Keim, M.E., and A.P. Lovallo. “Validity of the National Health Security Preparedness Index as a Predictor of Excess  COVID-19 Mortality.” Prehospital and Disaster Medicine, vol. 36, no. 2, 2021, pp. 141–144.  https://doi.org/10.1017/S1049023X20001521.  142 Choo, E.K. “COVID-19 Fault Lines.” Lancet, vol. 395, no. 10233, 2020, pp. 1333. https://doi.org/10.1016/S0140- 6736(20)30812-6.  143 Liao, T.F., and F. De Maio. “Association of Social and Economic Inequality with Coronavirus Disease 2019 Incidence  and Mortality Across US Counties.” JAMA Network Open, vol. 4, no. 1, 2021, article e2034578.  https://doi.org/10.1001/jamanetworkopen.2020.34578.  144 Mays, G., and M. Childress. “2021 Release of National Health Security Preparedness Index.” University of Colorado,  Colorado School of Public Health, June 2021.   145 Centers for Disease Control and Prevention. “Public Health Response Readiness Framework: 2024-–2028 Program  Priorities – Defines Excellence in Response Operations.” 2024.  https://www.cdc.gov/orr/readiness/phep/00_docs/CDC-PHEP-Response-Readiness-Framework_January- 2024_508c.pdf.  146 American Medical Association, Planned Parenthood Federation of America, American Association of Public Health  Physicians, National Birth Equity Collaborative, American College of Preventive Medicine, American Public Health  Association, For the Culture Consulting, LLC, and New York City Pandemic Response Institute. “Embedding Equity  in Crisis Preparedness and Response.” 2023. https://www.ama-assn.org/about/ama-center-health- equity/embedding-equity-crisis-preparedness-and-response-health-systems. Accessed May 10, 2024.  147 Congressional Research Service. “Tracking COVID-19: U.S. Public Health Surveillance and Data.” 2020.  https://crsreports.congress.gov/product/pdf/R/R46588.  148 Centers for Disease Control and Prevention. “Data Modernization Initiative website.” n.d.  https://www.cdc.gov/surveillance/data-modernization/index.html. Accessed May 2, 2024.  149 National Academies of Sciences, Engineering, and Medicine. “Evidence Based Practice for Public Health Emergency  Preparedness and Response.” 2020.  150 Samet, J. and R.C. Brownson. “Reimagining Public Health: Mapping a Path Forward”. Health Affairs, vol. 43, no. 6,  2024, pp. 750 – 758. https://doi.org/10.1377/hlthaff.2024.00007.   151 Lichiello, P., and B. Turnock. Guidebook to Performance Management. 1999.  https://www.phf.org/resourcestools/documents/pmcguidebook.pdf.   152 Ibid.  153 Roper, W., and B. Mays. “Performance Measurement in Public Health: Conceptual and Methodological Issues in  Building the Science Base.” Journal of Public Health, September 2000.  154 McDavid, J. C., and L.R.L. Hawthorn, L. R. L. Program Evaluation and Performance Measurement: An Introduction to  Practice. Sage Publications, Inc, 2006.  155 Roper, W., and B. Mays. “Performance Measurement in Public Health: Conceptual and Methodological Issues in  Building the Science Base.” Journal of Public Health, September 2000.  156 Ibid.  157 Cox, R., and M. Hamlen. “Community Disaster Resilience and the Rural Resilience Index.” American Behavioral  Scientist, vol. 59, no. 2, February 2015.  158 Lorenzoni, Nina, Stephanie Kainrath, Maria Unterholzner, and Harold Stummer. "Instruments for Disaster  Preparedness Evaluation: A Scoping Review." Australian Journal of Emergency Management, vol. 37, no. 3, 2022,  pp. 56.  159 Glik, D.C., D.P. Eisenman, I. Donatello, A. Afifi, M. Stajura, M.L. Prelip, J. Sammartinova, et al. “Reliability and Validity  of the Assessment for Disaster Engagement with Partners Tool (ADEPT) for Local Health Departments.” Public  Health Reports, vol. 129, no. 6, suppl. 4, 2014, pp. 77–86. https://doi.org/10.1177/00333549141296S411.     References  Mathematica® Inc.  45    160 Acosta, J.D., L. Burgette, A. Chandra, D.P. Eisenman, I. Gonzalez, D. Varda, and L. Xenakis. “How Community and  Public Health Partnerships Contribute to Disaster Recovery and Resilience.” Disaster Medicine and Public Health  Preparedness, vol. 12, no. 5, 2018, pp. 635–643. https://doi.org/10.1017/dmp.2017.130.   161 Dorn, B.C., E. Savoia, M.A. Testa, M.A. Stoto, and L.J. Marcus. “Development of a Survey Instrument to Measure  Connectivity to Evaluate National Public Health Preparedness and Response Performance.” Public Health Reports,  vol. 122, no. 3, 2007, pp. 329-38. doi: 10.1177/003335490712200306. PMID: 17518304; PMCID: PMC1847495.  Development of a Survey Instrument to Measure Connectivity to Evaluate National Public Health Preparedness  and Response Performance - PMC (nih.gov).  162 Ibid.  163 Technical Resources, Assistance Center, and Information Exchange. "ASPR TRACIE Emergency Preparedness  Information Modules for Nurses in Acute Care Settings," February 2022.  https://files.asprtracie.hhs.gov/documents/aspr-tracie-emergency-preparedness-information-modules-for-nurses- and-economic-framework.pdf. Accessed May 10, 2024.  164 Society for Healthcare Epidemiology of America. "Outbreak Response Training Program." https://learningce.shea- online.org/content/sheacdc-outbreak-response-training-program-ortp#group-tabs-node-course-default1.  Accessed May 10, 2024.  165 Haan, Katherine. "Best Learning Management Systems (LMS) of 2024." Forbes Advisor, April 8, 2024.  https://www.forbes.com/advisor/business/best-learning-management- systems/#:~:text=Learning%20management%20systems%2C%20or%20LMS%2C%20are%20software%20platform s,as%20to%20provide%20compliance%20training%20or%20customer%20education. Accessed May 10, 2024.  166 National Association of County and City Health Officials. “2022 Preparedness Profile Study.” 2023.  https://www.naccho.org/uploads/downloadable-resources/2022PrepProfile-PREVIEWREPORT.pdf.  167 Choo, E.K. “COVID-19 Fault Lines.” Lancet, vol. 395, no. 10233, 2020, pp. 1333. https://doi.org/10.1016/S0140- 6736(20)30812-6; Liao, T.F., and F. De Maio. “Association of Social and Economic Inequality with Coronavirus  Disease 2019 Incidence and Mortality Across US Counties.” JAMA Network Open, vol. 4, no. 1, 2021, article  e2034578. https://doi.org/10.1001/jamanetworkopen.2020.34578.  168 Krieger, Nancy, Christian Testa, Jarvis T. Chen, William P. Hanage, and Alecia J. McGregor. “Relationship of Political  Ideology of U.S. Federal and State Elected Officials and Key COVID Pandemic Outcomes Following Vaccine Rollout  to Adults: April 2021–March 2022.” The Lancet Regional Health - Americas, vol. 16, 2022, article 100384.  https://doi.org/10.1016/j.lana.2022.100384; Technical Expert Panel.  169 Stoto, M., and C. Nelson. “Measuring and Assessing Public Health Emergency Preparedness: A Methodological  Primer.” SSRN, August 2023. http://dx.doi.org/10.2139/ssrn.4538548; Technical Expert Panel.  170 Brown, Lisa M., Kathryn Hyer, and LuMarie Polivka-West, "A comparative study of laws, rules, codes and other  influences on nursing homes' disaster preparedness in the Gulf Coast states." Behavioral Sciences & the Law, vol.  25, no. 5, September 2007, pp. 655-675. https://doi.org/10.1002/bsl.785.   171 Botoseneanu, A., H. Wu, J. Wasserman, P.D. Jacobson, "Achieving public health legal preparedness: how dissonant  views on public health law threaten emergency preparedness and response." Journal of Public Health, vol. 33, no.  3, September 2011, pp. 361-368. https://doi.org/10.1093/pubmed/fdq092.   172 Chowdhury, P., S. Kumar Paul, S. Kaisar, and Md. A. Moktadir. "COVID-19 Pandemic Related Supply Chain Studies:  A Systematic Review. Trnsp Res E Logist Transp Rev. April 2021, 148: 102271. doi: 10.1016/j.tre.2021.102271.  173 DeSalvo, K., B. Hughes, M. Bassett, G. Benjamin, M. Fraser, S. Galea, N. Garcia, and J. Howard. 2021. “Public Health  COVID-19 Impact Assessment: Lessons Learned and Compelling Needs.” NAM Perspectives. Discussion Paper,  National Academy of Medicine, Washington, DC. https://doi.org/10.31478/202104c.   174 Burke, Marshall, Anne Driscoli, Sam Huft-Neal, Jiani Xue, Jennifer Burney, and Michael Wara, "The changing risk  and burden of wildfire in the United States." PNAS vol. 118, no. 2, 2021. https://doi.org/10.1073/pnas.2011048118.   175 Mannucci, Simona, Federica Rosso, Alessandro D'Amico, Gabriele Bernardini, and Michele Morganti, "Flood  resilience and adaptation in the built environment: how far along are we?" Sustainability, vol. 14 no. 7, March  2022, 4096; https://doi.org/10.3390/su14074096.    References  Mathematica® Inc.  46    176 Brown, Lisa M., Kathryn Hyer, and LuMarie Polivka-West, "A comparative study of laws, rules, codes and other  influences on nursing homes' disaster preparedness in the Gulf Coast states." Behavioral Sciences & the Law, vol.  25, no. 5, September 2007, pp. 655-675. https://doi.org/10.1002/bsl.785.  177 Choo, E.K. “COVID-19 Fault Lines.” Lancet, vol. 395, no. 10233, 2020, pp. 1333. https://doi.org/10.1016/S0140- 6736(20)30812-6; Liao, T.F., and F. De Maio. “Association of Social and Economic Inequality with Coronavirus  Disease 2019 Incidence and Mortality Across US Counties.” JAMA Network Open, vol. 4, no. 1, 2021, article  e2034578. https://doi.org/10.1001/jamanetworkopen.2020.34578.  178 Centers for Disease Control and Prevention. “Public Health Response Readiness Framework: 2024-2028 Program  Priorities – Defines Excellence in Response Operations.” CDC.  https://www.cdc.gov/orr/readiness/phep/00_docs/CDC-PHEP-Response-Readiness-Framework_January- 2024_508c.pdf.  179 Mays, G., and M. Childress. “2021 Release of National Health Security Preparedness Index.” University of Colorado,  Colorado School of Public Health, June 2021.  180 Federal Emergency Management Agency. “After-Action Review User Guide.” November 2023.  https://preptoolkit.fema.gov/documents/d/cip- citap/after_action_review_user_guide_november_2023_f?download=true.   181 Federal Emergency Management Agency. “National Preparedness Goal.” March 2023.  https://www.fema.gov/emergency-managers/national-preparedness/goal. Accessed May 6, 2024  182 National Academies of Sciences, Engineering, and Medicine. “Evidence Based Practice for Public Health Emergency  Preparedness and Response.” 2020.  183 Knox, C. C. “Systematic Analysis of After-Action Reports: A Plan Evaluation Methodological Approach.” Nat.  Hazards Rev., vol. 22, no. 4, 2021. https://ascelibrary.org/doi/10.1061/%28ASCE%29NH.1527-6996.0000519.   184 FEMA. “Homeland Security Exercise Evaluation Program.” Undated. https://preptoolkit.fema.gov/web/hseep- resources.   185 TRACIE. “COVID After-Action Report Resources and Examples.” January 19, 2023.  https://files.asprtracie.hhs.gov/documents/aspr-tracie-covid-19-after-action-reports---7-21-2021-508.pdf.   186 Naik, R., N. Maxwell, T. Jones, and S. A. Dopson. "Public Health Emergency Preparedness: Qualitative Analysis of  After-Action Reports. Disaster Medicine and Public Health Preparedness, vol. 17, 2023, e523. doi:  https://doi.org/10.1017/dmp.2023.201.   187 Piltch-Loeb, R.N., C. Nelson, J. Kraemer, E. Savoia, and M. Stoto. “s.” Public Health Reports, vol. 129, no. 6,  November 2014, pp. 28–34. https://doi.org/10.1177/00333549141296S405.  188 Administration for Strategic Preparedness and Response. “2019–2023 Hospital Preparedness Program:  Performance Measures Implementation Guidance.” 2022.  https://aspr.hhs.gov/HealthCareReadiness/guidance/Documents/2019-2023-HPP-Performance-Measures- Implementation-Guidance-8Nov22.pdf.     Appendix A. Methods  Mathematica® Inc.  A.1  Appendix A. Methods  The study included an environmental scan, a technical expert panel (TEP), a synthesis analysis of themes  and gaps in current metrics, and a synthesis analysis of strategies to advance public health preparedness  metrics. In this appendix, we describe our study methods.  A. Environmental scan  With support from our partner, MDB, Inc., we conducted an environmental scan. The primary goal of the  scan was to learn about existing domestic and international public health and health-care preparedness  measures, indices, and inventories (which we collectively describe as “tools”). Although the focus of this  project is on domestic preparedness, the inclusion of articles focusing on global tools that assess nation- level preparedness provided valuable insights and perspectives that enhanced and broadened  understanding of this topic.   We identified peer-reviewed and gray literature for the environmental scan by systematically searching  PubMed and Web of Science databases and select government agency and preparedness-tool websites.  We supplemented these searches with targeted Google searches. We applied the following exclusion  criteria to literature returned through the searches that:  / Focused on individual or household emergency preparedness (for example, checklists to assess  emergency preparedness at the household level)  / Focused on studies or tools that measure preparedness at the subnational level in countries outside the  United States (for example, comparing disaster preparedness in French pediatric hospitals)  / Did not focus on any phase of the emergency preparedness cycle (for example, articles describing post- disaster outcomes that did not also assess elements of prevention, protection, mitigation, response, and  recovery)  / Did not describe efforts to measure preparedness (for examples, articles describing emergency training  curricula for health and public health workers)  / Summarized after-action reports and lessons learned from individual public health agencies  Below, we describe our approaches to identifying relevant literature.  1. Searched PubMed and Web of Science for peer-reviewed journal articles: From October through  December 2023, we conducted searches of PubMed and Web of Science records using search terms  related to public health (and variations such as community health and population health); medical  systems (including variations such as health infrastructure and hospitals); emergencies, disasters, and  hazards; preparedness, readiness, resilience, and vulnerability; and measurement (including variations  such as measures, scores, index, and scorecard).13 We restricted the PubMed and Web of Science  searches to articles published after 2012 to focus on recent tools and research, and applied the  exclusion criteria listed above to the returned articles.    13 This list of search terms is not exhaustive.  Appendix A. Methods  Mathematica® Inc.  A.2  2. Searched government agency and preparedness-tool websites: In April 2024, we conducted focused  searches on the websites of key government agencies and prominent preparedness-tool websites to  identify relevant publications on public health or health preparedness. We then applied the exclusion  criteria described above to the returned literature. We searched webpages for the following  organizations and agencies: the Centers for Disease Control and Prevention, Administration for  Strategic Preparedness and Response, the Federal Emergency Management Administration, National  Association of County and City Health Officials (NACCHO), the Association of State and Territorial  Health Officials (ASTHO), Pan American Health Organization, National Health Security Preparedness  Index (NHSPI), and Trust for America’s Health.  3. Conducted targeted Google searches: The peer-reviewed and gray literature included scoping reviews  that mentioned a few U.S.-based tools that were not associated with articles returned from the  searches noted above. To learn more about these tools, we conducted additional targeted Google  searches using the tool name as the search term.   Initial PubMed and Web of Science searches for peer-reviewed literature returned 1,878 articles. After  applying exclusion criteria, we identified 74 articles to include in the full-text review. Our searches for gray  literature on federal agency websites, preparedness-tool websites, and Google yielded an additional 30  documents.  In total, we closely reviewed 104 pieces of peer-reviewed and gray literature (Exhibit A.1). From each of  these articles, we extracted information identifying the tool being discussed (if any), challenges in  measuring preparedness, and key findings related to measuring public health and health-care  preparedness. We highlight key findings from the environmental scan in Chapter II, although we cite  relevant sources throughout the report.  Exhibit A.1. Identification of literature via databases and supplemental searches     Appendix A. Methods  Mathematica® Inc.  A.3  B. Technical expert panel  Our partner, MDB, Inc., convened a technical expert panel (TEP) in January 2024, composed of 20 experts  from federal agencies, public health and health-care organizations, and academia (a complete list of TEP  members and their affiliations is in Appendix D). We identified TEP members with a background in public  health or health preparedness, an understanding of metrics, and broad knowledge of current disaster  threats. We attempted to identify a subset of TEP members who represent the perspectives of populations  that are socially vulnerable, given the challenges in reaching these populations and disparities in post- disaster outcomes.  MDB conducted the two-hour TEP meeting virtually, facilitating a combination of breakout group and  main group discussions. The breakout group portion of the meeting consisted of three small group  discussions facilitated by MDB and Mathematica staff. Throughout the meeting, TEP members discussed  (1) the strengths and weaknesses of current measures, drawing on findings from the scan and their own  experiences; (2) key takeaways from the COVID-19 pandemic; and (3) considerations for future  preparedness measurement efforts, including new data sources that could be captured in measures.  Appendix E presents the full TEP meeting agenda.   A notetaker captured comments from TEP members, which was subsequently used for thematic analysis.  We coded the findings to understand the relative frequency of different themes and the prevalence of  these themes across breakout groups. Unless otherwise noted, all TEP findings and quotations included in  this report were mentioned by at least three TEP members across two or more breakout groups. TEP  findings are interweaved with literature findings throughout the report.  C. Analysis of themes and gaps in current preparedness metrics  Using data from the environmental scan and the TEP, we analyzed themes and gaps in current U.S.  preparedness metrics related to eight characteristics (Exhibit A.2), which we summarize in Chapter II. Our  approach to assessing themes and gaps varied by characteristic, as some characteristics are relevant at the  tool level (for example, the types and intended users of indices) whereas others are relevant at the  measure level (for example, the data source for a measure of preparedness).  Exhibit A.2. Characteristics of preparedness metrics assessed in the analysis of themes and gaps  Characteristic  Level of analysis  Types of available tools  Tool level  Purpose  Tool level  Intended users  Tool level  How metrics conceptualize preparedness  Tool and measure levels  Types of disasters addressed  Tool level  Jurisdiction levels   Tool level  Data sources  Measure level  Preparedness factors being measured  Measure level  For tool-level characteristics, we used the literature from the environmental scan to develop a de- duplicated summary table of U.S.-based preparedness tools and their characteristics (Appendix B). We  Appendix A. Methods  Mathematica® Inc.  A.4  defined “preparedness tools” as tools that assessed national, state, or local capacity in two or more phases  of the emergency preparedness cycle (that is, prevention, protection, mitigation, response, and recovery).  We did not include tools that (1) exclusively measure nation-level preparedness, (2) measure subnation  level preparedness outside the United States, or (3) measure a single phase of preparedness (for example,  vulnerability and resilience indices). From the 104 documents that we reviewed as part of the  environmental scan, we identified 12 existing preparedness tools at the STLT (state, tribal, local, or  territorial) level. Each article did not present a unique tool; many of these articles focused on the same  tools and metrics (most commonly, the NHSPI). We used the summary table to describe the frequencies  of tool-level characteristics across existing tools and to identify gaps in these characteristics. We  synthesized these findings with others from the literature and the TEP and highlighted in the report any  inconsistencies across data sources.   For measure-level characteristics, we relied on the synthesis of TEP and literature findings to identify  themes and gaps. We approached the measure-level analysis this way because it was not feasible to  develop a comprehensive, de-duplicated list of existing measures, given the vast number of measures  across existing tools. We summarize the findings from the themes and gap analysis in Chapter II.  D. Analysis of strategies to advance preparedness measurement  To inform the analysis of strategies to advance preparedness measurement (Chapter III), we first reviewed  literature on public health performance measurement to understand important attributes of metrics and  the extent to which these attributes are missing from existing preparedness metrics, as identified in the  gaps analysis. We then reviewed TEP findings to identify strategies the TEP members had suggested to  address the gaps in existing metrics. We synthesized TEP findings with themes from the literature to  develop the list of proposed strategies in Chapter III. Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care Preparedness in the United States  Mathematica® Inc.  B.1  Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care  Preparedness in the United States   Tool   Type of tool  Hazard   Domain(s)  Jurisdiction  level(s)  Data source  Intended  users  Strengths  Weaknesses  ASPR’s Hospital  Preparedness Program  performance measure set  (ASPR 2022)  Measure set  AH  • Foundation for  Health Care and  Medical Readiness  • Health Care and  Medical Response  Coordination  • Continuity of  Health Care Service  Delivery  • Medical Surge   National  HPP funding  recipient (state,  territorial, large  local)   HCC (local/  substate) level   Data self- reported by  funding  recipients; ASPR  shares data  publicly  Federal  officials  State and local  officials  HCCs and local  multi-sector  coalitions  General public  Some measures are  at the HCC (local)  level so may be  relevant and  actionable for  communities to use  for planning   Most data are reported  at the level of the  funding recipient  (generally state and  territorial).  HCCs are not consistent  sizes and are not always  comparable.   Earlier assessments of  the HPP measures in a  2013 GAO report noted  the need for annual  benchmarks to support  progress over time.a  Assessment for Disaster  Engagement with  Partners Tool (ADEPT)  (Glik et al. 2014)    Index  AH  • Communication  outreach and  coordination  • Resource  mobilization  • Organizational  capacity building  • Partnership  development and  maintenance  Local  Data self- reported/ self- administered by  local health  departments  Local health  departments   Captures valuable  information on the  linkages between  LHDs and  CBOs/FBOs for  disaster information,  resources, shelter,  and other assistance  Evidence of the tool’s  validity and predictive  capacity in real-world  emergencies is limited.  Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care Preparedness in the United States  Mathematica® Inc.  B.2  Tool   Type of tool  Hazard   Domain(s)  Jurisdiction  level(s)  Data source  Intended  users  Strengths  Weaknesses  Community Outbreak  Preparedness Index  (Ghosh et al. 2023)  Index  ID  • Health-care system  preparedness  • Public health  system  preparedness  • Access to health  insurance and  social safety net  services  • Community factors  Local  NACHHO data;  FEMA data;  American  Hospital  Association  Survey; National  Provider  Identifier; other  sources  STLT public  health officials  and partners;  policy makers  Fills a gap in indices  specific to local  agencies  The new tool is not  widely validated or  researched in different  local contexts.   Connectivity  Measurement Tool   (Dorn et al. 2007)  Index  AH  • System  • Coworker  • Organization  • Individual   Local  (individual,  organization  and/or system)  Self-administered  questionnaire   STLT  emergency  preparedness  agencies and  organizations  Authors believe that  aggregated scores  collected from  specific  organizations or  systems provide data  that can be used for  comparative  purposes   Self-reported data are  prone to response bias.   The tool does not  include an assessment  of performance in  relation to connectivity.   Hospital Medical Surge  Preparedness Index  (Marcozzi et al. 2020)  Index  AH  • Staff  • Supplies  • Space  • System  Local  (facility/hospital)    American  Hospital  Association  annual survey  data, U.S. Census  Bureau, and the  Dartmouth Atlas  project  Hospital  administrators   Regional and  state  emergency  planners  Hospital-level data  provide granular  information that can  be aggregated to  inform state and  regional emergency  planners   The index fails to  measure synergies  between hospitals to  improve collective  response.  The index has not been  validated in relation to  hospital performance in  the face of actual  disasters.  Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care Preparedness in the United States  Mathematica® Inc.  B.3  Tool   Type of tool  Hazard   Domain(s)  Jurisdiction  level(s)  Data source  Intended  users  Strengths  Weaknesses  National Health Security  Preparedness Index    Index  AH  • Health security and  surveillance  • Community  planning and  engagement  • Incident and  information  management  • Health care  delivery  • Countermeasures  management  • Environmental and  occupational  health  National  State  64 data sources,  including surveys  (i.e., BRFSS,  ASTHO profiles,  Comprehensive  Laboratory  Services Survey,  All-Hazards  Laboratory  Preparedness  Survey, and  others), safety  inspection  results, and  federal  administrative  records  Federal, state,  and local  officials  Multisector  coalitions  Researchers  General Public    ASTHO coordinated  input from a wide  range of  stakeholders to  develop the tool in  2013  Served as one of the  first tools to assess  all-hazards  preparedness at the  sub-national level in  the United States  There is some  evidence that high  preparedness scores  were associated with  lower death rates  during the COVID-19  pandemica,b  There is evidence that  the NHSPI is not a valid  predictor of excess  COVID-19 mortality  rates for 50 U.S. states  and Puerto Rico during  the first six months of  the pandemic.c    Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care Preparedness in the United States  Mathematica® Inc.  B.4  Tool   Type of tool  Hazard   Domain(s)  Jurisdiction  level(s)  Data source  Intended  users  Strengths  Weaknesses  Preparedness Capacity  Assessment Survey   (Davis et al. 2013)  .   Index   AH  • Surveillance and  investigation  • Plans and  protocols  • Workforce and  volunteers  • Communication  and information  dissemination  • Incident command  • Legal infrastructure  and preparedness  • Emergency events  and exercises  • Corrective action  activities  Local   Survey  completed by  local health  departments  State and local  health  departments  The domains reflect  the essential and  vital capacities for  local and state  health departments  to effectively build  and maintain their  preparedness  capabilities   Data are self-reported  and may contain  potential response bias.  The tool is not designed  for comparison across  jurisdictions.   Rapid Urban Health  Security Assessment  (RUHSA) (Boyce and Katz  2020)  Measure set  AH  • Prevent public  health emergencies  • Detect public  health emergencies  • Respond to public  health emergencies  • Other  considerations  Local  Internal data  used for self- assessment  Local  government  leaders and  policymakers   Assesses immediate  capacity to respond  to disease and  health threats at the  local level    RUHSA is a self- assessment tool, so  does not allow for  comparison or  benchmarking against  other similar  jurisdictions.  Designed specifically for  urban jurisdictions, the  tool is not applicable to  rural jurisdictions.  Appendix B. Tools to Measure State, Local, Tribal, and Territorial Public Health and Health Care Preparedness in the United States  Mathematica® Inc.  B.5  Tool   Type of tool  Hazard   Domain(s)  Jurisdiction  level(s)  Data source  Intended  users  Strengths  Weaknesses  Trust for America’s  Health Ready or Not tool  (McKillop 2024)  Measure set  AH  • Incident  management  • Institutional quality  • Water security  • Workforce  resiliency and  infection control  • Countermeasure  utilization  • Patient safety  • Health security  surveillance  • Public health  system  comprehensiveness  (not included in  2024 report)   National  (summarizes  number of  states in high,  medium, and  low tiers)  State  NHSPI data  sources and state  public health  expenditure data  collected and  analyzed by  TFAH   Federal, state,  and local  officials;  general public;  researchers;   Includes a narrower  set of measures than  NHSPI, allowing for  focused attention to  guide stakeholders  in improvement  efforts.  High TFAH  preparedness scores  were generally, but  not uniformly,  associated with  lower death rates.a  The tool’s narrow set of  goals does not consider  the full range of risks  that a jurisdiction may  face.     Note:  Strengths and weaknesses were cited within the source for each tool, unless otherwise noted. AH = all hazards; AHA = American Hospital Association; ASPR = Administration  for Strategic Preparedness and Response; ASTHO = Association of State and Territorial Health Officials; BRFSS = Behavioral Risk Factor Surveillance System; CBO =  community-based organization; FBO = faith based organization; FEMA = Federal Emergency Management Agency; HCC = health care coalition; ID = infectious disease; LHD =  local health department; NHSPI = National Health Security Preparedness Index; STLT = state, tribal, local, or territorial; TFAH = Trust for American Health index.  a Moulton, A.D. “A COVID-19 Lesson: Better Health Emergency Preparedness Standards Are Needed.” Health Security, vol. 20, no. 6, 2022, pp. 457–466.  https://doi.org/10.1089/hs.2022.0037.   b Mays, G., and M. Childress. “2021 Release of National Health Security Preparedness Index.” University of Colorado, Colorado School of Public Health, June 2021.   c Keim, M.E., and A.P. Lovallo. “Validity of the National Health Security Preparedness Index as a Predictor of Excess COVID-19 Mortality.” Prehospital and Disaster Medicine, vol. 36, no. 2,  2021, pp. 141–144. https://doi.org/10.1017/S1049023X20001521.  Appendix C. Summary of Literature Assessing the Extent to Which Preparedness Indices Predicted Outcomes During the COVID-19 Pandemic  Mathematica® Inc.  C.1  Appendix C. Summary of Literature Assessing the Extent to Which Preparedness Indices   Predicted Outcomes During the COVID-19 Pandemic  Title  Author (date)  Tool discussed  Key findings  Examining the UK Covid-19 mortality paradox:  pandemic preparedness, health-care  expenditure, and the nursing workforce   Stribling et al.  (2020)  Global Health Security (GHS)  Index  Country-level mortality rates do not appear to be related to the GHS Index in a  manner that would be expected. The top 3 scoring countries on the GHS Index  (United States, United Kingdom, and the Netherlands) all have relatively high  mortality rates, while Canada (ranked 5th on the GHS Index) has a moderate  mortality rate, but Australia and Thailand (ranked 4th and 6th, respectively)  have a very low mortality rate.  Validity of the National Health Security  Preparedness Index as a predictor of excess  COVID-19 mortality  Keim and Lovallo  (2021)  National Health Security  Preparedness Index (NHSPI)  The NHSPI tool did not appear to be a valid predictor of excess COVID-19  mortality rates for the 50 U.S. states and Puerto Rico during the first 6 months  of the pandemic (March–September 2020). Researchers found a high degree of  variance and poor correlation between excess COVID-19 mortality rates  compared to the overall score and to the 6 individual domains in the NHSPI.   Should policy makers trust composite indices? A  commentary on the pitfalls of inappropriate  indices for policy formation  Kaiser et al. (2021) GHS Index  Composite preparedness indices like the GHS have several weaknesses, which  may account for the inverted relationship between predicted vs. actual  performance. Weaknesses identified include an inconsistent scoring system,  arbitrary weighting of indicators, inclusion of indicators with questionable  validity, inability to compare scores across countries, and inability to capture  political bias.   The Global Health Security index and Joint  External Evaluation score for health preparedness  are not correlated with countries' COVID-19  detection response time and mortality outcome  Haider et al.  (2020)  GHS Index  Joint External Evaluation  (JEE) for health preparedness  The GHS index and JEE were found to be strongly correlated, but both indices  had a poor correlation with countries’ COVID-19 related mortality outcomes  and had low predictive value for detection response time from March 11–July 1,  2020.   Does it matter that standard preparedness  indices did not predict COVID-19 outcomes?  Stoto and Nelson  (2023)  GHS Index  JEE for health preparedness  A country’s success in dealing with a pandemic is highly multidimensional and  may be too complex to represent with a single number, as provided by the GHS  and JEE. Methodological issues identified include the comparability of mortality  data due to highly variable completeness and representativeness and the  inability to capture variations in the presence of effective political leadership.   The Global Health Security Index is not predictive  of coronavirus pandemic responses among  Organization for Economic Cooperation and  Development countries  Abbey et al. (2020) GHS Index  A rank-based analysis measuring total cases, total deaths, recovery rate, and  total tests performed found a discrepancy between the GHS Index rating and  the actual performance of Organization for Economic Cooperation and  Development countries during the COVID-19 pandemic.  Appendix C. Summary of Literature Assessing the Extent to Which Preparedness Indices Predicted Outcomes During the COVID-19 Pandemic  Mathematica® Inc.  C.2  Title  Author (date)  Tool discussed  Key findings  Strengthening national capacities for pandemic  preparedness: A cross-country analysis of  COVID-19 cases and deaths  Duong et al.  (2022)  IHR-SPAR  GHS index  Universal Health Coverage  Service Coverage Index  World Bank Worldwide  Governance Indicator  Countries with higher GHS and IHR-SPAR scores experienced fewer reported  COVID-19 cases and deaths but only for the first 8 weeks after the country’s  first case (for GHS, the association was limited to countries with populations  below 69.4 million). The country-level rankings from the Universal Health  Coverage Service Coverage Index and Worldwide Governance Indicator were  not associated with COVID-19 outcomes.   A COVID-19 lesson: Better health emergency  preparedness standards are needed  Moulton (2022)  NHSPI  TFAH  High NHSPI and TFAH preparedness scores were generally, but not uniformly,  associated with lower COVID-19 death rates. The measure of effectiveness of  the pandemic response was measured by states’ cumulative COVID-19 deaths  per 100,000 population from January 1, 2020–January 20, 2022.   Are preparedness indices reflective of pandemic  preparedness? A COVID-19 reality check  Kachali et al.  (2022)  IHR  GHS index  States’ reported cumulative mortality rates during the first wave of the COVID- 19 pandemic (spring 2020) were primarily negatively correlated with the  expected preparedness rank, according to IHR and GHS.  Comparison of COVID-19 Resilience Index and its  associated factors across 29 countries during the  Delta and Omicron variant periods  Huy et al. (2022)  Pandemic resilience index  Across 29 countries, the percentage of the population fully vaccinated and high  government indices scores were significantly associated with a better resilience  index score in both the COVID-19 Delta and Omicron periods. The pandemic  resilience index combines country-level mortality, hospital occupancy, and  intensive care unit occupancy rates.   Global health security preparedness and  response: An analysis of the relationship between  Joint External Evaluation scores and COVID-19  response performance  Nguyen et al.  (2021)   JEE for health preparedness  Emergency Response  Capacity Tool (ERCT)  There is low agreement between JEE scores and COVID-19 response  performance, with JEE scores often trending higher. The JEE indicator  “Emergency Operations Center (EOC) operating procedures and plans” had the  highest agreement and predicted probability with ERCT (62 percent), and the  “capacity to activate emergency operations” had the lowest predicted  probability (16 percent).   The National Health Security Preparedness Index  (2021 release)     Note: Not peer reviewed.  Mays et al. (2021)  NHSPI  COVID-19 deaths were significantly lower in communities with higher levels of  health security as measured in the index when controlling for county population  size, population density, percent aged 65 years or older, percent Black, percent  Hispanic, percent below poverty level, percent under age 65 without health  insurance, number of nursing home residents per capita, and social vulnerability  rates measured in the Community Resiliency Index, and adjusting for clustering  of counties within states.  GHS = Global Health Security; IHR = International Health Regulations; NHSPI = National Health Security Preparedness Index; SPAR = States Parties Self-Assessment Annual Report;  TFAH = Trust for American Health index. Appendix D. Technical Expert Panel Participants  Mathematica® Inc.  D.1  Appendix D. Technical Expert Panel Participants  Joseph A. Barbera, M.D., The George Washington University   Georges Benjamin, M.D., American Public Health Association   Paul Biddinger, M.D., Mass General Brigham   Laura Biesiadecki, National Association of County and City Health Officials   Jason Brown, Public Health Management Corporation   Jack Herrmann, M.S.Ed., American Red Cross   Richard Hunt, M.D., U.S. Department of Health and Human Services   Mark Keim, M.D., MBA, Fairfax County Health Department   Christine Kosmos, R.N., M.S., U.S. Centers for Disease Control and Prevention   James Lawler, M.D., M.P.H., University of Nebraska Medical Center   Beth Maldin Morgenthau, M.P.H., NYC Department of Health and Mental Hygiene   Jenna Mandel-Ricci, M.P.A., M.P.H., NYC Department of Health and Mental Hygiene   Glen Mays, Ph.D., Colorado School of Public Health   Ali Mokdad, Ph.D., University of Washington   Jennifer Nuzzo, Dr.PH., Brown University   Lisa J. Peterson, Association of State and Territorial Health Officials   Michael A. Stoto, Ph.D., Georgetown University   Eric Toner, M.D., Johns Hopkins Center for Health Security   Craig Vanderwagen, M.D., East West Protection, LLC   Michael Wargo, HCA Healthcare   Appendix E. Technical Expert Panel Agenda  Mathematica® Inc.  E.1  Appendix E. Technical Expert Panel Agenda  A. Welcome and Stage Setting  B. Breakout Session 1: Current Measures  1. What is your experience with currently available measures and their strengths and weaknesses?   2. What did COVID-19 teach us about measures?   3. What important aspects of the literature on public health and health-care preparedness measures  were not addressed in the environmental scan?   C. Breakout Session 2: Future Measures   1. What impact should measures have?   2. How should public health and health-care preparedness be measured?   3. What are common data sources that could be used for future measures?  D. Group Discussion: Framework Development   1. What current and future measures can inform the development of a framework?    2. Should the COVID-19 experience drive the development of public health and health-care  preparedness measures?   3. Should the framework be based on threats, hazards, capabilities, or capacities?  E. Summary Remarks and Conclusion         Mathematica Inc.  Our employee-owners work nationwide and around the world.  Find us at mathematica.org and edi-global.com.  Mathematica, Progress Together, and the “spotlight M” logo are registered trademarks of Mathematica Inc.