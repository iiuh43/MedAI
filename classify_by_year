import pandas as pd
import requests
import fitz  # PyMuPDF
import re
from io import BytesIO

# Load your file (change if using .xlsx)
df = pd.read_csv("filtered_relevant.csv")

if "PDF Link" not in df.columns:
    raise ValueError("Column 'PDF Link' not found!")

# Function to extract the most likely year from a PDF
def extract_likely_year(url):
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()

        with fitz.open(stream=BytesIO(response.content), filetype="pdf") as doc:
            text = ""
            for page in doc:
                text += page.get_text()
                if len(text) > 3000:
                    break

        # Proper regex: find full 4-digit years like 2020, 2023
        years = re.findall(r"\b(19\d{2}|20\d{2})\b", text)
        if not years:
            return None

        # Count frequency of each year
        year_counts = {}
        for y in years:
            year_counts[y] = year_counts.get(y, 0) + 1

        likely_year = max(year_counts, key=year_counts.get)
        return likely_year

    except Exception as e:
        print(f"Error processing {url}: {e}")
        return None

# Loop with progress print
all_years = []
total = len(df)
for i, url in enumerate(df["PDF Link"], start=1):
    print(f"[{i}/{total}] Processing: {url}")
    year = extract_likely_year(url)
    all_years.append(year)

df["Year"] = all_years

# Save output
df.to_excel("output_with_years.xlsx", index=False)
print("\n Done! Results saved to 'output_with_years.xlsx'")
